
<DOC>
<VID> pLozUiapQuY </VID>
<CONTENT>
[Music]
I did some work in VR head open source
summit in Vancouver and today we have
with us our fifth game of networking a
Linux Foundation first of all thanks for
coming over to the show all excited to
be here so let's talk about in all the
last 12 months you know what happened in
the networking space it has been a
fantastic here you know we have seen a
hundred and forty one-year-old telecom
industry move to open source networking
right with the Aleph networking we have
now you know exceeded a hundred members
we now have participation from almost
70% of the global subscribers as enabled
by the largest of the large carriers we
have seen pretty much all the vendors
active and over five hundred million
dollars worth of software innovation in
terms of value has been created in the
open source community so we're really
excited
projects like onap which were launched
almost a year ago have moved to
production projects like tungsten fabric
have moved into the ls networking
umbrella so all the way up and down the
stack we can now safely say that the
telecom industry is going to use open
source that is based out of Linux
foundation for building their next
generation networks so we talked about
you know kind of in order over we are
reflecting on 12 months now let's look
at the future you know how do you go
from here oh yeah yeah we'll continue on
this path and it'll take you know two to
five years for deployment
so deployment is our main focus right
now for what is next for LS is how
networking enables what we call cross
project collaboration okay cross
industry collaboration cross community
collaboration and what do we mean by
that and and I'm using the term
harmonization to not all under like that
umbrella but you know we can use any
term but what that mean is how does
blockchain impact teleport
how can telecom networks glow cloud
native with kubernetes right so we
showed a demonstration of own app
running on kubernetes right
all of those integrations right the most
you know promising area that's coming up
is a project called acronym which is an
edge project so as you know the core
problem has been solved now telecom
networks come moving to the edge and
edge cloud is a big area it you know by
some analysts it's gonna be bigger than
even the current cloud that that has
shown up because it's distributed it's
enabling 5g it's enabling IOT it's and
only over-the-top applications right
tons of new ideas are coming up because
of edge cloud so how does edge and
correlate how do how do we integrate
edge with automotive grade Linux and 5g
for autonomous driving right so in a
nutshell the area for our for my
personally my focus as well as Lennox
Foundation is how do these communities
of these projects come together and can
collaborate so that there's more value
to our end-users to our members and
things like that so that's what we're
working on right now but if you look at
Linux Foundation it's kind of giant
umbrella you have all the split that
you're talking internal II so how first
of all did a lot of cross-pollination
happens yes then you come to these
events like that I mean everybody is
here correct and that is exactly right
however if you look at each of these
projects they're building their own come
examine individual what we're moving to
a phase is how do these projects work
together right work together so I just
hosted a seminar with the executive
director of CNCs Duncan right and what
we discussed is in telecom we have this
concept of virtual network functions and
we enough right vnfs our actual services
and applications that run on our telecom
network how do you make vnf cloud native
so we're calling we've created this term
called
CN
okay cloud native network functions
right so how do you migrate these vnf to
CNF and there are technology things but
both communities kubernetes and own app
community and networking community they
have to work together right to solve
this problem collectively
[Music]
</CONTENT>
</DOC>
<DOC>
<VID> 2yeccvlNBeY </VID>
<CONTENT>
[Music]
hi Lisa Parvati and we are here open
source summit in Vancouver and today we
have with us Anjali from rocket software
until you can you tell us what exactly
is open mainframe put herself mainframe
has been around for many years it is
very proprietary and a lot of the code
that is written on the mainframe and the
tools that are used are proprietary and
there is a ageing workforce on the
mainframe
they are either retiring they have
retired or they may no longer be with us
and that is because the tools and
technology that are used on the
mainframe are old Scoob all its
assembler and its technologies people
don't want to use the interfaces are
green you know there's no touchscreen so
rocket came together with IBM and see a
technologies and we've open-sourced a
platform which opens the mainframe to
the modern generation so modern
generation of end users and modern
generation of developers and we have
provided them basically an
infrastructure where they can build a
modern user experience which can be
touchscreen which is the web interface
they are used to using html5 JavaScript
typescript III you know tools that they
are used to languages that they are used
to command-line interfaces which again
they can script they can use Jenkins for
their C ICD pipeline and also REST API
so now everything is open and they don't
have to know the older technologies and
what that allows both end users and
developers to do is a newer generation
can adopt it and now have access to all
the critical data which is in all these
financial and retail and insurance
systems which is still on the mainframe
so the mainframe isn't going away and it
is better to bring the new generation to
the mainframe then try to move the
critical data elsewhere so Zoe is that
open source project and it is part of
the open mainframe project and it is the
first project ever done on
the Z operating system so when you talk
about Z there is Linux on mainframe but
most of the critical applications are
not on Linux they are actually on C
operating system which is proprietary so
this project has been built and we have
open sourced it on z/os the first open
source project and it is targeting the
younger generation really college
students high schoolers and we are
providing them the tools the languages
all the things that they can use and
they can believe in and bring the
mainframe to them so here you're talking
about your kind of workforce but at the
same time you also need a community
around Zoe itself that's correct so how
are you trying to get the community
around it our plan is to do hackathons
centered around Zoe so we can invite
students and we can invite community
people to learn how easy it is to use it
we are working starting to work with our
customers and this is the combined
industry to get them more involved
[Music]
you
</CONTENT>
</DOC>
<DOC>
<VID> U6P3jPcvkhE </VID>
<CONTENT>
this is a short introductory
presentation on rehabs a resilient
information architecture platform for
smart grid the original development of
the software platform was supported by
the US Department of Energy's advance
research agency
arpa-e there are revolutionary changes
going on in the area of energy with the
appearance of many distributed energy
resources we are moving away from the
centralized power station transmission
system distribution system customer
model we are changing to a more
distributed and decentralized paradigm
where energy is produced and distributed
locally possibly shared across the grid
we started building micro grids with
solar and wind generation playing an
increasing role this leads to increased
decentralization and enables cheaper and
cleaner energy but this also introduces
problems new technologies are needed to
manage and protect the grid however the
control architecture of the power grid
has not changed yet the old model of
centralized control driven by a control
room still applies power devices at the
edge such as transformers capacitor
banks and even loads are remotely
controlled a new very dynamic and
distributed energy production and
distribution paradigm does not mesh well
with this control or production
decisions should be made locally systems
which include inverters and substations
need to be integrated and interoperate
seamlessly today software is becoming
the universal integration tool this
means we need to implement complex
distributed real-time software that is
resilient and secure but how should this
be done vision with Reax is to provide a
software platform that enables the
design engineering and operation of such
software systems
reiax is a middleware a sort of
distributed operating system that runs
on networked embedded devices deployed
on the energy grid on one side the
platform interacts with sensors like
p.m. use
and actuators such as inverters and on
the other side it allows communication
between the pieces of the distributed
app rehabs apps are inherently
distributed and run in loosely coupled
interacting actors that are low overhead
containers of single or multi threaded
software components this is a list of
features in rehabs first of all rehabs
is a software platform to build
real-time embedded apps the apps can run
with real-time priority to meet timing
constraints the components of the app
interact with each other via high
performance messaging primitives that
support various communication
architectures such as pub/sub and
request to fly etc components are single
threaded and all interactions among
threads happen through messages rehabs
apps can be implemented in Python for
self real-time or in C++ for hard
real-time or as a mixture of the two
reiax provides a number of services that
apps can rely on these include a fault
tolerance peer-to-peer discovery service
high precision approximately 10
microseconds
time synchronization application
deployment and remote management device
access control resource management of
CPU file space network bandwidth and
memory footprint can be tightly
controlled so runaway apps do not
exhaust resources mechanisms are
available for fault tolerance such as
automatic app restart and network link
reconnect rehabs also supports a set of
distributed coordination services which
include dynamic group formation and
communication leader election and
consensus and time coordinating control
actions finally rehab says secure the
deployment mechanism and all
communications use secure protocols and
apps are strictly isolated from each
other and their access to resources
as Network link and devices are tightly
controlled this figure summarizes the
layers of the platform reacts runs on
Linux with real-time extensions enabled
and uses standard Linux packages it's
two main ingredients are the component
framework that supports the app
components and the platform manager that
implements the services apps are built
on top of the framework and rely on the
services example apps include
distributed SCADA power management micro
grid control energy management remedial
action scheme rehabs is designed to be
universal and it can support a large
variety of embedded apps to summarize
Reax is a software platform we have
demonstrated it in a few selected
application areas micro grid control
remedial action schemes and transactive
energy additional information is
available on our website next we will
show a demo to illustrate how rehabs
apps are built deployed and run in this
demonstration we will show a simple
application called the distributed
estimator we will utilize Eclipse to
demonstrate this
first this model file has an application
name distributed estimator they are
message topics since already since their
query sensor value and estimate three
components a sensor component a local
estimator a global estimator
the sensor component is defined with a
periodic timer that runs every one
second a published port publishes on the
topic of sensor ready the local
estimator has a subscriber that is
looking for that topic since already
there is a request port and the local
estimator with a sensor query sensor
value pair a reply port on the sensor
which has matching topics the local
estimator publishes an estimate which is
picked up by the global estimator
subscriber looking for that same topic
the global estimator also has a timer
every three seconds
actors are executables defined by
combinations of one or more components
the estimator actor has a combination of
the sensor component and the local
estimator
the local messages are messages that
stay within the node here's where you
could see the sensor with its published
sense already data and with the local
estimator which is subscribing to that
information the sensor query and sensor
value request reply ports exchange
messages within that actor
the aggregator actor has one component
the global estimator the estimate
messages are global and will be received
from the published information of the
local estimator the global estimator is
woken up every three seconds using a
timer
we'll now look at what it takes to
define a component
looking at the sensor component
the sensor class will define the time
report called clock with an on clock
function within the con clock function a
message is published using a port called
ready
the sensor also has a request fort which
responds to requests from other
components
next we will look at the local estimator
component the local estimators
subscriber fort ready is triggered when
a sensor ready message is received it
then sends a request on a query fort to
the sensor the sensor receives the
request on its request for it and sends
back a response the response triggers
the query port then the local estimator
will publish an estimate which is
available globally
you
now let's look at the global estimator
component this component includes a
timer that wakes up every three seconds
there is also an estimate subscriber
fort which is triggered when estimate
messages are received from the local
estimator
next we'll show how to start the rehabs
controller and a react node the rehabs
registry service is started first this
service could be started in the
background as a system service we will
start the rehabs controller application
on the development machine application
will be used to load the rehabs apps to
deploy them to rehabs targets and to
start and stop the applications
we will start the deployment service on
the development machine
the IP address of the deployed target
node will appear once the rehab
framework discovers the node now open a
reapplication by first selecting the
application folder then the model file
for the application the dot rehabs file
and the application deployment model dot
de piel by selecting the view button you
will get a picture of the applications
architecture and deployment in this you
see that the two actors the aggregator
and estimator are both deployed on the
same node the estimator contains the
sensor and the local estimator you can
see the messages and how they are
exchanged among the components you can
also tell whether they are local or
global messages
the application deployment model shows
we will deploy both actors on all target
nodes using the deployment model the
controller will deploy the actors to the
specified node seeing the react
controller we will launch the
application the application is then
launched by the rehab step low service
on each of the target rehabs nodes the
rehab step low service output shows
messages coming from each component
global estimator local estimator and
sensor you stop the application by
selecting the application and the stop
button you can also remove the
application from the rehabs target this
will remove all of the files for this
application
we will now run this application on a
virtual network which will have four
target nodes looking at this deployment
model you'll see that the estimator
actor will be deployed on three nodes
well the aggregator actor is deployed on
the fourth node
we will now launched mini net with four
virtual nodes we log into each of the
virtual nodes and start the rehabs
platform we also start a react
controller this gives you a display
window for the control app three
estimators and the aggregator you can
see all four target nodes indicated in
the control app
we locate and open the rehabs
application as before
we choose the mini met version of the
deployment model
if you again view the application this
time you will notice that there are four
target nodes deployed onto one target
node is the aggregator actor on the
other three is the estimator actor this
time you will see three target nodes
contributing estimates that are gathered
by the aggregator
there's a corresponding window for each
of these nodes
you
we will now deploy and launch the up
on the virtual network
once it is running you will see one
aggregator and three estimators
a director log can be viewed in the top
window while the other three windows
show the estimator actor logs
you
we will now stop the application
once they have grayed out then we can
safely remove the application from the
target note we can shut down all
registered target nodes by selecting
kill from the selection menu
then we can safely quit the control
application
you know how to use rehabs in your next
power application please visit our
website
</CONTENT>
</DOC>
<DOC>
<VID> J5dvTdEBuTg </VID>
<CONTENT>
we're from snowflake computing and today
I'm going to be talking about some of
our performance testing infrastructure
at snowflake with an emphasis on our use
of the TPCC workload so what is TPCC
TPCC is an industry standard ltp
benchmark used to simulate a realistic
workload of a retail business it
consists of 5 diverse transaction types
that have somewhat read only others are
readwrite they also vary in terms of
complexity and duration there's also an
approximately two to one read/write
ratio which is a similar to what we
experienced at snowflake so that's why
we've relied so heavily or part of the
reason we've relied so heavily on this
workload for our performance testing as
you can see from the diagram a TPCC
database consists of a configurable
number of warehouses and both the size
of the database and the number of
concurrent clients scale in proportion
to the number of warehouses chosen so
how do we use TPCC
we use it to analyze performance in a
number of different ways we have
periodic jenkins not just runs to search
for unexpected performance regressions
in our master branch we also test the
performance effects of enabling new
features such as our new serialization
protocol which andrew will be discussing
next and also changing different
parameters for example using different
asynchronous i/o libraries comparing
different page cache sizes we also use
it as a baseline workload to ensure that
foundation DB remains available in
performance while we perform snapshot
backups and rolling upgrades and we test
a variety of cluster configurations with
different hardware and different
topologies so what does a typical test
setup look like for us most of our tests
run on a 5 node cluster of AWS 360 next
large machines we always ensure at least
one virtual CPU per process and
typically run with triple triple
replication and an SSD engine and too
close to resemble what snowflake uses we
run most tests with three resolvers
three proxies and five transaction logs
and a large tester pool on separate
machines to ensure we're not constrained
by testing resources so now I want to
just briefly talk about one example of
an interesting finding that we had well
running these tests so we used to
operate under the assumption that
scaling the number of storage servers
would always result in increased
performance but as you can see that's
not always been the case
in TPCC throughput is measured in terms
of transactions permitted committed and
the number of clients scales linearly
with the number of warehouses used
so ideally one would expect linear
scaling of throughput and that's what we
saw here with 32 storage servers or 64
but in this particular configuration
when we went to 128 we started seeing
decreased throughput throughput and that
was really surprising even though we
replicated this many times and what we
found is for reasons that we still don't
entirely understand and are still
investigating we saw an increase in real
latency as we scale about the number of
warehouses and the number of storage
servers and this causes longer
transactions and with the way foundation
to be handles optimistic concurrency
control larger transactions result in a
higher conflict probability and this
higher conflict rate resulted in the
decrease in throughput so this is by no
means an official benchmark or anything
we can scale beyond this but it's just
an example of some problems that we
identified with one particular cluster
configuration and we were lucky to not
be surprised by production workload and
be able to debug this in our test
environment in addition to our work with
DP CC we've also done a lot of work
scaling out how many processes can we
can we handle in a single cluster and
often we found that the bottleneck there
was the cluster controller CPU so a
quick refresher the cluster controller
is a process whose responsibilities
include handling client connections
running a failure monitor and handling
status requests and this is largely
workload independent also cluster
controller CPU will increase with the
total number of connections and the
frequency of status requests and we see
here that even in the absence of any
workload as you scale out the number of
clients and the number of servers used
you see a steady increase in CPU and
this can be a problem because the
cluster controller is single threaded so
these tests and observations led to a
series of optimizations to help out with
making the cluster controller more
efficient with these optimizations we
were handle able to handle an additional
150 percent more status requests per
second these optimizations included pre
serialization of status of status
objects
and some low-level optimizations to the
float sq we also cherry-pick to change
from the open-source version to allow
processes to run with a cluster
controller class and when you run a
process with the cluster controller
class then you're ensuring that under
ideal circumstances that process will be
elected cluster controller but won't
have any other responsibilities so if
you run without this class you run the
risk that for example a hot storage
server could also be elected cluster
controller and that's be overwhelmed
start missing heartbeats and eventually
that can cause reelection zin downtime
we also improved the way we do
throttling so we don't have to make as
many status requests to the cluster
controller so some of the metrics that
Ashish was talking about you can get
those with a status request but if your
cluster controller is under duress you
might not want to do that so we pushed a
lot of those metrics to the proxies and
that we can get those cheaply for
efficient client-side throttling so
where do we plan to go from here we like
to continue scaling out our TPCC tests
to more closely resemble a production
workload we also hope that now that our
implementation has been open sourced and
I actually had the link on a previous
slide where we open sourced our
implementation written in flow and we
hope that other companies can run
similar tests on their own environments
because there's a lot of different
parameters you can change we also didn't
do any official benchmarking but we hope
that this robust open-source
implementation can lead the way for
doing that in the future also another
thing to consider we didn't do TPC II
make a TPC II workload but for other if
you have for example a higher readwrite
ratio or a more random workload that's
another industry standard benchmark that
could be used for Simmons similar
purposes thank you
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> hxjAS_1_qbE </VID>
<CONTENT>
hi everyone my name is senthil
ramamoorthy i am part of the foundation
TV team at snowflake today I'm going to
present about instant backup and restore
feature that we have been developing
first I'll start off with explaining the
current backup and restore
implementation and explain some of the
challenges that we run into and the new
approach that we take and how it solves
some of our challenges and what are the
caveats with that and we'll conclude
with a quick live demo of the backup
feature so the current backup
implementation works as a logical level
backup here is defined as a consistent
copy of all the key values in the
database and the consistent copy of the
key values in the database are obtained
by reading the entire database through
the f DB stack there are much more
details about the current backup
implementation which I'm not going
because of the time constraints the
restore works by playing back the backup
key values into their f DB cluster again
through the f DB stack as you can see if
you want to read the entire key value in
the database through the f DB stack it
consumes resources like CPU network disk
across the f DB cluster and that impacts
the foreground workload and the current
restore mechanism also consumes
resources on top of it it is slow the f
DB 3 version that we use is extremely
slow the future version that is supposed
to get better but it still may not meet
our performance requirements the impact
of the current backup this is a slide
that Marcus one of my teammates shared
already the pink bar here represents the
eye ops purely driven by the backup
process this is from one of our
production deployments
so let's switch over to the new instant
backup and restore and look at that
approach in the instant backup and
restore we don't look at backup from a
logical standpoint we look at it from a
physical standpoint so backup here is
defined as a consistent copy of all the
disk images specifically FDB takes a
application level consistent snapshot of
all the persistent data of all the FDB
processes across the cluster and this
collection of disk images form the
backup and you can copy this disk images
over attach it to another set of
machines and then you can restore the
cluster instantaneously so in this
picture there's a cluster one with a set
of FDB processes the gray boxes
represents the FDB processes some of
them a persistent data some of them
don't have persistent data and when you
issue a snapshot command which we
introduced as part of this feature it
creates a copy of the disk images the
blue storage boxes that popped out or
the snapshot disk images that we that
came out of after as part of the
snapshot operation these blue disk
images if you care and get a copy of
them those are the backup and the
cluster - it's like a vanilla cluster
which with no disk images attached to it
you can copy this disks over there and
attach to it
and you can bring up the cluster of
course you need to modify the FDB dot
cluster and phone division in DB dot
convict cetera a little bit of tooling
is necessary but the restores are pretty
much instantaneous for this feature to
work you need either a snapshot double
file system or a snapshot double block
storage so this is pretty much the text
of what I explained in the previous
slide so I'll just skip this so how does
f DB create a consistent snapshot across
the f DB cluster for that let us go
through the flow of the snapshot create
operation
so this is a standard of difficult
architecture and there are really three
persistence data three sets of
persistent data in the cluster the
coordinator which stores the information
about where the master is or the tea
logs etcetera and the transaction logs
which keeps the mutations and the
storage servers that keep the in storage
of all the key values its previous
because I've already gone through this
so the client initially sends a request
to snap the coordinators to the proxy
which gets forwarded to the coordinators
the coordinators when they see this
request they go on snapshot their own
file system or block storage based on
the configuration so basically the blue
boxes that emerged out of the snapshot
dead disk images of this coordinator
once that is complete the client sends a
snap create command to snap the tea logs
in the storage this snap create is
nothing but a specialized a transaction
except that it is different in two ways
that this snap create command goes to
every T log and every storage server in
the system
the second way it is different is that
venti logs and storage see this special
command they respond by creating a
snapshot of their disks or the file
system so in this picture you see the
request goes to the T log and it creates
a snap of their disk images and then it
sends the success to the client and
shortly after the storage is pulled the
snap create and they snapshot themselves
so now this all this blue disk image is
put together make the snapshot and you
can bring it back as further restore
since the snap create is a transaction
that is a version attached to it and the
storage T log all of them will execute
the snap create at the exactly the same
version of the database that gives a
point in time consistent image of all
the disk images in the system now the
three parts to this the snap create is
very cheap we saw that it is as cheap as
transacting a key value to the database
the second is copying of the disk images
this does take some resources but it is
significantly cheaper to copy the disk
images at the lowest level at the file
system or disk level rather go through
the entire FDB stack and this can be
highly paralyzed and which will reduce
the impact on the foreground and the
user workload on top of this many cloud
providers give you an option to snapshot
the disk images block storage and have
it have a copy of it available without
you spending any additional resources
from the production cluster and the
restores are instantaneous because you
have the disk images you just attach to
your line any machine set of missions
and it is as much as the cost is like
recovering a cluster the disadvantages
are dependency on snapshot double file
system and second it's somewhat the
production and the backup cluster has to
be somewhat homogeneous now I'll switch
over to the demo
then was it this is instant back up
really so what I'm going to I have a
cluster one which is you know I'm going
to start a workload on this and I'm
going to watch the the workload to make
sure that the transactions are starting
there is a thing that says three Dre
transaction rates etcetera so now I see
the transactions are progressing how I
switch over I'll start a CLI and I will
create a snapshot this response with the
UID which basically is all the disk
images are tagged with this particular
UID and then I invoke a cluster copy on
this one with that UID which copies this
disk images okay to the cluster two as
it is copying this workload is self
describing we can validate this data on
the second cluster where any script now
I'm going to there is nothing to do here
because the disk images have been copied
I'm just going to start the cluster here
okay and I'm going to watch for the
cluster to come up okay
this takes few tens of seconds and so
the workload is self-describing so we
can make sure it is it's a cyclic
workload for the FDB developers that
this the set of key values make a cycle
and you can verify that the database is
the integrity is still there so once it
turns healthy I'm going to run a quick
okay it's taking it's on time okay
it turned now I do a quick get range and
then I close to verify which will take a
while so I'll leave it there and the
integrity of the database gets verified
so that's the conclusion of my talk and
we are excited that to have an
alternative backup implementation for
the f DB operators to leverage okay
thank you Center
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> G3buaA7yw8o </VID>
<CONTENT>
hello everyone so I'm Marcus from
snowflake computing part of the FTP
engineering team and this is David and
we are here to talk a bit about high
availability within FTB so this is the
outline of this talk
first time on a motivate our work and
why we chose the architecture that the
architecture that we implemented then I
will do a small detour and talk about
building distributed systems in general
and after that David will take over and
he will talk about the snow cannon
architecture and how it is implemented
and how it works so snowflake uses
foundation DBS and integrals is a part
of the system it's it's the whole file
system if foundation DB goes down in
reach and our service goes down so we
came up with a list of requirements that
we have for a high availability slash
disaster recovery solution the first one
and the most important one by far is we
never want to lose data data loss means
we lose customer data in if we lose
foundation DB data we want to have the
possibility to have something like a
standby and be able sorry to to failover
to the standby and then also have the
possibility to fail back the reason for
that is usually your data doesn't when
you lose an F DB loss usually we usually
don't lose it completely it's more like
it's performance degrades for networking
issues losing machines these kind of
things and if we can fail over to a
secondary but don't have to throw away
the old primary if we can fix that old
primary and have a vulnerable secondary
again for free basically we also want to
have multiple secondaries
we're dead paranoid
we won't have the possibility to shut
down secondaries to do something like
software upgrades go to other machines
these kind of things and we want to have
terabytes potentially of mutations of
changes to our FDB storage in on disk
safely stored we will see a bit later
how that is useful and it should be as
highly available as possible correctness
is more important than availability but
it still we want to optimize for that as
much as we can get away with so the
first solution that FTB implemented in
that space was backups and that is what
we started running with however backups
are not free so what you see here is one
of our production cluster and this is
the sum of all these corporations
executed over time and the red areas is
where we are running a backup process so
sadly this scale doesn't start at zero
but what you can see is that roughly the
number of write operations - like the
number of disk operations doubles as
soon as you are running a backup this
got better with have to be 6 but it's
still the cost is still there and this
costs finally is also part of the
disaster recovery solution within within
FDB because that one depends on like
builds on top of the backup mechanism so
this is the comparison of all the
solutions that are available snow snow
cannon the thing that we built isn't yet
a open source but we're in the process
of doing that so you will hopefully
rather sooner than later be able to
deploy that as well if you choose to
keep in mind that this comparison here
is highly skewed to our requirements so
you could come up with all the points
where you would see more crosses that
there's no kind of thingy and more takes
at auto solutions
but basically what snow cannon gives us
is the the main drawback that it has is
that commit latency will go up slightly
by like depending on how you deploy the
whole thing but at the same time it it
doesn't increase load on primary we can
we can recover a backup and replay snow
cannon logs and get back in your cluster
without having any data loss we can
switch over and back these kind of
things the way we implemented this and
this is very high-level David will go a
bit more into detail is we built
basically I felt a second system called
snow cannon which is a full cluster and
it basically implements a distributed
queuing system think of it as something
like Kafka the main FDB cluster will
then stream synchronously all these all
its transaction that it executes all the
mutations of detron days transactions -
snow cannon snow cannon will persist
this - this and it will then a
synchronously push it to a secondary
cluster or even a third or fourth one
however many of those you want to have
and because of the asynchronous nature
on the second power of it you can like
bring down the other cluster for
maintenance - upgrades these kind of
things so now this d2 when we saw it
with this project the very first part of
the code was actually the idea was to
build a new distributed system we built
this unit system this before but if you
if you build a distributed system you
have to think about failure scenarios
and how you are going to fix those in in
during run time right you can have
machines or failing processes or failing
disks all failing you can have network
partitions you cannot differentiate
between network petitionary partitions
and machine failures you can have
message reordering on the wire and to
make your life even more miserable these
things will happen at the same time
because of that you need to have a good
testing story
and this is a difficult thing and if I
would have to say what is the best thing
about Foundation TV I would say it's the
testing story so if you think about
foundation TV you can either say this is
a database or a distributed key-value
store or you can say it is a distributed
system that implements several kind of
services within that system it starts
like tea logs and masters and resolvers
and these things and clues everything
together so instead of building a lay on
top of that what you can also do is you
can take this thing as a framework and
just implement your own service on it
and the amount of code you need to
change is surprisingly small if you want
to do that it is actually so small that
I managed to put it on four slides and
that is exactly what I did so the first
step was to add a new machine clause we
basically need to teach foundation DB we
now have this new service in this
example called snow cannon which is have
a puing system in the next step we need
to tell the cluster controller the guy
who's responsible to to recruit new
rules that this thing exists
so we basically add a new API call to
that the way of then actually serving
the API call is pretty much some
copy-paste it's like three lines of code
then workers which is basically the main
role that every process executes needs
to be able to start that rule and now
that you can can can see here is
basically this is the code that actually
executes then a snow cannons of one of
these special processes and then we need
something that orchestrates everything
and here we healthy FDB cloth always has
one master server orchestrating as no
can is pretty cheap so why not do it
there you could make an auto decision
this was ours so whenever the master
finishes a recovery it will simply it
will simply stall up this track and we
are done
so this means that using FDB as a base
for this simulit system makes your life
much much easier and I want to educate a
lot for that
and I wanna again say like the simulator
and the testing stuff is awesome and
will make your life so much easier being
able to run civil is a serializable
transaction within your services
stenches the icing on the cake thanks
Marcus so now that we've talked a little
bit about snowflakes requirements for
its metadata and sort of our motivation
behind making this thing I want to go in
a little bit into the architecture
behind snow cannon what is snow cannon
it is a multi cluster replication
solution built on top of FDB the
producer cluster pushes data
synchronously to the snow cannon cluster
which then buffers it together and
batches it and pushes it asynchronously
to the consumer cluster your consumer
can act as a standby the snow cannon
cluster is responsible for maintaining
your replication factor for making sure
that your failover is managed correctly
and for making sure that the clients
know which cluster to currently talk to
let's go into a little bit more detail
the first thing that has to happen is
that the client needs to query the snow
cannon for the for the current producer
the snow cannon acts as a client proxy
and gives the interface for the current
producer to the clients the clients can
now begin pushing data to FDB the proxy
on the producer will simultaneously push
transactions to both its own T log
system and to the snow cannon log system
a transaction is not acknowledged as
complete or committed unless it is on
all of the T log replicas and a majority
of our snow cannon logs the snow cannons
will buffer up this data and a
replicator actor will read from one of
the snow cannons batch the transactions
together and push them asynchronously to
the consumer the consumer cluster is in
a read-only state which was some state
we added to the metadata store to ensure
that the consumer doesn't accept
any transactions except from the snow
cannon we wanted a dr solution full
backup/restore
that could work across availability
zones or data centers with minimal
impact to the customer and with zero
data loss this is a tall order and in
order to do this we implemented snow
cannon to give us the best of both
worlds the synchronous push to the snow
cannons ensures that we have zero data
loss even when we're restoring a backup
the snow cannons were also implemented
to be very simple
there are append-only logs that write
directly to disk this means that our
rights are very cheap and it means that
usually they outperform the t logs which
in turn means that we can get our
replication factor without any
additional impact or latency to the
commit time the snow cannons can also
give you data center fault tolerance
without having to deploy the t logs or
the nodes in your cluster across
different data centers which can cause a
lot of extra latencies and some
performance degradation you only have to
deploy the snow cannons across different
data centers now for just a single
this-this-this essentially gives you the
same guarantees with only a single hop
across data centers to your commit time
now your producer cluster could go down
due to some terrible disaster and you
can bring up your consumer in a
different data center replay the snow
cannon log in that same data center and
begin again with zero data loss right
where you were before the snow cannons
pushing asynchronously to the consumer
also grants us a couple of interesting
benefits we designed the snow cannon to
be able to buffer the data indefinitely
which means that the consumer could go
down or become unresponsive for hours at
a time without any impact to our
customer workload this means that if we
want to take backups as Marcus was
showing it could take and it has a huge
impact to customer workload it won't
impact customer workload at all because
we can do it on our backup on our
standby cluster it also means we can
have multiple consumers so we could have
one running as a standby
we can have multiple consumers running
backups at the same time and you can
even have a consumer running test code
with actual production level traffic so
in order to test your code we also
implemented snow cannon to work on a
quorum based logic usually the proxy has
to commit to all of the T log replicas
before committing its transaction but it
need only commit to a majority of snow
cannons before we commit this means that
we're more fault that we're fault
tolerant in the face of node failure we
can lose a snow cannon we can recruit a
new stupid cannon and we can repair
holes all while the data continues
unhindered to be replicated to the to
the consumer one of the biggest benefits
of our architecture is the ability to to
switch over to a hot standby cluster
let's say that your clusters performance
has become degraded due to the B trees
being fragmented something it snowflakes
see a lot because of our turn or perhaps
there's just a network partitioning or
some sort of network degradation or
maybe you just want to do a major
version code upgrade without bringing
your whole cluster down the snow cannon
switch can handle all this for you
here's the overview again for the
standby to come up as your primary
cluster it must first have all of the
data that's currently on your producer
for this to happen we must block new
transactions to the current producer we
do this by setting it to read-only and
this means that new transactions from
the clients will simply air out and
retry now the snow cannons are free to
finish pushing its data to the consumer
a standby consumer is only five seconds
behind the producer and because of
batching the the push of the remaining
data to the standby is an extremely fast
operation not more than a few seconds we
call this the flush
once we've completed the flush and all
of the data on the snow Canada's is now
in the consumer we can bring this
cluster up as our primary we can set it
to read right and it can now handle new
transactions but before this can happen
the clients must be aware that the
switch happened as well so the snow can
is need to inform all of the clients
about the switch about the new cluster
interface and tell all the clients to
invalidate their key location caches and
watches etc so that now they can begin
again with the new cluster and voila the
switch is complete we're now serving
data on our primary and we're free to do
whatever maintenance required on the on
the on the original cluster and this
which only took on the order of seconds
or faster because the the right
transactions need only wait for the last
five seconds of data to be batched and
pushed to the standby cluster I also
wanted to talk briefly about the
challenges we faced in getting the
producer cluster recovery to work when a
node goes down and the cluster on your
producer cluster needs to recover we
face some interesting challenges because
now the proxy is pushing simultaneously
to two completely separate log systems
so it could be that your tea logs are
ahead of your snow cannons or the snow
cannons are ahead of the tea logs or
some combination of both it is up to the
producer to coordinate the recovery and
make sure that both log systems will
begin again at the same point of data so
the first thing that happens is the
master the master that the new master in
the cluster must choose a point in data
to begin the recovery on this is the
maximum version that's found on all of
the old log T log replicas it takes the
max as Evan said because the transaction
is only committed if it's on all of the
replicas in this case this is version
400 it now recruits the new T logs tells
them to recover from version 400 it must
also tell any behind snow cannons to
recover at this version so this means
that if there's a
snow cannon in this case we have one at
version 300 it must also stream from the
old log system until it contains the
last epoch end and we call this the last
epoch end version once the all the snow
cannons and the the new T log system
contained the last epoch end version the
producer can continue its recovery it
does this by sending a recovery
transaction to its log system and to the
snow cannon logs this works as any other
transaction does except it also pushes
the version up by a hundred million it
does this in order to make sure that the
old log system and the snow cannons
don't serve any data from old proxies it
could be that there's a proxy from the
old cluster that due to network
partitioning or some other reason is not
aware that it's from a old generation of
cluster but before that this recovery
transaction has to be a blocking call
for the snow cannon because it could
also be that the snow cannon is ahead of
this version so when the snow cannon
receives a recovery transaction it must
first roll back to the last epoch end
version and then it can apply the
recovery transaction now both the log
systems are synchronized and can begin
in the new epoch at the same version
there are plenty of other challenges
that we had to face in order to in order
to meet all the requirements that
snowflake had for backing up and having
disaster recovery for its metadata store
and a lot of interesting problems that
we had to solve but this is all we had
time for and we'd like to take any
questions either offline or now if there
are any I don't think there's time for
questions now but feel free to ask us
afterwards
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> rQM_ZPZy8Ck </VID>
<CONTENT>
okay hi my name is Ted Wilmes I work for
a company called expiry we're a
consulting company I specifically do a
lot of graph database work so that's why
I'm talking about Janis graph today I'm
active member of a Patchi tinkerer pop
and the Janice graph communities and
over the last few months have gotten to
know a little bit more about and use a
foundation dB
so today I'm going to talk about graph
databases in general just briefly to
give people an introduction to what the
state of the graph database world is
then we'll talk about Janus graph how it
currently runs on a number of different
storage backends and then what it looks
like on top of foundation DB then I'll
talk a little bit about what it took to
put together an adapter to actually run
Janus graph on foundation DB and then if
there's time at the end we'll talk a
little bit about performance so first of
all today I'm going to talk about graph
databases specifically the property
graph data model so you may have heard
of triple stores and RDF and things like
that but I'm gonna be talking about
property graphs property graphs have a
basic idea where you have vertices and
edges both vertices and edges can have
labels and then they can have properties
just properties being key value pairs so
pretty simple model here so what do
people actually use graph databases for
so there's of course as you would
probably imagine there's kind of the
canonical graph database examples of
social network analysis and things like
that but we're finding lots of customers
are also just wanting to use graph
databases for you know other sorts of
industry use cases here's just an
example simple data model from a supply
chain use case usually it's pretty easy
to see graphs and your existing in your
existing data sets that you're using
whether or not it's a good idea to use a
graph database or not it's usually more
of an operational question but here we
have a bill of materials graph and that
has some connection into your supply
chain where you have a network of
suppliers you can use that to look at
things like hey what happens if a
distribute disruption happens here at a
particular distributor another area
where I've spent a lot of time is got
started in graphs is actually in the IOT
space here's just a simple little graph
of maybe some infrastructure that you
might be monitoring specifically I
worked in oil and gas so we would look
at equipment out in the field and how
that equipment was connected and then
coupled that up with time series data so
it gives you kind of a high-level
contextual view of the system that's
laid out in addition to those time
series data that you're actually getting
so the graph world right now is kind of
exploding so there's lots of different
different vendors that are coming into
the space and the one that I'm going to
talk about today is specifically the
Janus craft project you all may have
heard of Titan before I think I don't
know if the person here is did it but
there actually was somebody wrote a
Titan adapter anyway for okay for
Foundation DB I thought so maybe and so
Janus graph is a fork of Titan Janus
graph is hosted at the Linux Foundation
Apache tinkerer pop is a graph
processing framework that Janus graph
actually makes use of in the graph space
right now there's a few different
languages that are common the two most
common are ciphers that's neo4j slang
guack and then also gremlin which is
part of the Apache tinkerer pop stack so
the Apache tinker pop stack gives some
basic graph query and language
capabilities a web server to contact it
and drivers and also some analytical
processing tools for running graph
algorithms over OLAP systems like spark
so the gremlin query language won't go
into a ton of detail this is just
supposed to be kind of a pointer if you
get interested in this later but a
gremlin query language is is a graphic
learning language that allows you to do
anything from analytical type queries to
just regular old OLTP type queries
mutations and reads so the Janus graph
architecture from the very beginning
when Janus graph was originally titin
years and years ago it was built from
the beginning to actually abstract out
the storage layer so Janus graph doesn't
actually store any data itself it's a
layer that actually
on top of another storage back-end
that's why it made it particularly easy
to put foundation DB in underneath of it
so traditionally folks have run Janus
graph probably mostly on Cassandra and
then I'd say a little bit further second
from that HBase but there's also a
number of different other adapters that
folks have developed over the years
Janus graph also can integrate with
third-party indexing tools so there's a
lot of benefits to running and this
layered approach but there can be some
challenges especially when you're
running on top of these eventually
consistent backends so what is the Janus
graph on foundation DB value proposition
so when foundation DB got open source I
was I was really excited because the
thing that Janus graph really was
missing was a distributed highly
available acid storage option so there
just wasn't anything out there you could
run it on a single instance with
Berkeley DB you can probably play Oracle
to give you you know highly available
Berkeley DB but I'm not sure of anybody
doing that so this was this was really
good news so one on the face of it you
know we get high availability and fault
tolerance acid transactions are a huge
win overall I think that pays off with
simplified operations and developer
experience and then also there's just a
lot of things internal to Janus graph
right now that have had to to be done to
get over the fact that a lot of times
it's running on these distributed
eventually consistent stores there's
sorts of bespoke locking recipes and
things like that things that maybe the
end users don't directly see but really
affect their usage of the system so
right now apache tinker pop and Janus
graph take kind of a generic a
high-level approach to transactions and
they say okay we have this thing called
the transaction but in and of itself it
doesn't actually give you any specific
sort of guarantees those guarantees are
gonna be inherited from the back-end
storage layer that you're actually
putting underneath of it so syntax
doesn't really matter here but you can
start explicit transactions do multiple
queries and then at the end you know
commit your transaction or rollback and
then whether or not you have any sort of
acid or something
or any consistency that depends on the
engine underneath it so why might acid
matter in a graph database so I'm gonna
tell a little story the parable the edge
to know where so here we go we're going
to just start with two vertices and B
vertex and so let's say user one here
looks up the vertex a and they look up
vertex B then another user comes in and
in the meantime while this first
transaction still open pretty
straightforward but they drop one of
those vertices then I go and I say okay
let's go add an edge between these two
things let's say you know Ted knows Tom
and then commits that well if you're
running this on Cassandra what's going
to happen is you're going to get what we
call kind of like this phantom edge this
edge to nowhere and so you go back I run
a little query on my graph again I say
hey how many people does you know vertex
a now and it says oh yeah he knows one
person he doesn't really know one person
though in reality but the database
thinks he does so this is the equivalent
of if you couldn't trust you know a
foreign key constraint in your
relational database so that's no good
there's things that are built into Janis
graph to try to lessen the chance of
this happen happening on a eventually
consistent back in but they're not
foolproof so this is something ideally
that we want to push down into a system
that is actually just purpose-built and
can handle that without any issues some
other operation the rely on consistency
Janis graph vertices have IDs ID block
allocation of course when you're running
that in a distributed system you want to
make sure two different you know
vertices that you don't want them to end
up with the same ID this is also
problematic from just ID allocation from
a performance standpoint schema changes
having agreement this goes back to kind
of metadata like we discussed earlier if
you're making changes to your graph
schema and a cluster you need to rely on
consistency their unique index
constraints and then lastly Janus allows
you to plug in third-party search index
things so now you're storing data and
say Cassandra and elasticsearch ideally
those things would stay in sync but
sometimes they don't
so Janice Graff like I said has a few
tools internal to it there's even a nice
warning in there that if anybody reads
the documentation it basically says this
works most of the time probably but
cross your fingers so obviously there's
a lot of room for improvement here so
right now the options for the developer
it's really just largely you know it's
left up to the developer you need to do
things at the application level to just
kind of plan ahead and and assume from
the beginning that you're not going to
get these sorts of guarantees and it's
just it's extra complication and and
frankly it's something that people just
they miss so and I can't blame them I've
done it before so the foundation DB
storage adapter so building a new
adapter for Janice Graf is fairly
straightforward partially because
there's a lot of examples already in
place already so I won't go into detail
and all these bullets but there's a
little recipe if you you want to build
your own Janice craft storage adapter
the data model for Janice graph itself
was initially built upon basically kind
of this generic BigTable model and so we
have here is vertex and edge data is
stored in adjacency list format so we
have a vertex ID then its properties for
that vertex are stored and then that
vertices inbound and outbound edges are
stored so one of the nice things about
foundation DB and also just about
Cassandra in general is in a graph
database there's not many opportunities
for sequential reads so the ability to
sweat slice queries on the edges is nice
from a performance standpoint so if we
were to map this to Cassander if you
used Cassandra before your partition key
would be the vertex ID and then your
rows are going to be sorted on the
clustering keys right now this data is
just stored is you know serialized byte
arrays so if you were to look at it and
you know cql you want to be able to read
it so how do we map this then to
foundation DB this is not really that
much different than the than the
documental air example we're basically
going to use a combination of the
directory layer and then
the tuple support and so our keys are
going to look like this if in Cassandra
we had a you know a key space that
stored graph for a customer a and in a
key space for customer B here we're
going to have our key is going to be
prefixed with the graph and then within
that graph there's different sorts of if
you want to think about it table terms
so there's table that stores vertex and
edge data one that stores index data one
that stores schema data and so then
we'll break it out a little further and
then finally we get down to the actual
key for that vertex and then whether it
be a property in or an edge and then the
value is just simply that byte array
that we want to pull back which is
storing maybe property value information
so if we stretch that out a little bit
here you can see from the first example
basically how that's mapped so obviously
here's something like prefix compression
will be something that'll really help us
out so I use the Berkeley DB adapter as
inspiration for this particular adapter
there's a host of different methods that
you basically go in and implement and
then there's a number of tests that you
can use as inspiration however I like
that
autonomous testing idea I think we could
probably use that so we took those
Berkeley DB tests and adapted them then
for the foundation you'd be adapter so
now if we go back to our example over
visiting this edge to nowhere case you
don't really need to read this but this
is the one time I'm excited to see an
exception basically we did that first
operation again but now we're running
his foundation DB and look we don't
corrupt our graph we're actually going
to get this exception because there was
a conflict when we went to commit
because that vertex was deleted so
future work I think future work there's
a lot of potential here so one thing is
and maybe this will be overcome by
events because of the improved support
for transactions but initially the the
current adapter
could use some improvements in the area
where it's extending transactions past
five seconds so right now you can do
reads past five seconds in the current
adapter it doesn't of course maintain
the same consistency guarantees as it is
it what if it was in a single
transaction but I think it sounds like
with the Redwoods storage engine we may
be able to just kind of pull that out
and hopefully just make use of that
storage engine for longer reader or size
limits for our for our queries the other
thing like I mentioned I think the one
of the biggest wins here is the custom
foundation DB implementations of Janus
graph internal pieces so the ID
allocation other sorts of invariants
that we're trying to maintain within
Janus graph I think that Janus graph
code can be greatly reduced and
simplified if we can make use of
foundation DB for that I think another
thing is and now there's certain use
cases for us where it would be helpful
to have some sort of hybrid storage
model right now we store data and kind
of a graph equivalent of this of a row
row oriented format I think in certain
cases it would be nice to store say more
of the historical adjacency list data
and a column oriented format so to do
that online it would be nice if the data
based on the backend could be moving
data from row 2 column oriented format
but to do that we need to have that
consistency we don't want to say start
moving some data and then I'll miss out
a write happened here or something like
that so I think that'll greatly simplify
that sort of thing the other thing that
I started looking at but isn't in the
listen in the actual adaptor yet is
foundation DB like I think was discussed
earlier publishes information about the
locations of keys and so if we co-locate
our Janus graph layer with the
foundation DB nodes I think we can do
some intelligent query routing and
predicate push down that really isn't
happening in any of the layers right now
so that you know gives performance
improvements from from a client
perspective and then lastly it'd be
great to pull full text search in
so it's no longer another third-party
component that we need to keep in sync
so that'll be a larger thing to do but I
think getting full-text and geospatial
search pulled in maybe we could make use
of some of that sort of indexing work in
the document layer but that would be
great to use as inspiration for that so
if you are interested in graph databases
or want to try this out we have it up on
our github repo if you're unfamiliar
with how to use Janice graph Janice
graph site has pretty good documentation
tinker pop does too so you can get
started download Janice craft basically
and then install this foundation DB
adapter it's easy to get up and running
on one instance or if you want to stand
up more Foundation DB nodes you can do
that I should have said that the Janice
graph deployment model you can also
horizontally scale Janice graph itself
out too so you don't just have one
Janice graph instance but you can have
however many whether that be one-to-one
with the storage layer or not so okay so
I'm excited about the future of
foundation to be excited to have
something that kind of fit this need and
this this hole that we had in the Janice
graph stack and appreciate the
opportunity to speak to you
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> fFSPwJFXVlw </VID>
<CONTENT>
ah there we go thank you
sorry about that so yeah as Dave said my
name's will I worked at Foundation DB
way back in the ancient mists of time
and I'm now doing something a little bit
different I'm here to talk about the
future of software development what on
earth could I mean by that well as
somebody who is asked to give a
big-picture talk at a software
conference I believe I'm contractually
obligated to begin with a slide
depicting Moore's law and also my
pointer doesn't work okay there it is
Moore's law clearly you can see here
we've got years on the x-axis there and
we've got clock speed on the y-axis
right and as you can clearly see it's
going up and to the right kind of
exponentially and well hold on a second
you sure that's the did we get the right
slide is this is this the Moore's law is
that is that clock speed or is that is
that harddrive density or maybe oh my
goodness it's weaving and spinning
productivity that's I wasn't expecting
that that's that's really weird there
must have been some kind of mix-up okay
let's let's try this again okay oh yeah
yeah here we go
that's that's totally the Moore's Law
slide you've got that nice logarithmic
y-axis there you see that yeah that's uh
what it's steam engine efficiency what
what is going on here all right let's
let's try one more time okay all right
anybody want to guess what this one is
okay I'll give you a hint the x-axis
here is the actual years along which
Moore's Law actually did operate now all
right it's actually industrial diamonds
so why have I wasted your time with
three different graphs all of which are
not Moore's Law the reason is I think we
in the software industry or in the
computing industry more broadly have a
little bit of a tendency to think that
were special we think there were somehow
different from every other technological
endeavor that
mankind has engaged in and something
that people point out a lot is this
Moore's law thing people say where else
in human history has there ever been
this exponential increase in the
capabilities of the underlying hardware
of what we're doing and the answer as
I'm hope I've convinced you is actually
everywhere it's incredibly incredibly
common at first and the reason is that
exponential growth is really really easy
when what you have is really really
primitive and so the fact that we
observe this Moore's Law relationship
maybe still is actually not telling us
that software is special it's telling us
that software is early right it's
telling us that we're at the beginning
that we haven't trailed off yet into a
logistic curve which is what usually
happens in technology and I actually
find this fact to be incredibly
empowering right it means it means we we
get the chance to be pioneers too it
means those guys in the 60s and the 70s
didn't have all the fun it means there's
a lot more to do and I think one
implication of this is it also means
that we should be looking for the
possibilities of radical transformations
in software engineering right things
that will completely change how what it
means to be a software engineer what it
means to write programs there's a couple
reasons for this one is because we're
early in history and so therefore
there's still low-hanging fruit another
is that we're early in history and what
that means is that the vast majority of
software is not written yet it can be
written in the future which means that
if we make process improvements now they
have a very long time horizon over which
they can pay off I think both of those
facts argue in favor of us taking a
really serious and hard look and
re-examining what it is we do and so
that's meaning behind the title of my
talk the future of software engineering
I think the future is out there in front
of us we're not there yet but maybe
maybe we will help create it ok so right
so the future there's a lot of different
possible radical transformations I could
talk about right I could
about new programming languages and how
something from category theory is gonna
totally change how everybody does
everything might be true that would be a
radical transformation if it worked or I
could talk about the sociology and
economics of software how who becomes a
software engineer might be changing
drastically that could be a radical
transformation of the software industry
but I'm talking not going to talk about
either of those things instead I'm gonna
talk about testing yeah right because
why because if you want to look for the
potential for radical transformations
one way of doing that one pretty good
heuristic is to look at where things are
currently the most absolutely awful and
terrible and painstaking and brutal and
I think testing kind of qualifies right
I saw a report from some analysts it was
like Gartner forced or somebody they
estimated that 30% of all effort in
software development was spent on
testing or on QA more broadly and if
you're like me you hear that number and
you're like thirty percent that's way
way way too low right well I guess like
you add together the amount of time you
spend writing tests the amount of time
you spend fixing the bugs that your
tests turn up the amount of time you
spend fixing the bugs your tests don't
turn up the amount of time you spend
working around and dealing with and
mitigating all the bugs in the layers
below you that they haven't fixed those
jerks all the time and effort that goes
into dealing with the fallout of
inadequate testing the outages the
economic damage right like that's like
we're talking at least 50% of my time
and I don't think I'm extremely unusual
and you multiply that by a lot of
software engineers in the world we are
talking about trillions and trillions of
dollars of productivity going into this
if you could take that and you could
eliminate it or make it much more
efficient much smaller fraction of what
we do that would be a radical
transformation of the software industry
and so the reason that I'm giving this
talk at this particular conference is as
I think people are generally aware
foundation DB had a different
relationship with testing than many
products did testing for us was not an
ordeal it did not suck up in vast
quantities of developer energy so I'm
not actually gonna dive into this a
whole lot both because I think a lot of
people here already know how foundation
DB did testing Evan and Ben both covered
it and sort of gave you some information
about it instead what I'm gonna do is
I'm gonna try and take what we did at F
DB and recontextualize it I'm gonna try
and give you a different perspective on
it situate it as one technique within a
much broader class of approaches and you
know talk about why you should be using
them talk about why you might not be
using them talk about why no really you
actually should be using them and if I
have time then I will close with like
some slightly more speculative stuff
okay
but before I get to all that let's first
talk about why testing is so miserable
right now one reason that I think a lot
of people are very familiar with is that
your tests are usually non-deterministic
right as soon as your test relies on any
kind of external service or as soon as
you run it in a even slightly noisy
environment suddenly it fails one out of
every hundred times or one out of every
10,000 times
either way it's a nightmare it's a
maintainability nightmare
it's a nightmare when you actually go to
try and debug something you don't have
confidence as to whether you've actually
fixed it or not if the test does fail
you're awfully tempted to say well
that's that's a known flaky test right
you ignore it and then it turns out no
actually it really was a problem um I
think people are also generally familiar
with the way that the foundation DB team
made heroic efforts to clawback this
property in our testing using a
technique called deterministic
simulation Evan touched on that briefly
there's tons of material online about it
as Dave said I gave a talk about it
years ago you can go read about that so
I'm not gonna talk about
but all that said I think we in this
room should be aware that most of the
world does not have this right most of
the world is still in the dark ages
can't do this and it's an ongoing source
of pain and suffering and it's really
bad okay but there are more reasons that
testing is terrible
another reason testing is terrible is
that your tests are very very often
fragile what do I mean by that I mean
that your test comes to rely on
properties of your system that are
incidental in some way that are not the
ones that you thought you were testing
so a really simple example of this is
suppose you're trying to test a computer
game all right like a 2d platforming
game one way you might do that is by
recording an input right so you say if I
hold down the right arrow for 6.7
seconds and then I hit the jump key for
3.2 seconds and then I shoot the bad guy
you know assert that bla happens and
that's a great test until you change
literally anything at all about your
program right you change the level
layout you change the physics engine you
change the input sampling rate you run
that test on a different computer it's
probably gonna fail this is not like
some weirdness about testing computer
games either this happens in all kinds
of testing domains it happens in UI
testing frequently it happens in
distributed systems testing right like
imagine you're trying to like play
forward some series of events and
something changes towards the beginning
right the two tests histories are gonna
diverge and you're gonna be off testing
some totally different thing than you
thought you were right so this is a
really bad problem like like the flaky
problem it's a maintainability nightmare
like the flaky problem you're very very
tempted to ignore the test because of
this I heard about a post-mortem
recently of some giant outage at some
giant company that his name I shall not
mention we're literally the same
check-in that caused the bug that caused
the giant outage
also disabled the test that would have
told them that they were about to have a
giant outage why because everybody knew
that test breaks every time you check
something in so I course right that's
really bad
even more insidious failure mode for
this by the way is sometimes your test
can fail open in the sense that you make
some change your test continues to pass
but it's now passing for a totally
different reason than you thought it was
passing right and so now it's a source
of false confidence and you yeah it's
it's really really bad and I don't think
people have a great answer to this
problem
okay but there's there's an even worse
one which is even if you somehow make
your test neither flaky nor fragile it's
probably not testing the right stuff I
think there's actually a really like a
deep reason behind this almost like an
analytic proof okay so it goes something
like this
the reason that people write tests is
because human beings are astonishingly
bad at thinking through all the possible
branches of control flow that a program
could take right we're astonishingly bad
at thinking through all the possible
orders in which two threads could
interleave or some other asynchronous
construct could interleave we're
astonishingly bad at thinking through
all the possible points in the execution
of a distributed algorithm we're a
failure might occur and what form that
failure might take but that very fact
right that's why we need tests but that
very fact means that we're unable to
write tests to cover all the things that
we actually need to cover right like
because if we could if we were smart
enough or had the right kind of brains
to write all the tests we needed to
write then we would have just written
the code correctly in the first place
right and so I think this is like really
scary and really true and the
implication is that tests can be useful
for turning up regressions but almost
completely useless for telling you about
unknown unknowns that's that's bad right
the latter is I think the more important
problem it's certainly the harder
problem and people try and fight against
this in a bunch of different ways people
people try and use coverage metrics to
fight against this which i think is a
nice idea but ultimately kind of useless
to like you know your distributed
systems people imagine that you have a
distributed system and your test suite
gives you 100% branch coverage
on it are you sure your system has no
bugs yeah obviously not right you could
have a bug that depended on whether some
code executed on process a before or
after it executes on process B you'd
have 100% branch coverage either way
this is not like a distributed systems
thing either right like imagine you were
writing a Python interpreter and you get
100% branch coverage have you tested all
the interesting behavior and that Python
interpreter no Python is a
turing-complete language there's an
infinite mountain of interesting
behavior that you could continue to
exercise so branch coverage is a nice
idea but it doesn't actually solve this
problem at all um okay I actually think
that all of these problems are just
symptoms of a deeper underlying problem
the real problem and the real problem is
that testing is still totally manual
right what we call automated testing is
not automated in the slightest we've
automated the absolute dumbest part of
it which is executing the tests and
running them automated testing to most
people means having Jenkins run your
tests and you know that's that's nice
that's certainly better than not doing
that right having sitting there and like
typing who does that actually tons of
industries do that so yeah good good
start but still we have every one of
those tests is painstakingly manually
constructed by a human being in the
first place imagine if this were any
other industry right magic if I told you
that there's an industry out there where
you know scads of highly paid
intelligent people are sitting doing
mind-numbing rote repetitive predictable
tasks with with no automation right what
would you say what would your VC say
they would say that's an industry that's
ripe for disruption and you know welcome
ladies and gentlemen to software
engineering right for a disruption and I
think this is the real secret sauce
behind what foundation DB did it's not
so much just the deterministic
simulation although that was a very
important part of it it was that we
didn't go down this path
it's that whenever we had a new piece of
functionality we didn't say how can I
write some tests to cover this it was
more like how can I write a system that
will forever be generating new and
interesting tests that will exercise
this it's like it's a different it's a
shift of mindset it's a shift of
philosophy and it's such a big change
that I think it needs a new name and so
for the rest of this talk I'm gonna talk
about automated creation of tests in
addition to merely automated execution
of tests as autonomous testing which i
think is a is a better word for the
stuff and foundation DB is not like
totally special right if you know where
to look if you squint at the industry
you can see glimmerings of autonomous
testing everywhere actually a really
simple example is just fuzzing suppose
you're writing a parser that's parsing
some untrusted bytes from the network do
you sit there and say well I better
write some unit tests for this know like
if that's all you do your parser sucks I
assure you it's wrong like what you do
is you get a fuzzer to feed millions and
millions and millions of random strings
of input into it and see if any of them
cause it to crash
that's autonomous testing it's a
primitive form of autonomous testing
property based testing is an example
from a totally different side of the
software industry right this is signing
the functional programming people came
up with it's something that the Haskell
people I think came up with the idea
here is if you have a piece of your
program or a data structure or something
with a very easy to specify interface
what you can do is construct a
specification of its contract and its
guarantees and then you tell the
computer to sit there and try and come
up with counter examples to that
contract this is a form of autonomous
testing this is actually something that
was exhaustively used in the testing of
the foundation DB document layer which
as you heard was just open source Thank
You Apple right so like the like it's
not like at foundation DB we just had
one magical tool the simulation stuff
and we like hit everything with it it's
that everybody every engineer was
constantly there was a culture of
constantly thinking about how to take
testing problems and make them less
human involved and so the question that
I've been grappling with in my career
since leaving foundation DB is why
doesn't everybody do this all the time
right because I've seen how good things
are when you do it this way and I've
also seen but I'm prohibited by NDA from
telling you about how bad things can get
when you don't do it this way the answer
is really bad by the way so like so
serious like why isn't everybody in the
universe using this stuff it's like it's
a real conundrum and it turns out that
there are actually some really really
good reasons why people don't do this
stuff but before I tell you about the
good reasons I'm gonna tell you about a
really bad reason which is I hear this
with surprising regularity that the
turing halting theorem proves that
software can never test software yeah
that's right and you know it's it's it's
kind of true you can come to me and be
like will if your program can find bugs
then surely I can write a program which
will crash if and only if the Riemann
hypothesis is true and then in order to
tell me if it has a bug your program has
to solve all of math are you saying you
can do that and like you know fine like
that's that's true but that's correct
but to me this has a little bit of the
feel of people who say that the cap
theorem means you can't write a good
distributed database right it's like
it's like kind of an almost trivial
impossibility result which nevertheless
doesn't actually address the issue right
humans debug software humans are not
mystical Turing Oracle's like if humans
can do it then so can computers we just
and we don't need to be perfect right we
don't need to find every single bug in
every single program that could ever be
written which indeed the turing theorem
says you can't do all we have to do is
be better than humans or faster than
humans or more scalable than humans or
you know different from humans so i
think i think this is a dumb objection
that said i think it's actually really
closely tied to a smart objection
the same as maybe arguably true of the
cap theorem and the smart objection that
this is tied to is that it's insanely
difficult and that I think is true an
easy way to sort of think about how
difficult it is is just to imagine the
size of the space you're trying to
explore right so when you're trying to
find a bug in a program you are
implicitly trying to explore the space
of all possible execution histories your
program could have the size of that
space is 256 raised to the power of the
number of bytes of input your program
has ever received that is a mind
bogglingly large space that is
inconceivably vast right you could you
could stumble around in some tiny stupid
corner of that space for the entire
lifetime of the universe and never find
anything and yet I'm up here saying that
you can hit most of the interesting
parts of that space in a very small
amount of time how on earth can we do
that the answer is that's insanely
insanely hard and it's a challenge that
people trying to use autonomous testing
I think frequently like get shipwrecked
on an foundation DB we put an insane
amount of effort I should really say
Evan put an insane amount of effort into
into fighting this exact problem right
tweaking and tuning all the knobs bugga
fiying things to turn up bugs more often
tweaking the random number generators so
that you have processes crashing just
often enough to turn up interesting
behavior but not so often that you never
make any progress this is a this is a
really hard thing to do
it takes somebody with deep knowledge of
the system to do it it it's like it's
really draining and tough work and if
you get it wrong the failure mode is
your tests say everything's good
that's a really really scary failure
mode right you need some kind of side
channel to tell you that no actually
everything is not good hopefully that
side channel is not your customers so so
I think that's super scary the next
thing is like also super super scary and
I think it's probably an even bigger
barrier to adoption so all of the
autonomous testing techniques
listed and other ones besides which I
haven't listed all depend in some way
they're all a little different but in
some way they all depend on your
software being in the right form for
them to test them and you can think of
the whole foundation DB deterministic
simulation system as having the job of
wrangling a big hairy stateful
distributed system into that form right
like taking it and turning it into a box
that took an input which was a random
seed like pretending it was a pure
function so that we could do that kind
of thing the only reason that wasn't a
complete and utter debacle was that
foundation DB was constructed with
tremendous tremendous foresight to
enable that most people can't do that I
mean start with the fact that most
people aren't writing software from
scratch right most people are working on
some ginormous java monstrosity from the
1990s even the people though who are
writing something from scratch rarely
have the foresight to say oh we're gonna
write a distributed database first we're
gonna spend a year writing a simulator
like who does that that takes that takes
a special kind of person to do that like
and you know a lot of people even if
they did have the inclination to do that
just wouldn't have the time right they
they need code now not in a year not in
two years so I think this is this is
like a huge huge problem and so long as
it's almost impossible to apply these
techniques after the fact it's gonna
greatly limit their their use okay and
the last thing here is what I'm calling
test Oracle's which is just a fancy way
of saying that you're you know even if
your test like turns up all the bugs in
the world it's useless if it doesn't
know when to alert you that it's found a
bug depending on the domain this can be
either really really challenging or
really really easy if you only care that
your program doesn't crash good good
news it's pretty easy to tell when a
program is crashed it's pretty easy as
hell when it's run out of memory it's
pretty easy to tell when an assert has
fired say but suppose you were working
on a graphical application you know
suppose that bugs come in the form this
border was five pixels too far to the
right or the bug is the screen
turned purple right you might need a
much more sophisticated system to tell
you when you've actually found a bug
this happened with foundation db2 there
were a database invariants acid
invariance which were too complex to
check with a simple assert statement and
so what we had to do was design entire
workloads dedicated to setting up those
invariants and then checking that they
were true still at the end so again
depending on your domain that can be
that can be a real challenge ok but
despite all that you should all still be
using these techniques and you should
this is this is what you should be doing
and there's a bunch of reasons some
obvious some not so obvious so first and
most obviously computers are cheaper
than people you might have heard this
there especially cheaper than software
engineers in the San Francisco Bay Area
so when you have computers writing your
tests instead of people writing your
tests you can write many many many more
tests and you will get a whole lot more
testing done and that will probably be
good almost more important than that
though is not just that you're gonna do
more testing it's that you're gonna do
different testing sometimes when I talk
about this stuff people asked me will
are you saying that I should like throw
away my my my lovingly crafted test
suite and just use your crazy computer
thing no don't do that right keep keep
your test suite that will find certain
kinds of bugs and the computers will
find other kinds of bugs because
computers and humans like human like
weren't yet we're all you know unique
and special snowflakes and different and
that's wonderful but we're all humans a
computer is a total alien all that stuff
I said before about stuff humans are bad
at thinking about computers are really
good at thinking about that stuff right
so humans will find some bugs computers
will find others and this like beautiful
synthesis of man and machine will come
together and it's just it's awesome
another cool thing about computers is
you can turn them on and off very easily
in fact I hear that you can even go to
Amazon and ask for a computer for a
limited amount of time and they will
turn it on and off for you this is this
is really great this is again something
that's a little bit different from human
beings if you want to hire more test
engineers or
software engineers that takes time you
cannot hire and fire them
instantaneously they take time to be
trained they have to sleep they have to
eat it's so annoying computers are not
like that if you want to do a medium
amount of testing or a small amount of
testing all the time and then a really
really really large amount of testing
all at once you can do that very easily
using autonomous testing that said
despite that I actually think that
that's not as important as people think
it is because I think that most of you
should be doing way more testing all the
time then you think you should be doing
and the reason has to do with the last
of these reasons here which I think
might be the most subtle which is
latency and by that I don't mean the
latency to running a single test I mean
the latency to running enough tests that
you find a single bug the reason is that
the amount of effort it takes to fix a
bug is extremely strongly tied to how
long it's been since that bug was caused
I think we all get this intuitively but
just a hammer the point home right two
situations one of them you know you're
writing some code and you go hit submit
to your repo and some pre submit hook
runs and it says blah like you have a
book you can't submit that right now
that's great that's so awesome you have
all the state of the problems still in
your head you have a literal diff in
front of you right you know probably the
bug is in one of those lines of code
this is about your best possible case
for finding and fixing that bug compared
to situation number two where your
friend causes a bug and it slips through
your testing and then it slips through
your release testing it into a release
and then some time goes by and slips
into your next release and then six more
months go by and your friend quits and
then four more years go by and you're on
call and your largest production
customer calls you in the middle of the
night and says hey something's not
working what what do you do I mean like
you're doomed right like it's it's gonna
be so bad even if that were literally
the
right the amount of effort that will go
into even determining if there was a bug
in the second case is going to be orders
of magnitude larger than it would have
been to just fix it in the first place
but the good news about testing or at
least about autonomous testing is it's
an embarrassingly parallel problem you
can get a million CPU seconds of testing
done in one second or five seconds I'm
does law you know by running it on a
million different CPU cores that's
really cool it means if you're willing
to spend the money you can drive down
the latency between causing bugs and
fixing bugs and that is going to repay
you in money and productivity and
frustration and everything so fast it's
going to change your life it's going to
change it's it's gonna qualitatively
change the kinds of things your team can
do yeah okay so I'm gonna wrap up now
I'm running out of time and I want to
wrap up by returning to that question I
raised before which is why don't we have
computers test all our software I mean I
know I told you the reasons right there
there were a ton of like really terrible
reasons but but seriously what would it
take what would it take to change that
like how how can we bring about the kind
of epochal transformation analogous to
the invention of the compiler where only
in really weird or exceptional
situations do you go back to doing it
the old way and the answer is I don't
actually know the answer to that
question but I'm currently trying to
figure it out so Dave share over there
and I have recently started a company
and our goal is to try and figure out
the answer to this question and then
thereby making autonomous testing super
easy thereby making it universal thereby
radically transforming the software
industry thereby assuring in a new
golden age of peace and prosperity for
all mankind it's it's pretty early days
yet it's really early days but we have a
vision and we have a technical roadmap
that we think you know has a decent
chance of getting us there okay
so there's a bunch of different you know
I would love to talk to you if you're
interested in any of the stuff I've
talked about here today there's two
kinds of people I'm especially
interested in talking to those would be
people who might be interested in coming
to work with us and people who might be
good early customers you know the latter
being like people who have really scary
QA problems that they feel like they
don't have a handle on and they think
some of these techniques could maybe
help because we have a prototype that
might kind of work but that said like
I'm also just interested in talking to
anybody who's into this stuff because
this is still a really small niche world
and not a lot of people think about this
stuff and so if you do I would love to
meet you
and I am definitely over time so I won't
take questions thank you
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> M438R4SlTFE </VID>
<CONTENT>
okay good morning everyone my Matthew
this is Mike Mike needs an introduction
we're both wavefront we've been away
from for about two years
and we're both on the team that run the
service called wavefront
and found HDB and this is our story
before I talk about FBB I'll tell you a
little bit about wavefront
we're Silicon Valley's best-kept secret
we're a SAS time-series metrics tracing
monitoring platform and one a few places
running FTB at scale and so because of
that we've learned a lot of things about
running it or the last couple years and
people like us we have startups and
large SAS companies as well so we talked
about scale to the earlier we run about
470 instances across 80 clusters some of
these clusters actually span multiple
AWS regions and that for us is about 330
or sorry 3300 FTB processes and our
largest cluster is often exceed about a
million rights a second on the memory
engine since we're all showing up
architecture I'll show you ours so this
is a real simplified view of a wave
front stack there's three tiers and
applications I'm sorry web web tier and
application tier then a database channel
I'll go into there the web servers here
run a small three node key value store
running FDB we share a content that's
common to both with wavefront runs two
mirrors of a primary secondary mirror
and this this key value store shares
stores content that's common to both
sides of the mirror so things like
alerts or dashboards or user
usernames on the app tiers where all the
magic happens we take in telemetry we do
stuff with telemetry we do queries we do
alerting and we store it into the
database which is FTB on the database
side we run as I mentioned we memory
engine and the SSD engine and a
coprocessor and I'll let Mike talk about
the rest there yeah so this is a very
high-level view of how we architect our
cluster every wavefront clusters he said
is actually two databases there we run
the memory and the S
the engine actually the easier if I come
out here on the SSD side we put a stripe
across a set of EBS volumes just basic
GP two volumes and we shim in in front
of them using enhanced i/o cache volumes
those cache volumes we use to cache our
reads this is important for AWS and
we'll talk about that later and the
rights are it's just a write through
cache so the rights actually fall
straight through into the EBS volumes
the memory engine is not using a stripe
the memory engine has we can kind of
take advantage of being a time-series
database we know we're always writing to
the tip of the database so we use write
throughput optimized st-1 disks are
actually magnetic volumes but they're
highly tuned for doing sequential reads
and writes never at the same time but
the FTB memory engine is only ever
writing or reading and it's doing reads
during recovery and it's doing writes
during normal operations because your
reads come from memory and in between
the two databases we have on each node
what is an f DB coprocessor let's
actually see if I can have to click over
here to
there we go
the FDB coprocessor lives between the or
the FDB coprocessor lives between our
SSD and our memory engine and because
this isn't like a Cassandra database
where it's consistently hashed it's an
ordered key value store it's performing
compression sorting optimizations
aligning the data and the boundaries in
the database so that we get the maximum
reads and writes out and it's aware of
the operating space available to the
memory tier the memory tier is very
sensitive to how much space is available
to be written into it so we have our F
DB coprocessor that basically can shut
down writes to the database shoveled
data out and then resume workloads and
we queue all the workloads up keep
everything durable so we don't lose
anything we run our databases with a one
to one processor count so earlier we
talked about like there were different
roles like proxies resolvers and logs
and storage there's these stateful and
stateless transaction processes those
actually aren't like specific things
like you have to run their a just a
denote on a process that this is a
transaction process and it can be any
one of these roles so we make sure that
we have one two one four storage engines
and transactions are a two to one so we
run two storage processes for every one
transaction process on the memory tier
because we're doing such a high volume
of writes we need lots of proxies and
resolvers to push into the transaction
locks which are carrying those
permutations now pass it back right we
run Linux and we've become experts at
running on Linux and experts at running
in a somewhat hostile virtual
environment so so we've learned a lot of
things that has how to tune Linux or the
machine we're running on around disk i/o
around CPU and memory and kernel tuning
so Numa it's a thing that no one
remembers until snowflake told us to
think about it so on multi cpu instances
like the i3 16x or
we are pretty prescriptive we bind a
process to a sepia dove memory so we
don't have the CPU thrashing across from
memory access
you know Mike touched on our disk layout
a little earlier we're heavy users of
disk caching called enhance i/o we focus
mostly on read caching and so we have a
1:1 mapping between the EBS volume and
the instance store itself mostly because
Amazon doesn't discriminate between I
ops and so we sort of cheap we get free
read caching i/o we then have a bunch of
extra i/o for our rights and what this
means in practice is you can see the
blue line is our read cash rate across
one of the figure out one of the larger
clusters we have and then the green is
the writes which we don't really cache
at all yeah so we get about a hundred
percent read caching because we shim and
nvme in front of each one so the only
overhead really on reads is just what it
costs in foundation DB because it's
lightning fast the only cost is also the
time it takes to build the cache which
is not very long about a day or so or
also experts between the kernel or we've
become experts these values work for us
in our workload you should experiment
but this is something that we have done
yeah it was really important for us to
tune the networking layer on the kernel
especially for the cluster controller
that's where latency can kill your
cluster it's doing the health checks
it's deciding who's gonna take what role
and what you know what roles are going
to be assigned out if your kernel isn't
tuned well you can actually flood and
DDoS your cluster controller and can
take the cluster down and we're not
saying it so what happened to us no well
yeah not on production but so it was
important to make some of these changes
so that we could go from being able to
run three four hundred process clusters
up to much higher now were almost 500
600 on a single cluster just out of
tourney tuning the kernel so that we get
the best performance
that's all you alright so one of the
things that's also important if you're
gonna operate FTP at scale is the
instance lifecycle it's hugely important
because we have some clusters that are
operating at up to 20 nodes in a cluster
so being able to ensure that these
instances come online and they're ready
to go that they are 100% operational
ready is important so we use terraform
we have a system called landing party
that is going that configures these
instances on first boot and we also use
make heavy use of ansible so that we can
do entire fleet replacements at once
which is we want to be able to quickly
and easily change out all of the
infrastructure so our database
configuration and terraform is is dead
simple it's how many nodes you know of
what type how much storage do you want
on it what version of ubuntu are you
running we were locked to 1604 a bit
we've just been unlocked because we had
to rewrite some of the enhance io cash
to support later kernels to get us on to
AWS kernels as well that enables us with
just some very simple helper scripts
that will go out there and deploy these
databases and of course because we're
observability it's important for us to
be able to immediately see when these
nodes come online and how they actually
perform and what it means you can see
new memory storage nodes coming online
how much CPU you can see a spike in the
data that was being processed
it's because there was likely a slight
backup as a node joy joined so honestly
we want to let computers do the hard
work for us so that's what landing-party
does we have landing-party and post boot
systems they actually when a system
comes online they're gonna go in there
if it's a brand new cluster it's going
to configure the memory and the SSD tier
for us automatically we don't have to
touch it it just configures new double
redundant memory or SSD engines it's
going to prepare the
Foundation DB configuration files like
our Numa settings it detects are we on
an i3 is this a 16 X or an 8 X do I need
to push out the Numa configurations it's
gonna get everything ready for us so
that all we have to do is turn FTB on
that's the one thing we don't do we
don't let it turn FTB on automatically
the instances join they're prepared
they're ready to roll
we turn them on with intent allows us to
stage work it allows us to prepare a
customer to grow their infrastructure
and then turn it on under controlled in
the background there's a process that's
taken to cluster it config and pushing
it in s3 so I'll launch we can pull it
back out so the machines kind of come up
ready to go yeah so we can yeah exactly
so the landing party also pulls down
that cluster files so that's
synchronized across all of the machines
all of the nodes so that we don't ever
have to manage that either because that
that can be rather error-prone so fleet
replacements really let computers do the
hard work for you the thing with the
fleet replacements is its we need to be
able to change the tires on the car
weights to the left right yep while the
car is moving we don't want to have to
deal with it so we have written tooling
that actually will go in there and
completely replace an entire cluster
without any human interaction besides
starting it
it goes through identify as which nodes
are to be removed excludes them re--
coordinates to cluster checks to make
sure the excludes have completed checks
to make sure the coordination states
have changed and let's see if I can
create my head enough to speed this up
for you guys
so that's that's actually what it's
going through and doing right now this
is just an ansible job we wrote we had
been challenged when I had first started
at wafer and I was challenged by one of
the founders who said it wasn't possible
to do this he said you're not going to
be able to automate excluding and
replacing the entire cluster all at once
is it all right so we did so this is a
lot to do in flight OS upgrades without
basically hitless upgrades I mean just
drop a whole new set of infrastructure
the tooling understands what was new it
was old and goes through the exclude
process without the human interaction
piece of it and at the very end it
disables term protection turns off the
instances for us yeah so yeah that is
yeah the last thing it does is before it
does that is it does a sanity check
coordinators move for both tiers or
excludes finish did we actually exclude
the right number of nodes and if
everything passes disables termination
protection destroys the instances and
then Rhian cludes the excluded IP so
that you don't have wasted exclude
sitting out there a lot of motivation
for the tooling was we learn the hard
way what happens if you terminate a
cluster coordinator without having a
replacement for it yeah which is it
doesn't work out yeah it doesn't work
after that
so this I believe yeah so it's going
through the cleanup phase now so all of
this is really like prime candidates we
have these in Jenkins they're scheduled
little jobs we don't want operators to
have to remember syntax and have to go
in there and do this this is just a good
show for how we you know what it looks
like how we do it
like yeah it's only three minutes it
feels like you know the longest three
minutes in your life man no really
though the importance here was we did as
MRC said we did find out the hard way
what happens if you destroy your
coordinators before you've recordin ated
the cluster is gone it's dead you know
what happens if you terminate your node
before the excludes finished well if
it's only one it'll heal it'll rear
eppley kate if you don't have enough
replication factor or it's too many you
have data loss so these tools were
specifically built to remove that human
error get rid of that element of it's
possible that I could you know
fat-fingers something forget to exclude
something forget a record ination step
the goal was to enable future engineers
as they joined the team to not have to
worry about those things and just join
without there being any concerns they
could focus on operating and not
learning the scary parts of FDB oh there
we go so I don't know how many of you
are familiar with the f DB trace logs
this is what the trace logs look like if
you enjoy reading XML I don't they're
incredibly Spartan and I actually found
reading the source code for foundation
dB lighter reading than trying to crack
these so we have a tool internally it's
called wavefront f DB tailor it
specifically takes this eyesore and it
turns it into this so that we can see
this is on one of our larger clusters
you can it takes and it shows you where
the roles are assigned what machines
what process import they're on how much
data is flowing through overall on each
node and then how much per process so
that we can find when there's data
distribution issues sometimes data is
not properly distributed sometimes a CPU
is hot somewhere and your tea logs with
your CPU bound are going to have some
shoes it shows us how much storage
memory is being used how much if there's
any transaction processes how much is
being used this this is everything that
comes out of the trace logs but it
readable so which leads to the next
point of monitoring which is basically
the bread and butter of what we do so we
you know we dog food we use our own
platform to monitor and internally we
have some tools the the wavefront fdv
tailor and we also have some Python
scripts it's pull data out and push it
up into our monitoring platform but
instead of really just showing you more
pictures of dashboards I think what I
would try and do is just show you like
live what it looks like on our platform
and how it works so while we figure out
the technical aspects if this is just
gonna work give us a second it's Mike
Mitch and the wafer FDB tailor BN will
have a link that was open sourced today
yeah that's a big shout out to Devon
sitting over there and Jay Bell right
behind him who put in a lot of work to
make that possible because we weren't
sure if that was gonna happen by today
yeah so the big thing in our platform is
you know we had time series monitoring
alerts events tracing but I think that
really what sells me on it and why I
love it so much is just how easy it is
to see what's going on now this just
looking at it doesn't look like an
incredible amount but this is actually
running a derivative of the roles that
are assigned and we can see immediately
that there are changes in the rate so if
the role is a log the value is always
some amount and if that changes you're
gonna see a flick on the value and we
can see a big red box that's an alert
that we have cache errors there's
something just broke so this is how we
monitor a FDB we have to know
every piece from top to bottom what's
working what's not working yeah there we
go and hand say okay shares we can see
which host is dead which cash is dead
and so this was a start of an event
where we actually lost an instance door
yeah and so we caught it right here so
one of the fun things that AWS will
never admit to is that things do break
all the time in their environment it is
a very ephemeral cloud things come and
go all the time instant stores will die
EBS volumes will go corrupt you have to
architect to deal with that so like we
put an nvme in front of each of the EBS
volumes when one of them goes we have to
start stock the system to get an instant
store back we have to rebuild our caches
but we have the alerts that show us s
and we can actually see the FTB data
that tells us that hey something isn't
performing right and then here near the
end you can see a lot more role changes
as the cluster is starting to restore
order and come back to life
where did it go don't just leave it in
this field so this is more of what comes
out of your trace you can see around
10:45 that the latency in f DB starts
going awry we're missing data its
spiking up and down the cluster is
actually struggling a bit the storage
and log queues which we had talked a bit
about earlier your log queues writing
the permutations of what's going to
eventually make it into the storage
queues typically should never reach
above a threshold and for our
configuration it's about one gig of data
we can see where we begin to lose out
how much operating space we can see it
falling off this is all stuff that we
get out of it those the trace logs from
the tailing system we pull it in we can
see where the SSDs here which is
actually this area right down here the
key value store drops out a couple times
and that is from the initial we lost a
drive to we had to restart
you see if I couldn't one of the other
nice things we get is you can see which
processes are dying you have immediate
observability in two processes are dying
they're restarting those are just memory
storage notes that went down with the
event and there was they begin the
process of self recovery this is a very
very durable database it's very
operationally it's a challenge it's a
challenge but it's not a challenge
because you're trying to keep it from
corrupting your data like my sequel or
Mongo it's not a challenge because it
has insane defaults it's a challenge
because it's so durable that it favors
keeping your things together which means
it's going to make some hard decisions
for you which is it'll stop the world
and recover itself if it thinks it needs
to but the alternative is losing
customer data and you don't want to
can't really afford that this is
actually great this is one of
Emergencies favorite charts this
monitors the file sizes on disk for the
transaction processes it monitors the
actual transaction log itself
and it monitors the rate of change in
the transaction logs our transaction
processes as they are as we are
recovering and it's pulling data in and
it's reading those files back into
memory the processes are growing in size
they're changing they're recovering and
we need to be able to see that in that
black line right there which is his
favorite line it tells you whether or
not the transaction logs are still
reporting out of FDB if those stopped
reporting FDB is hard down you you you
have to then go in and do a little bit
deeper surgery on fdv but this is how we
can quickly and easily identify and show
people hey FTP is recovering fine it'll
come back on its own don't worry it's
you know rereading in T log files from
an earlier outage
and some of the other items around this
event you can see we we track all the
metrics because they matter to us let's
see if I can so you can see in the
window when it first went out our oq
depth if you're very familiar with IO it
was not suppressing which means IO is
not being read or written nothing was
happening you can see where we lost it
and it came back at that particular node
so this is all what goes into
observability for foundation DB for us
and without it I don't know how we would
survive to be honest and we build alerts
on us yeah we do we actually build a lot
of alerts on this so one of the charts
one of the charts I have scrolled past
quite a few times is this pegged CPU
process so what's fun about this chart
is so those trace logs are constantly
emitting values and a very important one
is the CPU seconds how much time
CPU time is this process consuming if a
particular process dies and it becomes
unreachable by the cluster it stops
emitting that value well the FTB log
tailor actually continues to emit the
last value it saw so we can abuse this
knowledge and write alerts that look
specifically for processes that are no
longer in mitting this data and we can
find processes that have fallen out of
the cluster and they have fallen out of
the cluster for any number of reasons
but we can go identify those processes
because the rate of change in that
process is now zero and it allows us to
nullify all other processes that are
showing rates of change and highlight
only the ones that are no longer
reporting their CPU time and we use this
find the process kill the process and
restart it FDB monitor goes in restarts
the process cluster goes back to normal
operations so these are just some of the
operational challenges for us but having
those trace locks turned into telemetry
enable
us to really dig in and find these kinds
of issues where we would typically
before be banging our heads against the
wall like why isn't this recovering why
isn't this coming back
we built dashboards we built alerts and
now computers do all the heavy lifting
and work for us and that's all I have
nothing is it don't you guys have any
questions about how we do what we do so
you try to find the last slide here I'll
have the link to the github repo or
they're posted to the dashboard that
Mike showed you we've explored the JSON
it'll be up on the same repo to you if
you were to try it out you can
experiment with the same sort - whether
we use in production that's what we got
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> EMwhsGsxfPU </VID>
<CONTENT>
i'm evan shannon so i managed the
development of the foundation DB key
value store at apple and i'm gonna spend
the next 40 minutes taking you through
the architecture of foundation DB i was
first taken through the architecture
eight years ago however back then it
existed as some hand-drawn diagrams on a
piece of graph paper
what's pretty remarkable though is that
it took around three years of
development before we actually before we
actually made any significant changes to
the database that like weren't on that
original sketch and a lot of what i'm
gonna talk about today if you found that
graph paper now which would be there so
it's pretty pretty remarkable um so to
focus this presentation a little bit
before i get into it i wanted to
highlight some of the foundation DB
strengths so as i'm going to later as
I'm going through the architecture I can
kind of explain how foundation DB is
providing these properties so one of the
things is that foundation DB is is
operationally very easy to use and
specifically it does a lot for you in
terms of load balancing traffic across
the different machines and a cluster and
it also does a lot for self-healing in
response to failures so I'll come back
to both of those points as I'm going
through the architecture have for how we
do it um the other point is comes back
to something Ben really mentioned which
is that we provide scalability without
sacrificing performance or consistency
it's really easy to be skeptical about a
claim like that because it sounds too
good to be true so I want to be really
specific about what we mean about this
and so hopefully I can convince you all
that we actually do it so it's easy it's
a little easier to talk about not giving
up consistency and foundation DB for
scalability you know foundation DB
provides gives you acid transactions
there's a single global key space inside
of these transactions you can read or
write any key across the whole database
foundation you begin
you strict serializability and external
consistency which I'll get into a little
bit later it's a little bit harder to
quantify what it means to not sacrifice
performance for poor scalability because
there's a lot of dimensions to
performance so my approach is to think
about Foundation DB as organizing a lot
of individual like non-scalable key
value stores into a single cohesive unit
so we can talk about the like
theoretical perfect performance of the
system is if you dedicated all of your
hardware to these individual key value
stores what would be the aggregate
throughput of all of these things put
together what would be and so when we
compare Foundation DB against that model
we achieve roughly 90% of that
theoretical best perfect scalability so
and hopefully I'll be able to convince
you of that as we're as we're going
through it in terms of latency czar read
latency Zoar basically as good as you
could possibly get there a single hop
from a client directly to a server
that's going to serve the response for
that read writes are a little bit worse
to get a write successfully committed to
the database it's about four hops
through the system in practice this is
going to mean about four or five
milliseconds of latency on commits so
it's important to note that all of this
argument about performance is related to
the architecture which is what I'm going
through but it says nothing about our
actual performance and in fact a lot of
the projects were working on today are
gonna significantly improve the
performance of our system as a whole
like the Redwood storage engine so but
this is basically showing us with a
perfect implementation of foundation DB
this the sky's the limit
so now I'm finally ready to get into it
and I'm gonna do that by starting with a
little bit of distributed databases 101
so in this diagram we have three servers
and a single writer which is trying to
push data into the system and a single
reader which is trying to get data out
of the system and in this system we
you have the criteria that we need to be
resilient to a failure of a machine um
so the traditional way to do this is
using corn logic so if the writer when
it's writing data make sure the data
gets to two of the three servers um
and the reader may like reads from all
of the locations and elite is sorry
about that is only successfully reads
when it can talk to two of the three
servers we'll make sure every piece of
data gets to the system and then if one
of the server's fails well the system
will just keep going on naturally
because we only needed two out of three
responses from both places basically
this system has implicit failure
handling it just will naturally increase
so kind of the I guess I should have
brought some water up here so sort of
the core principle behind foundation DB
is if we don't actually need this
implicit failure handling that I just
described um there's actually a lot of
benefit we can gain by doing things
slightly differently so in this case
since we don't have to handle failures
our writer can write to all three of the
servers um because we now have no well
thank you van you're rescuing me from my
cough okay so if the writer writes to
all three of the locations this actually
gives us two huge performance wins one
of them is obvious in the lettle the
other one is a little more subtle so the
obvious one is because the data is now
at all of the server's the reader no
longer has to talk to all the servers to
do a read it can actually go to just one
of the servers to get a response because
they all have all of the data there's no
like quorum to combine them so basically
our reader is now three times more
efficient than it was in the previous
diagram the or the other more subtle
point is that when we can handle
failures in this system we're actually
going to do it do a lot better job so
the quorum logic with three servers gave
us a resilience of a loss of us one
single
gene in this system because the data is
making it to all three servers we
actually can lose two of our three
servers and not lose any data so that so
we're going to be much more resilient to
failures so then the question obviously
becomes well how do you handle failures
and so the foundation DB answer to this
and kind of one of the key innovations
behind the design is that we are going
to have an entirely different database
that it's going to store metadata about
this other database about our primary
database and so basically this other
metadata database is going to hold
membership of the servers that are in in
our primary database so in this case the
servers a B and C we're holding we're
responsible for committing data at
version zero when we started up the
database and after at some point in time
you know server a died and then we
replace server a with server D and so we
wrote to this other database now we're
doing our commits to B C and D this
other database can use the quorum logic
and implicit failure handling that we
talked about before and because it's
very low traffic database it's only
gonna you're only going to ever write to
this other database when there are
failures in our in our primary database
so Foundation B take took this basic
idea and turn it into a system and so
now I'll go in I'll start adding boxes
so this diagram here shows all of the
stateful components of foundation dB so
the coordinators are this other database
I talked about this metadata database
that uses you know Paxos and quorum
logic to do to do its writes in a fun
trivia fact the first version of
foundation DB this literally was a
separate database we used a patchy
zookeeper to hold this metadata and
which was quickly replaced with our own
implication you know a few like a year
later so for the other stateful systems
we have the transaction logs and this is
a distributed right ahead log that's
responsible basically for accepting
commits and writes into the system it's
job is basically to get sub durable on
disk as fast as possible so that we can
turn commit successfully to the client
basically it's a write once read never
data structure mutations are only being
held there transiently they're coming in
we're making them like appending them to
the end of the file and then once the
storage servers have the data we'll
quickly get rid of it so generally they
have very little they're using very
little storage there they're also super
efficient because they have such a
simple job these storage servers go back
to the point I was making when I was
talking about performance and
scalability so they are 90 percent of
our system and they are all basically
individual key value stores that were a
group that we're kind of allowing to
cooperate together to act as one single
big key value store um
so each one of them you know has a is
basically holding data for long-term
storage that is getting from the
transaction logs and it's serving reads
re requests that are coming in from the
users basically the entire system is
designed around making these guys job as
easy as possible and to simplify that so
because they're the bulk of the system
the transaction logs basically are set
up in such a way to make the the storage
servers have to do as little as possible
when they're ingesting writes and like
the clients and how we're doing our
reads are also trying to do as few reads
as possible and download for them so to
that end when were the transaction logs
are sending data to the storage servers
the way we do this is we have every
storage server has a buddy transaction
log and that storage server is gonna get
all the data that it's responsible for
from that one location so basically it's
getting an exact stream of writes that
are specifically designated to to this
one specific location and so we'll we'll
talk a little bit about how that happens
but we're doing it for efficiency sake
because these storage servers are only
talking to one other server it's super
efficient so now we can start from here
and start building adding on the
stateless components onto the system and
the first one I'll talk about is the
cluster controller so the cluster
controller is a leader that
selected by the coordinators and its job
is basically to organize the all of the
processes in the cluster into the full
system so basically when every process
starts up it's going to talk to the
coordinators to figure out who the
cluster controller is and then it's
going to register itself and kind of
whatever information it knows about the
process to that cluster controller so
it's going to say I have a disk I prefer
to be a storage server you know and this
is my information so the cluster
controller is then going to take all of
the workers that have registered with
the system and it's going to start
assigning them to do these different
roles well you become a transaction log
you become a storage server the cluster
controller in addition to like giving
out roles is also doing failure
monitoring so it's going to track it's
going to be basically talking to these
processes continually to determine if
they fail and we'll get into failures a
little bit later so before I can add
more boxes and trust me there's more
boxes we have to take a little break to
talk a little bit about how foundation
DB provides consistency so I mentioned
strict serializability before um and so
to provide that we first need serialize
ability and in foundation DB serialize
ill serialize ability is explicit um
every single commit you do is given a
version number and you can just observe
the serialize ability by comparing
version numbers you know this commit
committed after the other one or
happened after another one if it's
committed was higher so it's right there
for you to see um it gets a little bit
more complicated when you want strict
serialize ability and basically what we
need to do here is make it so that when
we commit it's like our whole
transaction happened at the
instantaneous moment in time that the
transaction was committed and the
foundation DB approach here is basically
when you start a transaction you get a
read version which is basically the
latest commit version of the the system
has committed previously once you have
that version for the rest of your
transaction all your reads are stuck at
that moment in time in
the pass for when you started your
transaction and so the data you're
reading from the database it's gonna be
you know a little bit old it's not gonna
see the newer stuff that's gonna come in
it's just it's just stuck at that
consistent point in time um and then
when you finally go to write the whole
concept here is that if none of the keys
that you read changed in this time
interval before between when you started
your transaction and when you eventually
committed then it's actually like you
did your it's then it's actually like
you did all your reads at the final
commit Bergeon it's like you're at an
instantaneous point in time so that's
the optimistic concurrency model at
foundation DB and as a consequence if
someone changes one of the keys you read
in this time interval in this short
window between your read version and
your commit Bergeon um we fail your
transaction as a client you retry so the
layers team you know is kind of having
to deal a lot and you're gonna hear a
talk later by Alec that like this is
something that you have to be very
conscious of that happens in foundation
DBA and you have to work around it okay
back to the boxes we now have an API and
you can see that there's now a master
and proxies and resolvers added to the
diagram and these components are all
basically the stateless components that
are here to implement the the basically
the consistency model I just described
so let's go through the different
operations you can do on foundation DB
and see what happens and see what
happens so we'll start in with reads as
mentioned reads are going directly to
the store servers that are responsible
for those range of keys so if you read
key a there's going to be some set if
your triple replicated there's going to
be some set of three servers in the
system that are that have that data and
you're going to talk directly to one of
those servers and the storage server is
just going to give you an answer if you
remember from the previous slide your
reads are versioned right so you're
passing in a read version with your
thing and the storage server has to give
you the value of that key at that moment
in time so we're reading
at version 200 and the storage server
basically is going to keep some history
in memory of recent commits and it'll
give us a at that version uh D this
comes back to one of kind of the
constraints of foundation DB that you
probably already all know about which is
the five-second transaction limit the
there's there's two places I'll mention
the five-second limit one of them is
right here because it's currently the
storage server is keeping the recent
history in memory and so to limit the
amount of memory used by the storage
servers we restrict like how much
history we keep so we only keep five
seconds so the other thing to mention
here is this metadata related to which
storage servers have which keys because
as a client you need to know who to talk
to you to give you any answer to any
video individual query um so this this
like mapping between keys and the
storage server is responsible for them
is state that's actually held and a lot
of components in the system the client
keeps a cache of these locations and if
it doesn't have an answer if it doesn't
know at any given moment whose response
for keys it's going to ask the proxy for
for that information so the proxy keeps
the entire map and the client will send
a request over the proxy saying who's
responsible for key a the if the if we
move if we shift responsibility of a
shard the clients cache could be
invalidated because the the person it
previously thought was responsible the
keys is now shifted and in that case the
storage server itself will tell the
client that the data's have the data is
moved the client I'll invalidate its
cache and it'll regrab the answer from
the proxy to get the correct location um
this state this mapping is actually
stored in the database itself um and
what's kind of a really cool and
interesting design so it's the
foundation to be the byte FF is the
system key prefix and it stores system
metadata in the database there um and to
change shard responsibility to give
ownership of a key
from one set of servers to another we
actually accomplish this by just
committing transactions to the database
itself um so you can it's a two phase
protocol where you say like I'm
intending to move this range to some
other location and then once that
location has copied all the data then
you do another one saying this these
these servers are taking over
responsibility um so this data stryn
algorithm is is you know responsible for
a lot of the load balancing that I was
mentioning earlier that we get out of
foundation DB so basically this we're
constantly kind of monitoring how much
work each of the very sort servers are
doing and shifting responsibility around
by executing transactions on the
database kind of giving ownership of
keys so like if you added a completely
empty new process to a foundation you'd
be cluster what's gonna happen is the
data distribution algorithm is gonna
notice there's now a new process in the
system and it'll just start giving it
key ranges and key ranges until it's
part it's like taking a some traffic
okay although a lot on reads or I want
to commits so rights and foundation DB
are actually just cashed up on clients
so there's nothing really to talk about
there and commits are basically going to
take everything you did in your
transaction bundle them up together and
send them as a single unit - one of the
proxies so in this case you're gonna
you're going to include the the version
that you did you read that every key
that you read and then every mutation
you're attempting to write and package
that up together and the very first
thing the proxy is going to do with that
information is a sign that that
transaction a commit version so in this
case we did our reads at 200 and the
master is going to tell us that we're
committing at 400 so the masters job
it's the only singleton in the pipeline
that's that's not scaled out it are only
a single box here and it's entire job is
just to give larger and larger commit
versions back to the user so I it even
though it's a singleton it'll never be a
scalability limit to a cluster um
because it has such a simple job and as
you scale up the system we actually
combine different transactions together
into batches and the master is only
giving a single version number to an
entire batch
actions so basically even if you hammer
the database super hard the Masters is
not really going to sweat giving out
these version numbers so once you have a
commit version you're now ready to do
what I was saying on the previous slide
and detect to see if anything you read
in this transaction changed between your
read version and your commit version and
there's that is being done on the
resolvers so basically the this is this
is another location where we get back to
the five second transaction limit
because the resolver a stateless role
that are that are storing the previous
five seconds of history of reads and
commits a reads and writes and it will
basically be able to tell you for any
given read if it's changed in this in a
time range so one important thing to
note about resolvers is they're sharded
bike when you add multiple of them
they're sharded by keys key range and so
you're going to give your gonna split up
your your reads and writes to according
to the key ranges of those resolvers and
send the just the specific data for
those that that resolver is responsible
for to those locations what this means
though is that as you add more respond
more and more resolvers to a system
you're doing a little bit of conflict
implicit amplify amplify Haitian
basically the two resolvers don't know
about the decisions the other one the
resolver z' don't know about the
decisions other solvers are making so if
one of the resolvers fails a transaction
and the other thinks it succeeds well
the what the transaction was failed but
the one that thought it was successful
is gonna fail future transactions based
on the rights that happened in that one
even though they didn't actually apply
to the database in general this is not a
huge issue and foundation DB as you as
I've mentioned already you already have
to design your clients to avoid high
contention workloads that are doing a
lot of conflicts anyways but in general
it means that you don't really want to
scale out resolver you don't want to
just configure 100 of them right off the
bat start slow and scale up to just as
many as you need so assuming the
resolvers haven't found any problems
it's now we can now finally make the
transaction durable so the proxy is then
is now going to ship the mutations the
right
from this transaction to the transaction
logs and so as mentioned previously
every transaction log or every storage
server has exactly one transaction log
that it's going to get all this data
from so if we're writing key B here
there's some team of storage servers at
the end of this pipeline that need that
that mutation that changes key B and so
those servers are mapped to some
transaction logs and so the proxy
basically knows all these mappings and
it's going to send the change to key B
to the set of transaction logs that'll
eventually get the data over to the the
sort servers responsible for it um
because there's way less transaction
logs and there are storage servers the
you could just happen to get lucky or
unlucky that all the locations that want
key B are just one transaction log
that's all you know
and in that case we actually have to
additionally replicate key B onto some
other transaction logs so that we're
safe against failures in the transaction
logging subsystem so there's a little
bit of complicated logic the proxy does
to figure out where to store the
mutations in the transaction subsystem
once the data has been F synced on to
the on those transaction logs and come
in durable made durable there we finally
can return success out to the back to
the user I mean behind the scenes the
data is going to be replicated over to
the storage servers so finally I can
wrap all the way back around to a get
read version request and get reversion
requests are responsible for giving us
how we provide them or responsible for
how we provide external consistency so
the concept here is that when you start
a transaction it's a very nice property
that you'll see every commit that's ever
previously happened on the system so in
in this specific example like we
previously committed to one of the
proxies and now we if we immediately
start another transaction that talks to
a different proxy we want to make sure
that this new transaction sees the
result of the previous one we just did
so the way that we do this is that when
we talk to one of the proxies for a read
version that proxy will send a message
to the other proxies asking if they've
seen any versions that are higher than
the one
we have locally and we'll just take a
max of all those responses and send it
back to the client this may at first
glance seem like a scalability problem
because every proxy is basically talking
to every other proxy exchanging these
versions however we're saved here by
batching we basically can we don't have
to do these reversion requests for every
single transaction we can group up a lot
of different requests together and for a
whole bunch of them we can send it send
these requests to the other proxies so
really we're only sending these messages
between proxies every 18 a millisecond
or so okay so uh that's kind of takes
you takes that's the that's the first
part we've gotten through how you how
you do commit how Trent like how
transactions flow in foundation DV um
however if we wrap all the way back to
what I originally said a huge part of
this design that that we've a trade-off
that we've made is in relation to
failures
so basically we're having to explicitly
handle like failures and foundation DV
because we don't have the implicit
failure handling that a chorim's give
you so now I'm gonna take you a little
bit through through what happens when a
process fails in foundation DB so I'm
gonna start with the target with the
hardest one in this case in which case a
transaction log dies and so this is
gonna kick off a recovery process so the
cluster controller is going to detect
that this server has gone down and the
first thing it's going to do is
basically attempt to recruit an entire
replacement for the entire transaction
subsystem that's going to basically take
over from the previous generation
basically like storing the data in this
other coordination database the court in
ethic on the coordinators so this is
using this this right is going to use
Paxos and we're doing this because it
would be an absolute disaster if we
could have two different masters
takeover simultaneously like any
consistent system is going to need a
two-phase commit somewhere so the first
step is that you know the the first
phase of our two-phase commit where
we're going to do a read from the
coordinator
to find out who exactly was who were
exactly were the transaction logs of the
previous system this new master is then
going to talk to those old transaction
logs and find out the final version that
was committed to them in this case were
the the one that died had version 400
and the other ones that were alive
actually got another commit after that
there's 410 and 420 so they have even
more recent data for because the commits
had to go to every single log the only
version here that actually was returned
commit success back to a client would
have only been version 400 and so but
we're allowed to take any version after
that so 410 or 420 is also fine it's
sort of like a client it doesn't know
the result of those transactions um so
the master neat so when it's asking for
these versions the master is also
locking these transaction locks to
prevent them from accepting any
additional rights in the future
basically preventing us from recruiting
new logs and having the old logs
continue accepting rights um and the
next so them so the master is then going
to pick kind of the lowest of the
responses it gets that from that from
these guys and command take that and
basically tell the next generation that
they're taking ownership of the days
starting at that moment so the master is
then gonna basically start up all of the
other systems at that moment in time so
the proxies were going to recover that
key to server look mapping as of that
version and the transaction logs
actually have to do a little bit of
copying as well and this the reason for
that is actually really subtle so back
on the previous step I said that we see
that this transaction log with version
400 is dead it's gone right but that
might actually just be a temporary
failure it could just be a little
network hiccup that triggered this
recovery um and if we have three servers
and we're triple replicated we actually
want to be safe against two failures so
what can happen here is that after we've
committed to a recovery version of 410
the two remaining guys who are alive can
permanently fail and this one guy who
was temporarily that at the store
can come back alive and he only had and
this this guy only has version 400 so we
need to copy just a little bit of data
from the previous generation to make
sure that even if there's this crazy
scenario of things dying and coming back
alive we're still able to have all of
the data up to the version that we
committed to be our recovery version in
any case once the transaction logs got
this little bit of data we're finally
ready to go with this next generation so
the master is then gonna do the next
phase of the two-phase commit to the
coordinators kind of finally writing
these new sets of transaction logs into
the database saying that they're taking
ownership from the previous generation
after all of that happened we can
finally tell the cluster controller
we've taken over which can then
basically open the floodgates of traffic
onto the system again so that was the
hard one if that same recovery process
that I just went through is gonna happen
even if a master resolve or a proxy dies
the philosophy here is basically we know
we have to make this one recovery
algorithm really fast and so if we do
the card case really well we can just
use that hard case for any to handle any
failures even if they were potentially a
little easier um so eventually we may
get around to writing specialized
recovery logic for replacing some of
these stateless roles but for now
there's just one thing that the one
process that happens if any of them die
um if the cluster controller dies well
that's really simple it's a leader
elected by the coordinators and so it's
heart beating constantly to those
coordinators and so when it dies it'll
stop heart beating and the coordinators
will detect that and just to reflect a
little electro replacement and even
simpler than that
if a coordinator dies well it's using
quorum logic it has implicit failure
handling nothing happens when it dies
the user will probably want to replace
it just to restore cual tolerance but
it's there's no emergency
and finally we wrap down back over to
the storage servers which as you can
recall or 90% of our processes in the
system and one of one of these things
dies there's basically no effect to the
user clients will just automatically
start sending requests to the other
remaining
responsible for the keys at that server
had and that day distribution algorithm
I mentioned earlier is going to start
shifting a responsibility of all those
key ranges on the failed note two other
sets of a live servers so the system
will just naturally heal from this
problem note like with no problem
so that's kind of the the gist of it I
just have a few other points to talk
about one of them is kind of a potala
form of pathology that's specific just
to foundation DB really um so as I've
been talking this whole time we've
mentioned a number of times this five
second transaction limit and normally
databases handle saturation performance
by basically relying on back pressure to
a so as as more and more people overload
a server it'll just naturally slow down
responses to those requests however in
foundation DB because of a five-second
limit that can lead to a death spiral
the concept is like if every Reed you're
doing if you're doing like five or 10
serial reads in a row and your
transaction if every reads starts taking
a second well all of a sudden by the
time you get to your last read you've
passed the five-second limit so then
you've done all of this work and all of
these reads and you get to the end and
you try and commit and you just fail and
if every client starts doing this then
basically no work is being done in the
cluster it's just a disaster your index
file everyone's hammering the server
hammering the server's and no work is
getting done so we saw this problem and
our solution to it was this concept of
rate keeper the idea is that when we're
in saturation we're gonna build up all
of the latency before we get the
original read version to our request
so basically back to the diagram when
you start a transaction you're
five-second limit really only starts
from the moment you get a read version
basically you have two commits within
five seconds of getting that version so
if we can basically slow down the rate
at which you the clients are getting
versions we can make it so that one even
though it might take a few seconds to
get a read version once I have one
they'll be able to do all the rest of
their
operations with very low latency so that
rate fear keeper components another
singleton that lives on the master so
the final thing to mention is sort of a
theme of foundation DB and been
highlighted it a little bit but uh you
know obviously this design is really
complicated there's a lot of little
moving pieces there and there's a lot of
edge cases I didn't even really get into
in this architecture discussion so the
question of the day comes back to well
how can we trust or how can you guys
trust that we actually don't have any
bugs that just throw out this entire
design like do we act you don't actually
have acid guarantees if there's some bug
that corrupts your data in some weird
case um so basically the the founders
recognized this basically from the
get-go and that's why they started with
simulation right because the the idea is
this thing needs to be tested really
severely so that we can actually trust
that our inflammation our implementation
of this design is meeting the guarantees
we say it does so the way this works is
kind of when I was going through this
whole architecture right I was talking
about all of these different processes
in these boxes sort of in my mind and
maybe in your mind you're thinking about
them is happening on different machines
or different processes in those machines
but in actuality there's an indirection
between the roles in the work that's
happening and where it's happening in
the cluster so it's actually you can
actually start up a foundation to be
like cluster on your laptop in a single
process and that one process will do all
of the work of all these roles right
there locally in that one process what
this allows us to do is if when we're
running the whole system in one process
we can actually have that single process
pretend like it's an entire network so
it could because it's all one process
just instantly send messages you know
from the proxies the resolver from the
revolvers you know back to the proxy
from the proxies of transaction log but
instead of doing this instantaneously we
actually pretend like there's latency
between these components we drop some
packets randomly we reorder things we
pretend like whole system dies we
pretend like there's corruption on disk
basically every bad thing you could
possibly think of we we do in this
system
and because it's an because it's a like
single process that's doing this we have
determinism so if we can run you know
hunt we run hundreds of thousands of
these things of these randomized tests
every night pairing these random
failures with some workload that's going
to ship check some property of the
database and when it comes back with an
error we can in the next morning like
replay the exact really rare series of
events that caused this and kind of
figure out what happened this is really
powerful
oh my eight years working on this
database probably six of them has been
sent tracking our problems down by this
thing so it's it's really kind of the
one of the big secrets sauces that makes
foundation to be possible um so that's
all I have for you guys before I step
down I just want to say thank you to
Dave Rosenthal and Dave shear they made
a lot of hard decisions early on with
like developing the simulator developing
flow even through the developing this
whole architecture basically at every
moment they were making technical
decisions early on they were focused on
kind of the long-term sustainability or
long-term success of this database and
so now I'm reaping the benefits of the
work they've laid out and early on so
thank you guys
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> 16uU_Aaxp9Y </VID>
<CONTENT>
all right so this is the last talk of
the day my mandate is to be quick I
promise I will be so metadata management
for machine learning pipelines my name
is Steven Pimentel and I work at Apple I
would normally give a 40 minute version
of this presentation this is my first
attempt at compressing it to five
minutes I'm calling this the haiku
version and I hope it isn't more like a
cohan I'm going to talk about a
foundation DB layer called entities
store that I wrote for an internal
system at Apple we use it to store and
manage metadata for machine learning
pipelines entity store exposes a data
model for versioned entities with
fine-grained authorization and lineage
that summary on the slide isn't very
complete but it is a haiku so why does
metadata matter for machine learning say
you're running machine learning
pipelines on a cloud platform for lots
of users the number of users is large
and they span a diverse range of use
cases and teams pipelines start with
data sets the data sets are many varied
and usually raw there are often
requirements around who is allowed to
see which parts of which data sets raw
data sets are transformed to produce
datasets suitable for training and then
we must track what raw data sets were
used two or more can be joined or
otherwise used in combination what
transforms were applied using what code
in what languages with what versions of
what libraries training produces models
we must now track what architectures
were used what learning algorithms what
frameworks tensorflow
PI torch with what libraries and what
versions of these libraries and this is
before we even get to hyper parameters
we can also use one or more pre-trained
models in case of transfer learning or
fine tuning in an experimentation
framework you often iterate through a
number of models varying architectures
and algorithm
but all trained for the same task or use
case now metadata must be tracked per
run in addition to the previous types of
metadata we have additional run specific
types finally we may want to serve a
model in production but as with any
production system a model will go
through versions as it is updated and
improved you may have Canary deployments
or roll back to a previous version or
deploy multiple versions for a/b testing
we want to store and manage this
metadata in a unified framework that
tracks provenance for each version of
each entity this is what entities store
does so entity store is a foundation DB
layer that implements a data model for
versioned entities with fine-grained
authorization and lineage it's
implemented as a python library exposing
its own API above the foundation DB
Python bindings read and write
authorizations are separately recorded
at the level of individual fields also
known as cell based security versioning
of entities is automatic with
modifications to immutable fields
resulting in a new version rather than a
mutation each version has a unique ID
like a get commit ID formed from the
sha-1 hash of its primary key in mutable
fields parents version and authorization
groups versions form a parentage tree
and can be explicitly selected for use
also like get each entity is modeled as
a collection of objects that represent
its distinctive versions along with a
core object for mutable non versioned
fields provenance or lineage is a record
of datas origin and the transforms that
have been applied to it entity store
stores records records lineage via label
directed multigraphs the graph for
version parentage is constructed by the
versioning mechanism other forms of
provenance such
derivation of training data sets from
raw data sets are represented by
different labels for graph edges objects
are schema lists and consist of any
number of fields with values fields can
be single valued or set valued and
either case can optionally be indexed
and fields can also have large blob
values this rich data model is mapped to
the key value store versioning
authorization and lineage are
incorporated directly into the data
model layer so clients get them for free
transactions allow multiple clients to
concurrently access entities without
fear of inconsistent results or data
corruption and thank you very much
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> Z1IbfjHGi78 </VID>
<CONTENT>
hi everybody I'm Andrew from snowflake
computing working on the foundation to
be development team and I will be
talking about so kind of the way that
internal FDB types get serialized and
sent across the wire or stored as values
in the database itself or stored on
files but for motivation
availability of foundation DB DB is very
important for snowflake if you know
foundation DB is down that the snowflake
is down and so sort of the reason I'm
talking about this is that the the
current serialization format does not
support schema evolution kind of the way
it works the way to think about it is if
you have a message with two types or two
fields a and B it serializes a and B and
concatenates it currently so if you want
to add a third field that's well really
work it'll if you read it with something
that expects only two fields it'll
something lapin I don't you know you
don't want that okay so yeah so
currently what that means is that two
foundation DB processes need to have the
sort of same protocol version to talk to
each other for introducing protocol
versions this isn't such a big problem
because you can have the new guy
understand both protocol versions but
for sort of downgrading back to the old
guy if there's something say written to
a file with the new protocol version the
old binary won't be able to read it so
that's why I downgrading a cluster is
not supported one of the reasons okay so
we implemented a serial is eight we have
an implementation of flatbuffers that
works with foundation DB types so here
we kind of have this idiom used in
foundation DB for serialization it's a
lot like a visitor pattern and so our
flatbuffers implantation sort of it also
works with with this idiom
so so flatbuffers what we're looking at
it because it's um it's already
documented for one so that's good and so
we didn't want to design our own kind of
custom thing to get schema evolution we
wanted to sort of go with something
that's has a lot of use right okay so
where where would be good applications
for flatbuffers so even if you don't
want to do anything like online upgrade
if you want to do just a normal upgrade
where you read something say from the
disk that was serialized by an older
version this would be good there because
then you could downgrade kind of like I
was describing before also if you are
writing something into the database
itself as a value the same thing applies
and this also could be useful for
network messages if you want to support
something like online upgrading and so
kind of for an example here let's say
you want to you have a new binary and
you want to see what happens if you just
enable it on one storage node if you
were using flatbuffers and this won't
cause a recovery right because if if you
take down a storage node that won't
cause a recovery so let's see
right so so you can interoperate with
the old okay let's say let's say let's
say you do it and you you see a CPU
regression you can you can kind of just
try upgrading one storage at a time to
and just see what happens and that's not
really something supported with the
current protocol okay so where is this
where is this not a good idea okay so if
you're going to write database Keys
flatbuffers is not going to preserve the
ordering of what you are reading and you
often want to sort of have the
serialized by it's maintain the ordering
of the original type and for streaming
messages the the current protocol has
this property that if you know what the
type is and you have the byte sequence
and you and you serialize it it will
consume the right number bytes and start
right at the beginning of the next
message flatbuffers also pop-up
flatbuffers does not have this property
so you need some some other protocol to
encapsulate the flatbuffers message okay
oh that's when I was going to talk about
it sergeant okay so how does this prove
availability what I described earlier
basically you could do something less
drastic than taking or like stopping
with a cluster and bringing it up and
seeing what happens you can do something
with just one note at a time so if there
is a CPU regression you won't cause an
unavailability okay so so testing we've
talked about testing in foundation to be
a lot today what we have for testing
this so far is we can test it on a live
foundation DB cluster by kind of having
you know one binary with one version of
the message and another with an earlier
version say
and kind of upgrade one thing and see
what happens but we really want those to
be able to do this in the simulator and
what we've been able to do and we've had
some success with this is building FDB
server as a shared library and then DL
opening it so that a simulator can
basically kind of start a new FDB server
process in the simulator at either
version but this gets a little tricky
because the like if there's any changes
to the simulator itself or any global
used then it you know it's it's not it
wasn't really set up like that so you
need to be aware of that if you want to
support this yeah I think that was all
there okay cool so if you have any
questions grab me after that's all
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> 0xEjlPK3je4 </VID>
<CONTENT>
what is the hot spot in foundation to be
a hot spot in any database for that
matter high volume of writes or reads to
a small set of blocks a small number of
partitions in this case on a storage
node or a set of storage nodes team as
depends on how much as application a
couple of matrix just to sort of give
you context everybody's mentioned Steve
mentioned the storage node keeps five
seconds of data in a version tree that
are non-durable this can grow and shrink
in size the storage queue is the size of
these mutations the the and another
metric called non-durable versions is
the number of versions that have not
been persisted to the sequel light and
the only thing you really need to know
is that when storage queue goes up rate
keeper goes down when NDB goes up bad
things happen when it goes too high so
there's this is a simple talk there's
just a couple of takeaways and maybe I
can give some more time back if you want
to detect two kinds of things if you
have a right hotspot you will find that
both the storage Q and the NDB go up
simultaneously on a specific process if
you have a read hotspot you'll find that
only the story only the NDB goes up and
not so much the storage queue and the
reason for this is foundation DB tries
to prioritize reads or writes if you
have a large amount of writes then they
take a deprioritized and the storage
cube I mean the storage node is busy
supplying all the reads if there's a
large number of reads then the storage
mountable versions will go up as a
result so how do we solve these problems
we made a code change which changes the
priority of the right tasks you will see
this in the previous slide that solid
line up top is in in the lower chart is
we said rights are not getting pushed at
all let's increase the priority
try to read that helps us a lot
we applied application level throttling
that Cantrell reads writes final grade
in throttling for oh these are certain
applications that are doing worse but
most importantly this is the second
takeaway from this talk is you need to
understand your data patterns and and
this is something that being a database
company we should be really good at but
it turns out we weren't as good as we
should be and we've been sort of you
know not on the head by various people
including so I'm sitting in this room
about that so how would you do this
foundation DB keeps track of partition
stats but doesn't have any application
context the application of the layers
itself have both application context and
API that they can use to get partition
stats from foundation dB I mean we may
have made some changes to it to give you
both the storage and the port
information but it's a trivial change
that can be ported to the open source
quite quickly and in and and so now if
you take your application context and
merge it along with the partition stats
then you kind of know where your data
accesses is are going which storage
nodes are they going very right it's
really flowing - and then we keep stats
for every single transaction we we just
buffer this up in memory and when it's
time we flush it out to disk if you're
running very high throughput you can
switch over to sampling this is a sample
stat all I really want to show is that
we have partition ranking from we call
it partition rank but it's really a
shard in FTB terms and we see AHA here
oh we fit so many bytes from here we
said so many bytes there and then you
take this information in our case we
push it back into snowflake because we
can create easily you can push it
anywhere else you want to be I've heard
the FT B team is considered pushing it
back into FDB itself and running queries
on top of it but you know it's very
common to see different distributions
for your data where is it
a large amount of of certain kinds of
data and very little of the others this
in itself is not a problem
however skews in data access is a
problem and here what we've done is
we've tried to figure out how much data
is read or written per minute for like
top partitions and the and that's the
graph on the right by the way oh sorry
that's the graph on the left which is PI
partition what are the reads and then
the graph on the right is by the entity
so this is the graph on the left is the
view from the FGB side the graph on the
right is the view from the application
side but they've both been sort of
merged and they're sort of looking at
them together so what do you do you
address this in various ways like the
first two or three sort of deal access
patterns here are clearly egregious and
need fixing you can cache you can fix
your accesses but you know if you're
going to access close to a gigabyte a
second or so you gigabyte a minute and
at least on our system you will cause
problems and that's it thank you
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> Xf6b-PAdIFc </VID>
<CONTENT>
well my name is Torsten I'm one of the
product managers at snowflake and so
this is a sponsor talk so I'm by no
means an FTP expert but I do want to
walk you through some of the highlights
of snowflake which as you know is
heavily using FDB and you might have
heard this before during the day so one
of the foundations for snowflake is what
we call a multi cluster shared data
architecture what it means is that we're
very disciplined about separating
compute from storage and that gives us a
number of interesting capabilities so
the first one is everybody that's
working on the same snowflake account
it's working on the same data set so
they're all seeing the same
transactionally consistent view of the
data no matter which team or which part
of the company is making changes to the
to the data set in addition to that you
if you have different teams or different
departments in your company you can
define and create independent compute
resources that are powering your team
and they then get access to the shared
data set and they're independent of
whatever other teams are doing over the
same data this has a great benefit that
you can do workload separation so for
instance if you look into this busy
picture here at the top you can see
there is data loading going on ETL
workloads are happening and in the
bottom you have for instance
dashboarding power users they're using
for instance to blow to do bi whatever
happens on the data loading side gets
its own dedicated compute resources you
see this little sequel cluster that's
sitting there so that's the independent
compute for data loading and then at the
bottom you have different compute
clusters that are powering the BI
experience for users that are using
tableau so you have this workload
separation the other aspect is you can
also scale these compute resources
independently of each other so for
instance if your data science team needs
massive scale out compute capacity you
can have that for them in a dedicated
computer cluster while other teams are
working with much smaller clusters and
then last point what I mentioned here is
you can also give the same team multiple
clusters and that essentially gives you
the ability to get virtually unlimited
concurrency so unlimited numbers of
users or queries and running at the same
time over the same data set so let's
drill a little bit into how we are doing
this so this is an architectural
blueprint of the different layers that a
snowflake is is using at the top you see
what we call the cloud services and
essentially they are first of all making
sure that when a connection comes in
that you're authorized and authenticated
to work with snowflake and then as the
query goes through the different layers
we are compiling a query plan we're
taking care of transaction management
and all of that is backed by metadata
that is stored for all intents and
purposes in an F dB so once a query gets
submitted for execution then it goes
into the second layer that you see here
this is where we have our so-called
virtual warehouses those are these are
independent compute clusters that you
saw on the previous slide and they're
connecting to the third layer at the
bottom which is the data storage where
snowflake databases live what's nice
about this is the tiered storage
architecture architecture between level
2 and level 3 so we're using the local
memory and the local disks on the VMs
that are powering this this middle layer
the virtual warehouses we're using that
to cache any data that you are
frequently used for for for your queries
and that that saves a lot of round trips
into remote storage for for the third
layer alright looking at this storage
this might be a term that you also have
heard earlier today the way that
snowflake organized it's it's it's data
internally is into so-called micro
partitions and this is done
automatically as the data is being
loaded into snowflake we're taking the
data and we're cutting it into micro
partitions that are a couple of
megabytes maybe a few tens of megabytes
in size what we're doing as part of that
is we're transforming the incoming data
into a columnar representation and we're
also building up metadata structures
that allow us to reason about what's
contained in what partition this gives
us the ability to do pruning during
query processing at various levels so
first of all because of the columnar
presentation we can discard any any any
columns that are not participating in
the query we don't need to touch those
and then in addition to that the
metadata gives us the ability to reason
about which which micro partitions may
actually contribute results to the query
that you've just submitted and for those
where we are sure that they're not
contributing we don't need to touch
those partitions either so that gives
you great performance benefits obviously
and these partitions are also the unit
for our DML operations so when you're
running insert operations we are not
changing existing micro partitions who
are typically just adding new micro
partitions to the end now the one of the
cool pieces here is that's true for both
structure CH data as well as
semi-structured data that you may may
load into a snowflake no matter what
you're using as the incoming data format
we are converting the add which is
forming that into this optimized storage
that's based on micro partitions and
there's there's no schema or no hints
required to do that and as soon as you
submit a query that will automatically
benefit from from the optimized data
structure so you're getting the pruning
and the filtering that we just talked
about so that's a that's a bigger topic
for us so we'd like to make things as
automatic as possible for our users
we talked about micro partitions there
is no distribution key that you have to
define we are doing it automatically for
you
you don't have to worry about like a
high availability configuration failover
between different virtual machines all
that comes automatically out-of-the-box
there is no vacuum you don't have to
define specific statistics to make sure
that your queries run fast so although
it comes out-of-the-box virtually no
knobs and the time to choose the great
performance for your workload is super
small so let me jump over into quick
demo so that we get a brief look of
snowflake in action and what I would
like to do in the demo is just show you
one particular aspect where snowflake
integrates into the spark ecosystem
so we have a spark connector that you
can deploy into your spark application
that injects itself into the query a
planned generation process of spark to
give users a highly optimized experience
when they're storing their data in
snowflake so what I've done here
essentially I've taken about two
gigabytes worth of tweets from Twitter
stored them into s3 and you can see
those files here and let me jump over
here I have browser window with some
queries over that data in data bricks
you can see here I'm populating a data
frame with the data that sits in the
bucket in s3 over on the left and you
can see this is the schema that we're
getting it's all JSON lots of properties
in here if we are doing account you can
see that it's about 3.2 million
different tweets that are contained in
the data set that I have in the bucket
and if you squint you can see that's
down there it takes about half a minute
to run the count operation and running
this on a two notes bar cluster so to
compute notes one master note pretty
standard configuration are just clicking
through the cluster setup and here's a
little bit more involved query so over
these these tweets I'm doing a group by
the language property and then just
counting to get the most popular
languages for the different tweets and
you can see English and Japanese are
awfully popular here and again if you
squint you see that takes about half a
minute to to run so that's kind of
interesting now let's take that same
data set and bring it over into into
snowflake and I've done that over here
you see a tweets table that lives in a
snowflake database if I click on this
you can see that we are storing the JSON
in a variant column so this is our data
type for this semi structured data like
JSON and Park a that I talked about that
automatically does the translation into
the internal storage representation and
now let's jump back over here into a
different browser window where I'm
connected to a somewhat smaller cluster
just one compute node instead of two and
I'm
- snowflake and let me run a couple of
queries here against snowflakes so this
is the first one so you're just checking
if we can get a connection to my
snowflake warehouse and that should
hopefully just finish in a couple of
seconds and spit out the current date
and you can see today is December the
11th and you can also see that here we
are essentially telling the spark read
operation to run a query with current
aid against snowflake so let's do
something more interesting here let's
populate a data frame this data frame
with all the rows in this table the
tweets table that we just looked at over
on the Left listener on this and then do
the same count operation on it and you
can see here the JSON is coming back for
the first couple of rows
here's a count operation in about two
seconds the same 3.2 million JSON
documents now here I'm running an actual
snowflake query to populate another data
frame and you can see here in the syntax
I'm using some of the built in snowflake
sequel constructs to work with semi
structured data in snowflake let's send
this off and there you can see we're
getting languages and some texts back
and now let's run this query here which
does again the same grouping by language
and counting the tweets per language and
you can see that same result in about
three and a half seconds coming back now
the nice thing again here is we're
running a much smaller cluster backed by
a snowflake warehouse and you can see
some of the performance benefits here
which which are due to the to the
internal optimizations that snowflake
does behind the scenes and know that you
literally have don't have to do any
changes to your spark application code
so the connector injects itself
transparently into the plan generation
process whatever transformations you do
over your data frames will look at them
and figure out which ones are relational
in nature and backed by data that sits
in snowflake and will automatically
translate that
into sequel queries and run over slope
in snowflake we can take a quick look at
this here so here is the sequel query
for this the does the counting and down
here you see the group by language so
this is the sequel query that was
automatically generated by the spark
connector when we when we submitted that
that last group by statement in in spark
so with that let me jump back in here
and the great software only exists
because of great engineers so obviously
being a sponsor talking wanted to show
this for a minute we are we are hiring
in into our development offices one
local here to the Seattle area down in
San Mateo as well as in Berlin Germany
things that we are working on are
obviously performance one of the most
recent things in that space was
materialized views which where we were
taking a fairly fresh view on how to do
materialized views for relational
databases on the areas that are of
interest to us is the whole data science
machine learning space and how do we
best support these workloads from a
snowflake perspective modern enterprise
data architectures like how do we
integrate into application stacks like
spark which we spend some time on today
and then obviously performance also for
our metadata layers in our cloud
services particular F DB for metadata
scale and then also increasing our
footprint growing into additional cloud
regions both in AWS as well as an azure
that's all I have for today thanks very
much
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> U6h17dgmkh8 </VID>
<CONTENT>
so what I'd like to share is what does
it take to take all this energy and this
positivity that we have today as a
brand-new project and how do we sustain
it how do we make sure that this project
is here 10 years from now 15 years from
now and that it's successful and it's a
thriving community and my name is nithya
ruff I'm a mother
technology strategist for Comcast I run
the open source program office at
Comcast I consider myself a pragmatist
and not you know pure idealist on one
side or the other and and that's
important in shaping my talk I'm really
passionate about the fact that companies
should really work outside of their
sphere to innovate and not just you know
inside the company innovation comes from
everywhere an open source in fact allows
us to collaborate and innovate with
people all over the world I advocate for
inclusion in technology in various
forums I sit on the board of the Linux
Foundation and represent diversity I I
consider myself a woman of color she
heard that's the classification I go by
so let me get to my talk after
introducing myself and Dave luster thank
you so much for inviting me it's
fantastic to be here so my question to
all of you is is organic growth of a
project good for a project and what I
mean is you know sometimes we think
organic natural it's good you know
there's nothing added it's not
manipulated it's not changed it's not
planned it just grows by itself
naturally and that's a good thing I
contend that for food maybe it is a good
thing right because on organic food for
the most part I think most of us will
say organic food is a good thing it's
pure it's clean in its unadulterated
it's untouched and it's healthy but I
also contend that organic open source is
yet another thing and perhaps it's not
so good to have organic Oh
source and what I mean by that is just
letting open source kind of grow by
itself project for example without you
know some amount of thought and care and
intention and and many times we have
very long held beliefs in open source
that really hinder us from growing a
project or sustaining a project
successfully we often get trapped by our
own thinking and we tend to think you
know if it's good it'll just grow by
itself so I'd like to kind of challenge
some of those myths that we all believe
in not all of you maybe but some people
do and and then kind of talk about what
it really takes to be a successful
project to sustain a successful project
so one of the myths that we all tend to
some sense sometimes subscribe is that
if they build if we build they will come
that if we build a good project that you
know people will discover it people will
flock to it will start using it and it
starts kind of organically growing and
it becomes magical and it you know just
grows perhaps it was true you know about
15 20 years ago in the beginning days of
open source when there were very very
few projects right and you know all of
us have heard the famous story of
leanness is email and you know the world
kind of said okay we'll get involved in
linux and soon you know linux became a
big big project but it's not always the
case today for example there are about
seventy two million repos just on github
and then you know i haven't even looked
into SourceForge and get lab and other
places so when you have this kind of
paradox of choice and then there'll be
hundreds of database projects alone many
different libraries for doing a certain
thing and you kind of then say gosh how
the heck do we communicate to someone
that we are here especially as a
brand-new project and how do we make
sure that people get involved whether as
users or as contributors or committers
etc so what happens is today it no
longer is sufficient to
create a project and tell your friends
and then you know it takes off you have
to create awareness in fact marketing
has become quite a science now in
open-source you've got to create a brand
awareness for the project you've got to
tweet you've got to have blogs you've
got to go speak at conferences you've
got to have of course a logo and you've
got to have stickers and you know all of
that good stuff and and and that's what
it takes these days to go out and
actually create a Venice for your
project the second thing one often hears
is that open-source is quite different
you know planning is for companies
planning is for commercial projects
open-source needs to be natural and
organic and you know goodness and
sometimes we tend to think that it's it
doesn't need the kind of intention or
planning that projects in the company
and commercial space do the key
questions though when you that you would
ask an open source and in commercial
projects is often the same every project
needs to have a goal every project needs
to ask why do we exist what problem are
we solving who cares about this
particular problem and how do we then
reach that target audience and you know
how do we welcome this target audience
and you also need to ask a bunch of
other questions what kind of license to
be used because what kind of behavior
are we looking for from our contributors
and from our developers that want to get
engaged in this program
do we want to CLA or not what kind of
legal documents we do we need for this
project and very often in the early days
of open source many developers were
quite well-versed in licenses and
licensing information but today we often
don't spend time learning about licenses
or you know what the intent of each
license is and what kind of behaviors it
can create you know if I use a GPL what
happens if I you
and apache2 what happens what do I want
do I want corporate developers getting
involved or do I want contributions back
into the project they don't want
contributions to be you know hidden away
by people who make the changes so you
got to think through some of this before
you launch a project and you also have a
choice these days in the early days of
open-source projects were often you know
standalone and today you have the
benefit of foundations you have the
Apache foundation you have the club's
foundation you have the software freedom
Conservancy you have the Linux
Foundation you have multiple homes for
these projects to be housed in and
projects in the foundations often get an
umbrella of benefits whether it's legal
advice or business development marketing
or events or other kinds of support and
sustainance
and more importantly it gets a neutral
home for instance when I look at some of
the projects that we've created at
Comcast there are pros and cons to
hosting it ourselves at the Comcast
github i/o and then sometimes it makes a
lot more sense for us to host it at the
Apache foundation or the Linux
Foundation and we've often done that
because we wanted to provide a neutral
home we wanted to make it grow you know
differently and sometimes you know the
company a single company glow may not be
beneficial for for the project itself
the third myth that I often come across
is good coders will you know figure
things out you don't need any onboarding
you don't need any documentation you
don't need any help and this used to
happen particularly in the embedded
space I used to be in the embedded space
I worked in the octo project and Yocto
is a distribution builder that allows
people to build their own custom
distributions and we often used to say
hey you know if he's not smart enough or
if she's not smart enough to figure this
out then they don't deserve to be in the
project
and you know they don't need any
documentation they can figure this out
and maybe it was right in those days
when you know the pool of developers was
very little but today you find that
there are a couple of different reasons
why you need to make sure that you have
good onboarding good documentation good
structure for the project one you often
find that 75% of projects on github have
one or less maintained errs and and
often these maintained errs are bearing
the burden of the entire project and
they're often burning out and they have
no help and they have no support and if
they choose to leave or god forbid you
know you think about the bus problem
right they get hit by a bus then what do
you do and you do need to make sure that
you have succession planning and you
have at least different roles in the
project and you have people working on
you know maintaining the project beyond
the main maintainer the main person who
started the project so that's one very
very big reason why you need to create
documentation create structure create
standardization of you know what's
happening in the project the second is a
lot of new industries are coming into
open source these days finance
healthcare even us from a media and
entertainment perspective via recent
entrants into open source and in the
last 10-15 years so you find that a lot
of new people and then new college
students coming out also I find that a
lot of us if you are underrepresented in
open source in the past and you're now
entering open source you struggle to get
through a project because some projects
are just not documented well they're
just not welcoming and if we are to grow
open source and if we are to sustain
open source and if we are to continue to
have you know people enter this business
and this you know culture that we've
created we do need to make sure that
it's easy and welcoming and it's well
documented
the next myth that I often hear and this
is happening a lot which is you know
open source is not necessarily the right
place for me to solve security
reliability and scalability issues its
it'll be done by the user you know when
they start using it they'll do the
testing they'll do the patching then
they'll work and make sure that it's
scalable in their organization and very
often we kind of say you know it's only
necessary for us to work on the
functionality and then the users can
worry about you know all of these things
but it's not necessarily true anymore
you find that as we use open source from
abroad broadly we need to really build
in more security into open source and
best practices around reliability and
scale upfront and cannot be an
afterthought in fact some projects have
been born in data centers such as
Facebook's data center or Comcast's or
say googles and then released into the
open and they come with some of those
prerequisites built in because they've
been tested and tried in the data
centers of those organizations so it
really is important that organizations
especially projects take on some of
these some of this work in up front
rather than leaving it for users to do
and you find that you know foundations
like the Linux Foundation for example
has started projects like the core
infrastructure initiative whose job it
is to create best practices for security
and also to review security practices
for projects that are under their
umbrella and to help them to create
better practices and to they also do
badging they do reviews of your
practices etc so there is help there for
projects to build this into their
projects this one is often also cited
that open source is really
about people who are serious about
solving a problem it's about passion
it's about enthusiasm and that if you
build too much structure too much
process too much planning that it kills
it and that you know open source to grow
should be left alone on the other hand
some of the successful projects have
seen including the conference namesake
which is kubernetes really was created
with a lot of structure and planning in
mind including you know different groups
sub groups and the community and how the
communication will take place and how it
will scale and you know how planning
happens how commercial companies will
use it and and then mirror in open
source um you know vice versa etc and so
when you have structure it it actually
allows for more improvisation and it
allows for more experimentation because
some things are codified some things I
documented some things are well
understood and so you can actually play
with it change it modify it and and keep
moving it forward as needed good
projects live forever and this is
something that I've heard also or we
don't even remember you know that
projects have a life cycle and projects
have you know a certain amount of time
that they live or they need some
intervention in between and we just kind
of you know give birth to the project
and then just think that it'll grow and
it'll keep you know moving forward and
what I find is that projects actually go
through a life cycle there's a launch
period where you have to do a great deal
of awareness building perhaps a lot of
course correction adjustment you're
putting some initial components in place
you know governance etc and then it goes
through a commercialization period where
perhaps you know companies are using it
companies are basing their commercial
products upon it there's a commercial
ecosystem that's developing around it it
becomes a much more thriving community
and this is often one of the peaks where
the
the project is extremely popular and
then it starts going down in terms of
you know it is reached everywhere it
needs to reach and it's gotten a lot of
traction and it's more in the sustaining
and the maintaining mode and the kind of
activities during the sustaining and
maintaining mode are quite different
than you would do during
commercialization or launch you probably
reduce your marketing you're probably
doing more case studies you're probably
you know doing more to kind of continue
the momentum of this project and things
of that nature and then there's the
sunset mode where you actually put the
you know the project to bed because
perhaps there's a newer and better
project that's come into being but you
still need to worry about all of the
users who are dependent upon the project
how do I make sure that they can still
continue to use it but that we are not
spending so much time and money you know
maintaining this project because it now
is is self-sustaining and it just needs
you know minimal support and work what
you learn from this really what I have
learned least is that project
sustainability really requires intent
and it also requires goals it requires
constant monitoring of where you are and
which phase of the project and what you
need to do to make it go successfully or
you need to provide the right level of
support for the right phase of the
project so I know I'm going much faster
than I expected Dave so that I'll give
you guys some time back it's really in
tension and planning that's needed in
order to sustain and grow open source
it's not just beliefs it's not just you
know give birth to it and then it'll
just grow by itself we do need to market
a project
you cannot just you know let it sit on a
github in among 72 million repos you
need to have a strategy you need to
understand what the goal of the project
is who it needs to reach how it
to reach them you know whether it's a
small project or it's meant to be
ubiquitous and reach as many people as
possible the kinds of users it needs to
reach we do need to worry about culture
everything from how we onboard people
how we make the project more inviting
more inclusive to how we communicate how
we are transparent in the project to who
takes care of the project what the
succession plan for the project is and
the culture becomes extremely important
and you know best practices there are a
lot of best practices for scalability
reliability and security and we need to
adopt those as a project you don't need
to invent everything yourself you don't
need to create everything yourself but
you do need to follow those practices
and frankly if you have a good structure
of the main core elements of the project
then it becomes easier to improvise its
it becomes easier to transition the
project to other maintained errs and
developers and it also allows us to
sustain the project if we have a good
plan in place for the various phases of
a project when I look at foundation DB
and I just did a very quick look at
foundation DB I find that you guys have
put a really fantastic you know plan in
place and there is a real commitment to
community over code and I think that's
that's really terrific because at the
end of the day a project is made up of
people and people are the ones who
create code and people are the ones who
create innovation and if we take care of
the people then good code follows and I
think that's a great practice that the
Apache foundation speaks very
passionately about and and I'm a big
believer in that
I love the fact that you guys have a
great code of conduct and code of
conduct is not to discourage people but
it's mainly to say this is how we'll
conduct ourselves as a as a team this is
we will be very respectful of each other
and we will be inclusive of people in
this project
and and this kind of a summit where
people can come face-to-face and talk to
each other develop relationships is so
so important because we often are
working remotely we are often working on
email and so I find that when I come to
one of these events and I have a
relationship that's built on meeting the
person looking at them eye to eye or
having a meal together it's often so
much easier to get work done remotely
then if I never knew the person and I
just have to deal with them you know
remotely all the time I love the fact
that there are so many communication
forums and it's transparent and it's
laid out nicely and you've provided for
structure you provided for tools you've
provided for ways for teams to engage on
the foundation level as well as the
add-on levels I like the fact that it's
in a neutral home and you know while yes
Apple is is the big benefactor behind
the project it's nice to know that it'll
be sustained and it it's ongoing and
that you know everyone can get involved
in the project and I think you guys
chose to do a light governance to begin
with which which makes sense because
you're saying I don't know which way
it'll go and what else we need to put in
place so we'll start with the light
governance and then we'll add and change
as needed and as we move forward and you
know being on github and and providing
some of the tools and some of the other
documentation the are the onboarding
guide etc is is fantastic so I thought
that you guys have already put a lot of
great elements in place to create a
sustaining and a successful project and
just to kind of end the talk if you want
to look at some of the projects that
we've put together it's at Comcast at
github do we've hosted some there and
some we've kind of donated to Apache and
then some sit you know outside of the
company again to kind of see where is
the best home for the project and you
can see what we're doing from an open
sore
perspective at that place and those are
some of the attributions in and I hope
I've given you some some of my thoughts
around why some of the organic
mechanisms that we often believe in on
some of the beliefs that we have are not
always the right ones and that we need
to actually do planning actually
understand goals actually understand
intention when we want to create a
successful project thank you
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> fN25ERr5nck </VID>
<CONTENT>
this I'm now gonna talk about something
that's really special to me which is the
new multi region support that was
recently added in six oh and it's
special not only because I spent the
last year-and-a-half painfully
implementing it but also because it
removes a really big caveat that
foundation DB has had up until this
point which is that generally if you're
as a user choosing foundation to be one
of the reasons you're using it is
obviously like data safety and
availability right you want your
database to be like always alive and
never lose your data and so the fact
that foundation DB has basically been
generally designed to work within one
data center has kind of been that caveat
I was talking about it's it's like well
it's great if they're all co-located
together but I want to be safe against
failing a region and so like this the
six oh release like is gonna remove that
caveat and so I'm really happy to be
here and share this share the this new
feature with you
so already talked about myself and I've
already done a lot of motivation but you
know the the obvious reason why do you
want the multi region support you want
to survive you want to remain available
right when the region is out and the
other the other one that's a little
that's also important for some people in
some applications is potentially you
want to be able to serve reads locally
from a lot of different regions so that
can make a big difference for some
applications ah so coming to this
problem we had foundation DB and we're
looking at what we can we do with in in
multiple regions and the first thought
was sort of to take the same approach
that a lot of databases like sequel
databases use which is basically to set
up some asynchronous replication between
your primary region and a completely
different foundation DB database that
you're going to run in the secondary
region so these are just completely
independent data databases and we're
basically shipping the changelog from
the first one and there's some external
agent to the system like these dr agents
we're taking the data and applying it to
the other region in
in order this approach it has a huge
flaw which is that basically if you lose
your primary region right just like it's
a synchronous replication you're going
to lose some amount of data if that
hasn't been synced yet from the primary
to the secondary if you just
instantaneously lose your primary so
this has leaves you like with a really
really hard choice as an operator right
because your database is down and most
databases failures like a region failure
generally is not permanent unless you
know there's something really bad going
down
so you're stuck with like okay do I wait
till it's back or do I choose to lose
some data and no one wants to make that
choice it's if you are losing data
though here's the sales pitch it's the
best kind of data loss you could have
because you're gonna lose just the tail
of a mutation log so you're basically
going to roll back to a consistent point
in time but still no one wants to make
the choice um
the other kind of bad thing about this
design is because these two databases
are completely separate they actually
don't have the opportunity to cooperate
so let's say we were running double
replication in both sides and in the
primary there's not a region failure but
we just lose both replicas we lose two
machines simultaneously we'd really like
it if we could heal from that by
grabbing the data from the secondary but
because they're different clusters like
there's no ability to do this healing
across across the regions this generally
is going to mean that we need to run
with more replicas in both sides which
is obviously going to cost you something
so our first attempt at doing something
better here was what was called three
data center mode in the 500 releases or
it's still there in 600 and the basic
concept was well let's just take
Foundation DB and spread the processes
across regions um and this approach
works but it comes with some pretty big
caveats so the first one is you're
basically the the way the setup works
first off um is that you're gonna have
three different regions and you're gonna
put your transaction logs in two of the
three regions and you have storage nodes
across all of them like two and each two
swords replicas in each of the regions
for six total because we're
synchronously replicating to multiple
regions on the transaction logs we now
can survive a region failure with no
data loss so that's you know checks that
checkbox
however the they're the costs here are
that basically the system wasn't really
designed to handle this configuration we
sort of jammed it in there by spreading
our processes everywhere so you're gonna
have more because you're replicating
across regions you're gonna have a cross
region network latency as part of your
commit pass so that's gonna obviously
increase your latency Xand for some
applications having 40 milliseconds is
on your commits is going to be a big
deal the the other thing is that
basically the data distribution
algorithm that we have is really
targeted for machine failures not region
failures and what you want to do in
these two cases is dramatically
different so if a regular machine fails
you really just want to replicate it and
like heal from that loss and put the
data somewhere else if an entire region
fails you know you're losing one third
of your total capacity it would be a
disaster to try and copy all of the data
from all of those machines to other
locations so basically what we had to do
with this design is effectively when a
region fails disabled a distribution
altogether so this means that while
you're in a region failure scenario
you're in inherently degraded State
you're pretty fragile and it means that
basically an operator of the system is
going to need it to drop the region
that's failed immediately discarding the
replicas that are there so the system
could get back to a healthy state so
that's pretty painful the the final
thing I'll talk about that's that's not
great about this this mode is that it
has no awareness of the locality of the
machines so I talked previous
presentation about how the transaction
logs and the storage process ease oh I
have like a buddy system where for a
given storage node there's one
transaction log shipping it's all it's
data well in this node model the
transaction logs are spread across two
of the regions and the storage servers
across three and basically there's
no attempt to match up the transaction
log that's serving data to have a store
to a storage server in the same region
so this is gonna explode the amount of
wind traffic you have across region
traffic you're gonna have because
basically for all six of these storage
replicas they could potentially be
grabbing it from some transaction log
across the network and even originally
when you're writing the data to the
transaction logs those were Tramp
traveling across regions so you saw a
given mutation might go across the
network maybe eight times here um so
basically that's that's where we were at
five - we had this asynchronous
replication option that had this manual
failover with with the potential of data
loss and the two sides didn't will it
cooperate then we also had this three
data center mode this policy based
replication it had high cross region
Layton sees the high overhead you know a
lots more storage replicas in this
inefficient way in communication so the
goal with the six oh release was really
to try and combine these approaches into
something kind of unique and I think is
really special so we're gonna do a
synchronous replication within a
database and then some policy based we
use some of the policy based designs
from the other from the three datacenter
mode on the transaction logs and what
we're gonna do is take advantage of sort
of the geographic features that are kind
of provided to you by cloud providers
today and that is that basically you
know like AWS or whatever already has
these two different notions of locality
right you have regions which are
generally going to be distinct
geographic locations that are far apart
from each other and then within a region
you're gonna have availability zones
that are just still distinct geographic
locations usually however they're pretty
close together and so there's like a
difference here the the being farther
away a part is going to isolate you
better from failures for correlated
failures but being close together is
going to give you a lot lower latency so
the mode that we've come up with is
basically taking advantage of this
difference and so we're going to make
do synchronous replication of the
transaction logs to multiple
availability zones in one region and
then do asynchronous replication of the
actual physical storage data across the
regions what this basically means is
that in the event that we lose one of
the availability zones wherever we're
printing writes at the moment um we can
copy the data from the other
availability loan zone and it's just the
most recent history the last little bit
of the the transaction logs history we
can get that shipped to the other region
and then we can just seamlessly and
automatically failover with no data loss
and and basically as long as the
availability zones the to availability
zones don't die within you know ten to
thirty seconds of each other it only
basically like you only have the they
don't have to survive both availability
zones it zones don't have to survive a
very long time just enough to like copy
this last little bit of data so we're
getting the failure resilience for the
most part of being in multiple regions
but we're only paying the latency cost
of talking to multiple availability
zones and this is really powerful it's
kind of a best of both worlds scenario
um so I think I said this a lot of it at
least but I'll go through it so the
commit latencies are only talking to all
of the availability zones in a region so
very quick commits Layton sees again and
storage replicas you only need to in
each region so this is much better
compared to the each of the other
scenarios are described basically you
only have four total storage replicas
because we have that because we're all
one cluster we can use them to heal we
can use copies in one region to heal
another region so you can lose all both
replicas in one region plus another copy
and the other region in your database is
still running just fine and then also we
like optimize the design to only send
every mutation across the network
exactly one time and I'll get into how
we do that but it's so it's going to be
significantly more efficient than the
previous implementation so it's time to
bring back the boxes
so if you look inside of region one
you're gonna see a diagram that's very
similar to what I described this morning
it's got all the components there and
generally we're basically going to be
accepting commits in that in that like
that primary region and the only thing
that's really different about a 600
configuration will all go through the
differences is that when the proxies are
writing stuff to the transaction logs
they're gonna make sure the stuff is
durable in both availability zones
inside of that region so the second
region you know just has those just has
those extra transaction logs and so
you're paying a little bit of cost but
not too much to replicate your data
there once the after everything has been
committed we're gonna we have this new
role called a log router which is going
to be responsible for pulling the
mutations across the network across the
regions and it's going to pull every
mutation across it exactly one time so
basically the way we accomplish this is
every mutation is basically when it's
created or when it's like committed
assign a random one of these log routers
and that one log router is responsible
for pulling it across the network just
purely random then that means that the
log routers now have combined in total
have exactly one copy of everything and
so the transaction logs on the other
side will reindex the data for the
storage server that for the local
storage servers and so basically they're
pulling they're combining results from
all the log routers and redistributing
it so a lot of changes went on under the
covers that you know are not in my
diagram here related to these
transaction logs because we had to be a
lot smarter about the pairing between
transaction logs and storage servers as
a little bit mentioned basically we only
want storage servers to be able to grab
their data from the local transaction
logs to prevent the crosswind traffic so
what happens when our region one goes
down well the first thing that's going
to happen here you can notice that the
other AZ has survived and maybe that's
temporary so the the first thing that's
going to happen is the cluster
controller that the coordinators are
going to detect
that the previous cluster controller
died and they're gonna pick a new one
over in the other region this cluster
controller is then gonna spin up the
entire system and the the new
transaction logs are going to use the
log routers so stream the last little
bit of data from those lat from those
last remaining transaction logs across
the network and this is the part that
you know hopefully is generally quite
quick
I put 30 seconds as an upper bound but
generally is gonna be a lot quicker than
that
once we've strained all the data now
we're completely safe even if we lose
those other transaction logs just a pure
short-term storage and the database will
just continue seamless you know
seamlessly running in region two you
have the option of having a different a
Z on the second side which might give
you some better failure probably
properties when failing back to the
first side although it's optional to
configure them the coordinators in this
scenario you'll notice that there's a
third region here that has some
coordinators in it the coordinators as
you'll recall are relying on quorum
based logic to do to provide like
failure properties so we need a majority
of them alive and so if we want the
failure property of surviving one one
region failure plus one additional
machine failure like three coordinators
in three different regions is a nice way
to accomplish that you can you know if
you lose losing a region takes down
three of your copies an additional
machine will take you four and there's
nine total so you still have a majority
um so what's next here so foundation TB
is like the six oh release has all of
this in it in working today it can be it
can you know fill over to one region
fail back to another region however
there's still you know some work to go
and there's still some things we'd
really like to add the current
implementation only supports two regions
I mentioned all the way back at the very
start that one of the reasons you're
going to want this feature is
potentially to do local region to
replicate data like look to
do local reads in different places and
so because we only have two regions
support if you're using this for reading
from lots of different places it's not
quite there yet we're hoping to get
there if also even though we think is a
good trade-off between the availability
zones and regions in terms of your log
replication you you might be super
paranoid and you might not care about a
40 millisecond commit latency so you
might want to synchronously replicate
those logs across the network instead of
doing the async plan I showed so that'll
come to probably in the next release ah
the other caveat the other big caveat
here is there's always the potential
that you lose an entire region or that
in which case in the previous in this
design here if you lose both like all of
your key logs simultaneously you may
want to switch to the other side even if
that means data loss so this is
equivalent to the FD BDR trade-off
before so decision no one wants to make
but we want to let you make the decision
in the worst case scenario that like a
meteor takes out something you know like
and there's probably easier ways that
you lose both availability zones at the
same time so that feature exists you
from the CLI already in sick so however
it's not tested to the same standard as
the rest of the codebase there are some
really rare correctness problems related
to the fact that if a machine comes back
alive in the region you thought was dead
at the same time you're doing the
command it could possibly like have a
corrupt view of the world
so in any case I want to throw it out
there because we're super paranoid about
these things and but probably it's safe
but be careful the last thing to talk
about is um right throughput is
currently going to be reduced when a
region is filled so while a region is
down we enter a performance mode where
the transaction logs are having to queue
up all of the data that's bound for the
other region and currently the
transaction logs just aren't haven't
been optimized for this use case so what
this means is that generally when a
region goes down in this configuration
you're gonna have to just like with the
three data center mode you know what
then if you have a high rate bandwidth
workload you're gonna have to configure
it to drop that remote that remote
region pretty quickly so that you can
flush out the log data that's being
queued up for that region the last thing
I'll mention here is replicating to
multiple regions adds a new thing to
monitor which is that you really need to
pay attention to how far behind one
region is from the other region because
the amount of data that's queued up in
the log system down for the other side
is going to determine what you have to
copy on a region failure so if this
thing gets out of hand and is an hour
behind the other side well you're no
longer safe against a region failure
because you're gonna spend a long time
copying that out at that hour of data
before you can recover so it's really
important operationally to monitor this
lag and if it gets you no more than a
few seconds to figure out what's going
on so that's all I have thank you guys
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> nlus1Z7TVTI </VID>
<CONTENT>
this is about the future of FTB storage
engines my name is Steve Atherton I've
been let me use this thing I've been
working on foundation DB for about four
years I've done a bunch of different
things but the thing I'm here to talk
about is storage engines in general and
the Redwood storage engine which I'm
very excited to talk about today so this
presentation is gonna hopefully have
about four parts and minimal pauses and
mistakes made by the speaker so first
I'm gonna talk about storage
architecture of fundation DB and then
review current storage engine options
talk about what we'd like to see in
future storage engines and then
introduce the Redwood storage engine and
some of its technical highlights so
what's an f DB storage engine so its
main purpose is to persist keys and
values to disk so it's not distributed
it lives and it's used by a single
process from a single thread which makes
it the most exciting part of this
distributed database okay
maybe not but it's really important
because about 90% of FTB's of an f DB
clusters processes are half storage
engines and the other 10% are designed
to funnel data to those storage engines
as fast as possible so just a little
block diagram here we have to have one
every day you know there has to be one
system diagram and every presentation I
think is the rule so we so this is
showing basically where the storage
engine fits in to FTB's architecture so
we have this distributed log system and
we have a storage server role the
storage engine lives inside the storage
server every storage server has exactly
one storage engine instance the storage
server receives mutations in version
order version order from the distributed
log system and it initially writes them
to two places in memory two different
data structures one is a tree like thing
that lets you efficiently point read and
range scan values of keys by their
version their sorry values of sorry you
can read keys and ranges
a very specific consistent version and
get of course their values which is why
you would never mind that was a blender
okay so the other place that the
mutations go is a structure that stores
blocks of mutations ordered by version
and then on a delay those versions are
about those mutations are applied in
version order on the storage engine so I
say on a delay because our storage
engines currently are single version so
once you've written something to the
storage engine you can't read the value
that was there before and so in order to
support reads during the five-second
window that that our transactions live
for we have we need to keep that data in
memory which is that little tree
structure on the right and not push
mutations to the storage engine until
they've left that buffer then
periodically and in practice it's
whenever once every one to two seconds
we commit on the storage engine and then
we send a message to the distribute log
system telling it it can forget the the
log it was talking to can forget
versions up up to that committed point
so commits always happen on a clean
version boundary so our current storage
engines there's two of them
SSD and memory so on the Left we have
our SSD engine is based on sequel light
so it's a b-tree on disk which has a
nice property of giving you instant
recovery for on on a cold start it and
it's as its name implies you're supposed
to use the storage engine only on SSDs
on the right we have the memory storage
engine which despite its name does
persist data to disk and exists as
essentially a binary tree in memory and
it has it's on this structure is a
rolling log of mutations and snapshots
of keys and values from the in-memory
structure so so as a result it has a
slow recovery
from disk it we recommend using SSDs for
the memory storage engine but you could
probably get away with using spinning
disks so that we have these two storage
engines and they're pretty great so what
else could we possibly want
well three main things first is read
only transaction lifetimes that are
longer than five seconds so note that
this is not going to increase the right
transaction length that's desert
determined by the version arable held in
the resolvers and fundamentally you
probably don't want to keep on
increasing that number in an optimistic
concurrency system because you're going
to increase the the longer you let your
transactions run the more likely you are
to have conflicts but to get see sorry I
lost my place another thing we want is
prefix compression because as you've
seen earlier today with like the
document model and the graph model
modeling data models on top of FDB tend
to use a lot of common prefix bytes in
their keys we'd also like better
performance particularly fewer disk
reads per key and more write parallelism
which are which I'll talk a little bit
more about later so regarding that that
five second transaction lifetimes so one
thing we could do which could be done on
top of foundation DB or it could be done
on top of a storage engine by a proxying
storage engine that basically turns a
single version storage engine like
signal light into a multi version
storage engine with being a multi
version layer so basically you'd store
keys as tuples of key inversion here's a
table showing some examples so we have
three keys that were set at different
versions and two of them were cleared so
in this model reading a key becomes a in
this model reading a key becomes a
reverse range read from well with
basically from the version you want to
read plus one the way our ranges work
down to the down to version zero for
that key with a limit of one because you
so you're doing a range me but you
really just want the first result back
because you you say you want to read it
a at fifty and you don't actually know
where a was last read or cleared our
sorry said are cleared at but range read
performance suffers as you accumulate
old versions so in this example if I
were to range read from A to D at
version 30 I would read over six key
value pairs and ratone only one so and
you also have to scan your entire keys
base to remove expired versions at some
point so we don't really what so we
don't want to do that we'd like to push
multi version support into the storage
engine and do something more efficient
so in general FTB storage engine
requirements and what i'd like to review
this now so it has to be an ordered key
value store you of course have to be
able to read and write keys you need to
support range read in forward and
reverse order some certain encodings
could make reverse odd you know awkward
but that's the only reason why i bring
that up
here's an important one you need to have
fast range clears so that is to say that
your range clear operation has to take
immediate effect and not significantly
harm subsequent reader what or right
latency it can have background work that
that happens later and for a long time
as is the case in our current storage
engine but but the the clear age can't
stop or stall the speed at which you can
apply mutations to the storage engine
you also need to be to read data at a
committed version what we have today you
can only read the latest version commit
on the storage engine but what we want
for future storage engines is to be able
to read any committed version within
some defined some configured interval so
notably missing from this list of
requirements are low commit latency
because our distributive log system
provides papaya is what
determines our commit latency and
provides durability for FTB transactions
when you commit them so the storage
engine isn't involved until later so we
so we can buffer up rights and commit
them like you know periodically every
couple seconds for example we also don't
need concurrent writers because the
storage server is going to apply
mutations serially so there's no need to
worry about different threads or
different processes accessing does the
storage engine so I'd like to talk a
little bit more about our current SSD
storage engine which is based on the
sequel Lite b-tree which notably is not
a B+ tree and so quick review B B trees
have values inside their internal nodes
and B plus trees do not the so as a
result B trees tend to have worse
branching factor a branching factors
than B plus trees and so we which in
turn will basically sorry I lost my
train of thought there with a high
branching factor you could hopefully
reach a point where you only have one
out of cache read per per look up for
point lookup which is a great property
to have so sequel light is not optimized
for single write or throughput every set
and clear operation must traverse the
tree serially to its target page and
then modify it so as a result our writer
thread it's really an actor but I'm
calling it a thread in FDB only has
about one outstanding IAP at any given
time and sequel eight is also not as
optimized for large key value pairs and
it's not designed to be used in an async
framework it's not written for an async
framework so we've adapted it using Lib
core o which is a library for stack
folker routines and it's kind of it's a
lot of complexity and we'd prefer to
have a storage engine that was written
in flow that's not to say that we
wouldn't do the same tune a stiix again
to AB dab some other great storage
engine it's just that you know
right now that sorry I totally it's just
we're not doing that right now we we
have some ideas in mind for we want our
storage engine to do and nothing else
does it exactly so we're writing it from
scratch
so the first decision to make is do we
want a b-tree or in the you know B+ tree
of course or an LS M so a B+ tree
optimizes for read performance which is
in line with the rest of FTB's
architecture Ellison's do usually have
fast point lookup using probabilistic
hints like bloom filters or cuckoo
hashes but range reeds are very common
in FDB applications and probabilistic
ants are less useful there but I
understand there is research being done
in that area a good example of this is
non-unique indexes you'll have some
index identifiers some value and then
your primary keys are the last part of
that key so you need to range scan your
index name and value to do a lookup and
that index and get all the primary keys
of the relevant records so without
native versioning like for example
people often ask but rocks DB without
native versioning support we would need
to use something like the multi version
layer on top of that which has the
pitfalls discussed earlier so this isn't
to say that Ellison storage engine is a
bad idea it's just it's certainly not
and it's a great idea for some workloads
it's just not our focus right now based
on what what our needs are so so this
brings me to the Redwood storage engine
so it's a version to be plus tree on top
of a version of pager it persists
version history but it mitigates the
inefficiencies of the multi version
layer design I'll talk more about this
later so at this point I'm just kind of
reading bullets to you and of course it
has a key prefix compression which I
mentioned earlier and I'm gonna talk
about that in more detail later so a
quick review of what a copy-on-write B+
tree is so here we have a b-tree root
node and and we're gonna show the child
length of H
points to page 7 so there's there's that
child page and it's in our child page
and so when you want to modify this
structure you the the sequence is you
first copy the page then you modify it
so here we've we've added hi equals Z at
the leaf level and we've copied page 11
to page 25 before we made that
modification so we've done this and now
we need to make page 7.2 page 25 so we
have to update the parents pointer which
means we have to copy page 7 and and
make the appropriate change and then we
have to do it again all the way to the
roots and we have a new root and the
nice thing about this is we don't have
to have a right ahead log because we not
left our data structure in an
inconsistent State on disk at any point
the atomic like the point in time at
which all of the new data is visible
from the tree is that last step where we
updated the root and so this is
expensive for random writes because so
if you have a branching factor of 200 to
1 and you have 4 levels in your tree if
you touch 200 random leaf pages you're
likely going to have to touch 200 random
parent of leaf pages to update those
pointers because your third level of the
tree is also larger than 200 pages and
then probably also most of your second
level will change to so it gets the
problem so you get a lot of write
amplification basically so we can limit
the copy-on-write
cost using indirection so here I have
the same three nodes the same setup as
before and on the right I'm going to
show the same sequence using indirection
with a page table so this page table
Maps logical pages to physical pages and
so now the same 7 11 and page numbers
that are in my be tree nodes those are
now logical pages instead of physical
pages so whereas on the Left we copied
page 11 to page 25 and modified it on
the right we keep page 11 as page 11 we
write it to a new place and we update
the page table to say
the new place with the new slot where
page 11 is physically located whereas on
the Left we still have to do the copy on
a copy upwards to the root so redwood
has a version 2 pager which is like that
page table we just saw but it also has a
version dimension all memory all entries
of the of the page table are kept in
memory at all times and the on disk
format is is very much like in fact the
prototype it's literally exactly the
same thing as the FTB memory storage
engine as a result recovery from disk is
slow and so to avoid that the in memory
state will be stored in a shared memory
buffer that lives that that can survive
graceful process exits and restarts and
the new processors are just attached to
it and use that structure but of course
if you you know powered out and power
off the machine rebooted etc you're
gonna have to do a slow recovery from
disk so the the sort of version B+ tree
on top of this pager basically it
consists of logical pages that are all
red at the same version so there's many
in a sense there's many versions of the
B+ tree because if you start at the root
and read it at some version and then
read every page below it at the same
version you essentially have a like
unchanging version of the B+ tree like a
snapshot of the entire B+ tree so within
a version within a page you can have
multiple versions of the same key but we
control the amount of history to avoid
that's that slow range read effect that
we talked about earlier where as you
accumulate older data you're getting
less your weeds are less potent in terms
of actual useful results you can return
also it's notable that prefix
compression makes this cheaper because
if you have you know a at 5 a at an 8
you know 15 like the a part you know it
could be some long key it cancels out
and even the first couple bites of the
version could actually sorry not cancel
out but prefix out
so even our versions are as I mentioned
earlier versions are actually pretty
long there are these versions for the
well for the purposes of this interface
they're going to be 8 byte versions and
it basically if you write a three times
rapidly the first few bites of that
version of probably unchanging and can
be borrowed from the earlier node well
I'll get an actually I'll get into
prefix compression more later getting
close to the end ok so another property
of Redwood is a high branching factor
which is which comes it was as a result
of minimal using minimal boundary keys
and having key prefix compression thanks
so the last thing I'd like to talk about
is prefix compression and a little bit
about how Redwood does it so data models
on FTB tend to use repeat prefixes I
think I've said that before in last few
minutes and so string and turning can
reduce repeats but at a cost of
additional reads and additional
complexity in your application
I'd like to so ideally you would like to
just keep you it would be better to not
have to do any any string replacements
or enumerations and just you know
construct your keys in a way that that
is natural for your data so here we have
one option with the JSON model if you
can have some key equal to a value of an
entire document or you can have what the
document layer actually does which is a
bunch of separate keys and values want
one key value pair poor value in the
document so you can see if there's a lot
of repeat sequences there in those keys
sorry ok so one way to to do prefix
compression is linear so you basically
serialize the sorted set of keys as a
prefix length and then a suffix string
and that gives you the minimal possible
footprint
um and so here on the right I'm gonna
add some links that show basically each
where each record borrows its prefix
bytes from so as you can see they're all
just everything every record borrows
from that's from the previous record and
therefore to search this structure
it's Lin it's a it's a linear search
because you have to start at the first
key and read you know all of them to get
to the last one actually be able decode
it so is there a better set of prefix or
slinks could we could we could we change
these borrowing these prefix borrowings
borrowing relationships to get a better
search time well it turns out that we
start at the middle and work out there
we go
have some nodes borrow from the middle
and then some other nodes borrow from
those nodes we get a set of links that
look like this and then if we redraw
those in a different way this is the
same links here so the dotted lines are
showing the prefix source the prefix
borrowing source and the straight lines
are the solid lines of the child
pointers we get a binary tree notably
everything I've added to the binary tree
so far borrows from its immediate parent
this last one actually borrows from the
root it skips over its immediate parent
it turns out and I don't have time to go
into deriving this or but it turns out
that for any Bani binary tree whether
it's balanced or not there is one ideal
prefix source in your ancestry and you
can describe it with just one bit and
that one bit is telling you whether
you're whether you're borrowing from
your previous ancestor or your next
ancestor previous means the ancestor on
your left that is greatest and next
means the ancestor on your right that is
least this results in perfect prefix
compression and Lanier's and log and
search time without they'll be the old
additional overhead and this be hot
besides a binary tree is your prefix
length and that extra bit
so why does this matter it's not because
of space non-perfect prefix compression
gives you pretty good it gives you a
pretty good space-saving it's about
predictability because now we can we can
very quickly answer the question will
this set of keys that I want to add to
this compress page fit once I you know
fit fit in the page with it which has a
fixed size you know limit of say four K
at once they are compressed so that ends
up being really useful for meet if we're
adding to a page it's also really useful
when you have a bunch of sort of data
you want to bulk build pages you can
scan through it linearly and you know
exactly where based on just comparing
adjacent prefixes you know exactly where
you can stop your scan and then build a
binary tree because you know exactly the
point where the the compressed form
would overfill your page it turns out
that this also works at the B+ tree
level so here I have two pages and two
beats to be plus three pages each with a
small binary tree inside it and if
you'll notice in page seven at the
bottom the left side and the right side
and the root of the binary tree don't
actually have a previous ancestor or a
next ancestor in the binary tree but it
turns out that if you substitute the the
previous key boundary from the parent
for the parent page or the next key
boundary it it actually it well
basically you get you get exactly the
same effect so if you take a bunch of
data that's sorted and you build a whole
bunch of B tree pages out of it using
this this this borrowing bit you know
you using the same single bit precision
you know borrowing sorry prefix or
specifier that was terrible then you get
perfect prefix compression for that tree
now note that the the tree as a whole is
not always going to have perfect prefix
compression because
as you know sorry I thought I put that
here
so deletions can cause parent pages that
originally had ideal ideal boundaries
that the child notes were borrowing from
to basically have bytes that the child
pages are no longer borrowing because
the because the items that were that
we're borrowing the parents bytes have
been deleted so it'll drift over time
but it's again that's not that main
purpose but it's still pretty good
compression so that's that's all I had
I'm sorry I did run a little bit over
I'm in conclusion redwood is gonna bring
longer read-only transactions it'll be
faster for reading and writing and it'll
be smaller on disk it is on master bran
the master branch right now it's a work
in progress it's far from finished a lot
of the work done so far has been
experimenting it has been very
experimental and just kind of exploring
design choices there's a lot of check
ins that completely replace the results
of whether it's the content of other
check-ins but it's work work is in
progress it's coming along pretty well
that's that's all I had
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> 2HiIgbxtx0c </VID>
<CONTENT>
I'm Alex I'm from the foundation to be
Apple or from the layers team at the
Apple Foundation DB team and I'm gonna
be talking about a topic effective
client design and so you may think that
in if you're designing client
applications on top of foundation DP
that because you have transactions
concurrency is an easy problem and in
some sense it is for one thing if use
transactions correctly you can be you've
pretty sure that the correctness of your
system is is maintained in the presence
of concurrent actors the issue though is
that correctness isn't the only thing
you also have to worry about performance
and minimizing conflicts in your
workload can be one of the harder things
that a layer developer or a client
developer has to consider when they're
trying to design their application or
data model so I want to go into a few
techniques on how you might minimize
conflicts and design an effective data
model so first going into what a
conflict is so Evan talked a little bit
about this in his talk but a conflict is
when you have two transactions that are
trying to modify the same data at once
in particular in foundation DB every
time you do a read the client without
you even having to do anything will
record what ranges of keys you read and
we'll add this to a set of read conflict
ranges that it keeps in memory likewise
whenever you do a write it modifies a
separate set of write conflicts and then
when it goes to commit your transaction
it submits the read conflict set and the
write conflict set along with any
mutations and it's these conflict ranges
that it's that the resolver you use in
order to determine which transactions
need to be failed so what happens if you
get a conflict well typically your that
you're going to retry and what that
means is that you have two performance
problems that you'll run into one is
that each time you do an unsuccessful
attempt at committing something you'll
end up wasting of resources on the
cluster and this means that if you have
a lot of conflicting things you can end
up decrease in the total throughput of
your system because a lot of it being
used to handle these things that don't
end up doing any work they don't get
committed so that's a problem and the
other problem is that you have an
increase in observed client latency then
in particular if every time you retry
your if you get a request from a user
every time you retry that's another
round of requests to the database that
your user will have
to wait through and so you're observed
client latency is going to be higher and
so we want to so that's pretty bad if
you're both decreasing your throughput
and increasing your latency so what can
we do about it so I'm going to outline
three separate techniques that a client
might use and they are using atomic
operations using snapshot reads and
using using version stamp operations and
I'll go into what all of these are and
then I'll go into a kind of a motivating
use case where you can see them in
action
so atomic operations Tomic operations
are an API that foundation DB exposes
that allow you to push down work to a
storage server typically all the atomic
operations could be re-written as the
user requesting a key from the storage
server getting it back modifying it and
writing it back so for example if you
wanted to add one to a key you read the
key you add one to its value and you you
submit a commit that overwrites that
value of course the problem is that if
two people are trying to do this at once
one of them has to fail and so the
alternative is using an atomic operation
you basically send a commit to the to
the storage server that just says add
one to the key whatever it is and you
don't actually do the read you just let
the storage server handle that for you
one warning with this is that if you
imagine a particularly bad data model
for example that reads a single key and
updates at every single transaction
without atomic ops then you'll end up
serializing all of your operations and
that's bad but with atomic ops what
you'll end up doing is just slamming the
storage servers that are responsible for
that key so you can turn your one set of
performance pathologies the serialized
operations into another just hotspots so
they're not a panacea and you have to be
a little bit careful the second
technique is called snapshot reads so
like I said before whenever you do a
read in foundation DB the client is
automatically adding a read conflict
range well snapshot reads don't add that
range they say I know what I'm doing
don't have to read conflict range - the
key on reading just do the reads and
give me the values so the the idea here
is that you might do some reads specula
so for example let's say that you had
five jobs and you wanted to pick one of
them then what you could do is read all
five keys at snapshot isolation level
and then whichever one you actually end
up picking to process in that
action you call a method called a breed
conflict range or a breed conflict key
to add a conflict range just to the key
that you actually use to determine what
your operation and then carry on and if
two people come in at once and they pick
different keys from the five keys that
end up getting modified then they can
both kind of coexistence that's great
and the other thing you can do a
snapshot reads is if you're modifying a
key using atomic ops because that key
will be pretty hot if you want to
include any or do something based on the
key of the value of that key within your
transaction you can read it at snap so I
actually snapshot isolation level and
not be killed by somebody else modifying
it the warning here is that conflict
ranges are how FDB guarantees
serializability
and so if you are a little bit too
clever with getting rid of conflict
ranges you could end up committing
things that you shouldn't and then you
can have interesting sessions trying to
debug what's going on in prod and then
the final thing is of version stamps and
Ryan already mentioned version stamps in
his presentation but version stamps
essentially let you get a 10 byte
monotonically increasing value from the
database at commit time and overwrite
parts of your key or parts of your value
with that 10 byte monotonically
increasing thing and foundation DB
guarantees that within a cluster that
value is unique and that value always
goes up in time and this allows you to
do things like handle cues in a very
high contention way because there are no
Recon flicks at all and everything is
handled by the cluster kind of putting
things in commit order a couple warnings
here
one version stamps are inherently non
idempotent if you end up retrying a
transaction you will get a different key
guaranteed the second time this is the
exact opposite of item potency and it
also the values aren't valid across
clusters you can't correlate exactly
versions you get from one cluster with
versions you get another or from another
and that includes doing things like if
you have to restore into a new cluster
you're not guaranteed that the version
stamps that you get back will make any
sense so but they can be very powerful
in certain situations and so to talk
about these things I want to go through
a case study and the case study is the
sync problem so what is sync so sync or
synchronous
is a process where you might have
multiple clients who want to synchronize
on in some set of values in this case
we're gonna use a lot of a mathematical
set but you could imagine synchronizing
a map or synchronizing something more
interesting and so it's going to have a
pretty simple API you're gonna be able
to insert things into your sink machine
and you're gonna be able to get things
from your sink machine and you're going
to be able to pass it a token from the
last time you read and so you'll only
get updates you're tailing updates
continuously so we're gonna start with a
pretty simple approach we're not going
to worry about concurrency at first
we're just gonna keep a key that key is
going to have the maximum token we've
seen so far and we're also going to keep
an index of items in our sink machine
index by this token value and then we
just sync by doing a scan so for example
here's a simple sink machine inside the
cluster we have five items the max token
is four items of zero through four or
index zero through four so in order to
insert something our client will just
read the max token it gets back for is
its max token and then it will commit a
new transaction you can see in its reads
that it has the max token and in its
right set right set it has the key that
it's writing to five as well as the max
token and so when it inserts for show
into the database because it's the only
thing going on it gets added to the end
and the max token gets updated
atomically likewise a second client
let's is trying to do a sync
so it'll sync from three so it'll start
scanning from for the one after it got
its last token from and it'll get back
to results back elderberry and
Fraschilla okay here's the problem case
right so you have two clients trying to
insert at once one is trying to insert
for show ones trying to insert Fig
client one reads the max token it gets
back for client two reads the max token
it also gets back for now client one
writes five to the database over writes
two key five it succeeds because it was
first
but now client to client two tries to do
it right and it's trying to write the
exact same case trying to write five and
importantly it's basing its key right
the key that it's choosing on the value
of max token but max token has changed
since it began its transaction so the
resolvers will fail it all right so this
is
actually kind of will work with low
concurrency workloads and so if you have
a few enough people trying to interact
with the sink sink machine at once then
you might not have a problem but but
eventually you'll end up being oh I see
what it's doing oh this has a volume
control and every time I accidentally
hit volume it like complains about I'm
already at min volume whatever yes if
you've too many clients of one's coming
in you'll eventually be upset about
having an answer client questions about
how come they get random conflicts all
the time and so you decide that you
should want to want to make this more
scalable and add the ability to handle
more require more clients and ones and
so the problem was that all of our
clients based their next key based on
the value of max token and they all
choose chose the same value based on the
next token they all added one and so
we're going to try an approach where
we're going to try and relax
the reliance of max token so we're no
longer going to do that read at full
oscillation we're gonna do that in
snapshot isolation level and then we're
also going to have clients try and pick
different values when they insert into
the sync index through randomness so
like I said just out of random value to
the value you get from max token and
then write that element using the new
value and then we'll update the max
token accordingly with the value we
chose and we'll use it the max atomic
operation in order to have many clients
do that at once so let's see an example
again of the problematic use case of two
clients trying to insert at once this
time you'll notice there are gaps in
between the elements of the sync index
and that's because we're adding a random
value each time so we're sort of
incrementing nicely by one we get gaps
and so the first client will try via the
max token it gets back 20 and let's say
the second client tries to read the max
token it also gets back 20 and then
let's say client 1 generates a random
number and it generates a very random
number 7 and it writes back to key 27 so
if you look at the read set of this
transaction notice that max token is not
within it that is because we read max
token of isolation lot isolation level
but we are writing Zacky 27 and also
we're adding key 27 to our read set and
the reason we're doing that is that if
our second client happens to choose 7 as
well and tries to hit to that same key
we want
conflicts to save us if we had made the
mistake of not including that we would
have had those bad production problems I
mentioned earlier and so client one
succeeds incorrectly Android stereo 2
position 27 client to by amazing
coincidence didn't pick 7 and this time
tries to write fig 2 position 22 and
because it doesn't have any max token
has changed but it doesn't matter
because it's not the read conflict set
it's not writing to the same key as the
other transaction so it succeeds and now
fig is inserted in position 22 and our
sync index so is this a good solution
well in some sense we haven't exactly
solved the problem and that we still
have a bounded probability of conflicts
right if people pick the same thing then
they get a conflict so that's not great
but maybe well we're okay with that but
there's a deeper problem that has to do
with reads so this is a little bit more
involved in his three clients sorry
so again we'll have two clients trying
to insert at once and one client who's
trying to do a sync so as before client
one will read the max token and we'll
have client to read the max token and
then let's say client one tries to
commit it generates a random number of
seven again it inserts for Java in
position 27 so far so good now let's say
at this point client 3 tries to begin at
sync so it lasts on 19 so it's going to
start reading from 20 it's going to add
two results back elderberry and for Java
also so far so good
now client to client to let's say rolls
its random number generator and gets
back to again well this time when we
insert something into the database it's
writing a position 22 it has no read
conflicts that are that have been no
reach no keys have been modified since
it started that it cares about and so
it's will successfully insert fig into
the database but inserts it inserts it
at position 22 and the problem there is
that because client 3 has already read
through 27 client 3 will never go back
and sync back 22 so essentially you've
had a lost right into your system so how
do you fix this how do you fix this
problem that some values aren't synced
and as an addendum
this design this basic idea of adding
random numbers or randomness to the keys
as you're entering entering them into
the queue that's not necessarily not a
tenable design for example certain job
queue structures this would be perfectly
fine if you're doing certain kind of
roughly auto incrementing primary key
type things this might be fine the only
problem is that because of our read use
read pattern we'll lose some updates and
that's that's the exact problem we're
trying to solve so if we look at this
the problem was we've read through a key
and then somebody else committed
something before us and so the way we're
gonna get around this is by making sure
that every time we do a write it's at
the end of everything that anyone who's
ever committed and so to solve that
we're going to use version stamps so
we're going to remove the maxxtow kinky
all together we don't need it anymore
and we're just going to begin all of our
index keys with the current commit for
Earth equipment version using version
stamp operations and we're going to
depend on the two properties of version
stamps that I mentioned before one
they're monotonic by commit order this
is how we're gonna make sure that our
syncs line up correctly and the other
thing we're gonna rely on is the fact
that they unique this is how we're going
to make sure that two clients coming at
once don't write to the same place so
here we have our two clients trying to
insert into the database this time is
going to be relatively simple client one
when it tries to insert video it can do
this all in just a single blind right it
has no reads and it's great conflict
ranges it has one mutation namely that
it's setting the version stamped key
beginning with the version stamp two for
Java and it's right conflict side is a
little bit complicated ask me afterwards
if you want to know the details let's
say that the foundation you be close to
it gives at version 500 so when it goes
to write into the database it will
overwrite the places with the version
stamp with 500 and boom Michelle gets
added to the end of the database or to
the end of our sync machine then the
client to it also will submit a very
similar-looking transaction but this
time let's say the foundation DB
database gives it a different version
and it's we know it's going to give it a
different version and we know it's going
to give it us a higher version so let's
say it gives it five twenty and fig it's
added to the end of the database there
and so you can have multiple clients all
adding to the same
machine at once all getting placed at
the end happily now happily coexisting
so is this a perfect solution well kind
of in some sense it meets our spec
exactly we have unlimited parallelism
all coming in at once to the same place
and we have zero conflicts no but
nothing is perfect right so we have a
couple of problems one is that FTB's
tuple air encodes integers very
compactly in particular it uses a run
variable length encoding scheme so if
you have less than 65,000 items in your
sync index you can get by with only two
bytes for your token for each individual
item but virgin stamps are 12 bytes long
as deployed in many of the bindings and
so you're increasing your space usage
usage sometimes by a lot also version
stamps can make your code significantly
more complex a lot of your client code
is going to be written with the
assumption that it can know what keys
it's about to write we're version stamps
just by their very nature you don't know
what it's going to write until the very
end until it gets committed so that can
make a little bit more complicated
especially if you have to do things like
remove multiple updates to the same key
remove something you're going to sync
that's a little bit of a hard problem as
mentioned before this is not night
impotant operation so if you want to
make it item potent you have to do a
little bit of finagling where for
example you might keep a map of item to
version stamp and you have to check that
map to see if it exists or something
like that and likewise deletes and
updates can make somewhat complicated
that when you do a delete or an update
to something that's in the version stamp
thing in order to figure out the key you
need a map like that in order to do it
correctly
so in conclusion there are a couple
different strategies you might employ in
order when you're analyzing your data
model one is to look at your redirect
modify write patterns that you have in
your database things keys that you're
updating within the transaction and see
if any of those can be replaced with
atomic operations you want to be careful
be mindful of your read conflicts think
about which read companies you don't
really need and which ones you can
remove and then a third thing is you
have to be careful when you're being
clever with conflict ranges etc that
you're not accidentally removing
something that you actually do depend on
and therefore destroying the correctness
of your system so it's a little bit of a
balancing act but it's kind of necessary
to get good throughput in good latency
with FDB so thank you very much and a
happy data modelling
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> KPqmB13zI9c </VID>
<CONTENT>
trying to get large some American accent
it didn't really work out it was too
hard don't know how you guys learned it
but anyway you had to deal with my
Indian accent I am Baskar I work for
Apple I am working on foundation DB
layers for lost run out of years before
that I worked on Cassandra I did in
Cardinal Cassandra storage engine it was
better area before that and they worked
and also some workload improvements well
before going into document layer I want
to spend a little bit time on foundation
to build layers concept well Ben already
explained it I just want to I'll speed
it up so if you look at a typical
database stack it looks something like
this it has three components core engine
transactions module and stranger this is
a very theoretical conceptual view
usually the lines are blurry they
overlap quite a bit the core engine is
the one that decides the data model for
any database whether it is a document
data model document or sequel database
coroner is the one or transactions of
module and the storage engine these are
easily independent of the data model
well I guess I skipped it but query
engine is known which implements quality
planning at all and transaction module
guarantees the issued properties and
storage and is the one which guarantees
replication durability guarantees
so the problems that we usually solve in
bottom two layers are independent of the
data model they're usually same with
your database you deal with it easily
depends on what in a transactional
guarantees it there are always providing
not much on the what kind of that data
model it supports so Foundation debate
tries to solve the bottom 2/3 of the
stack at scale Foundation DB has
serializable transactions and it has
very strong isolation guarantee is it
supports well it has all the user base
top it has
synchronous backups multi-is in support
we talked about what foundation to make
good and so far let's look at the API
the API for foundation DB is very
minimalistic it has a rocky value shown
API unlike the traditional unlike the
sequel or document databases it doesn't
have joins or aggregations or secondary
nurses but the API is strong and
realistic enough the idea is you can use
this as a basic building block and you
can build interesting and complex data
models on top this is where the promise
of layers comes into picture layer stays
on top of foundation DB and it builds
the data models on top of on top of the
foundation to be API because formation
to be sauce all the most of the data
base problems layers can just worry
about data model and only the only that
petal problem not much of everything
else solved by foundation DB and the act
as the present state is stored on the
foundation DB layers are usually
stateless and layers can be either built
as libraries or you can build them as
stateless micro services as long as you
use the transactions every language the
layers list transactions properly
concurrency is taken care of taking care
by foundation DB so big because of that
if you want to have a more throughput
you can just run more instances without
worrying about concurrency or scale so
it's quite easy to scale as well well
this goes without saying
obviously layers inherit all the
foundational features it you get the
multi support we have the replication
and everything just happens seamlessly
well we already know the there are some
utility layers they are so critical they
actually shipped with for addition to B
language bindings directory layer which
is which provides us key space
abstraction on top of foundation db-api
and
to put a layer gives us a sorted order
data data type in recording and of
course there are a couple of layers from
community there is a linux NBD block
layer and a generous growth layer I
think we have talked after this in the
same spirit we have document layer
document layer we think this is the
first step this is the first step from
us towards the promise of foundation DB
future in future we'll see more more
layers from community and hopefully from
as well well good well document layer it
implements document database API on top
of foundation DB it's not just any
document of Sapa it is MongoDB quite
compatible because it is very compatible
you can just use any standard MongoDB
drivers or framework to connect to
document layer there is no you don't
have to for all that matters for the
application it looks like a MongoDB
server it does their things better
that's a different point but it is it
looks like a motive server well whatever
you can say out MongoDB people really
love the MongoDB API it is very easy to
use it is very quick to onboard the
query language is very rich there are
lots of different features on top then
and also lots of frameworks out there so
a company that with the strength of
foundation DB we really think this is a
very good way to very good and easy way
to on guarantee foundation baby well the
API there are no surprises here you
wanna know MongoDB is it is MongoDB API
it stores JSON documents and it is camel
s that I'm not going to spend any time
on API because there is huge
documentation out there there are lots
of tutorials and videos on MongoDB API
let's look at the feature set document
layer it is not a drop-in replacement
for MongoDB for most like for every
application out there we started as a
the core set of documents it did
document layers supports trade
operations lot set of quarry or blade
operators it supports secondary indices
and transactions these transactions are
foundation debit transactions expose
throw definitely API you see that here
you might not find the popular features
like change trains or aggregations of
MongoDB creations I guess these are two
big ones and also we probably might not
have all the second all like for
attached indexes and stuff like that
the we are this is the project this is
just starting up we are working on it
it's going to happen very soon what
makes document layer very special well
we keep hearing this morning anything to
it foundation to be starts with strong
consistency guarantees and document
layer just inherits that the consistency
it has very strong consistency
guarantees and it happens seamlessly you
do it application doesn't have to
specify what kind of read concerned what
kind what kind of read preference what
kind of write concern what kind of
consistency level they how to access
later on how to carefully manage all
that it is always consistent it is given
out of the box and there are no logs it
is optimistic concurrency control and
also they are not database loss at all
it is completely lock free the scaling
foundation to be well it is a
distributor base it is not just just it
is distribu at the same time it does die
the shortening and everything is dynamic
there are no static short case is the
again it is better at the same times
simpler for application application
anybody using static sharding database
like Mongo or Cassandra peep
applications easily it's quite often
that you use a short key and after six
months or one year once your data grows
quite a lot you realize hey my short key
is wrong now I have to chase my short
key and guess what I had to remake it
all my data or read it all my data again
there is no short key so you don't have
to worry about how to distribute your
data database foreign TV takes care of
it well I said so much about document
layer is this good and that good I had
to back up all those claims I think the
best way to backup these clients is
going little bit into into the design I
want to talk a little bit about how the
code execution model works and also how
we how the storage model works these two
things and highly will explain all the
claims so in the book with with the
single node sequel database like MySQL
post rest we are used to the norm that
everything is a transaction transactions
are not some slow features which you
have to use very carefully only when
there is no other way around everything
is a transaction with a like with
something like Porsches or most my
sequel even when you run a statement in
Porsche res without starting a
transaction Porsches automatically
starts the transaction runs the
statement commits immediately after so
that statement runs at a separate
transaction so document layer works more
in the same in the same spirit
everything is a transaction because
foundation to be everything is a
transaction so either application can
explicitly go and say I want to start a
transaction I want to run all these
statements and commit this which grows
all the statement are just like volt
MongoDB applications you can just keep
running I keep issuing the request
separately and each request
starts a separate foundation to be
transaction and we call them impulsive
transactions so let's see how they
actually look like well the green kind
green dot represents the MongoDB request
let's say document layer receives Eric
one singular question this is out of
transaction context a single request and
document layer sees this request it has
to find based on the model it has to it
has to do some operations on foundation
DB if you take an example of let's say a
simple MongoDB Riak MongoDB insert that
might need to read the metadata on among
a metadata from foundation DB and it
might have to do a find out if there is
a duplicate document it might have to
insert the document and also update the
secondary indices for the particular
collection all these operations will go
a separate foundation to be operations
but all of them happen under a single
transaction that gives sealless because
that gives zeros the constancy
for the whole for the request and well
yeah and obviously if there are any
conflicts document a takes care of
retrying or not so this is how the
transactions work but there is a catch
foundation to be transactions are short
or they have a limit of five seconds in
five seconds they have high second
limitation
obviously we can't really feed
everything you can you can imagine
MongoDB you can imagine a MongoDB
request which touches all documents in a
collection I could be running a request
to give 10% bonus to all my employees
that has to touch each and every
document and that may not depending on
how big my company is it might not fit
in a single transaction in it might not
finish in five seconds so it might not
fit in one transaction so obviously
document layer does the obvious thing
which is it slits into multiple
transactions so the guarantees here are
not as strong as short-lived
transactions
well shortly requires but it is it's
still guarantees constancy at individual
document level this is I think even for
the the longer he comes
for long-grain request may not be as
good as for the short running ones I
think it is still better than the
competition
then express it transactions application
can go and say hey I want to try a
transaction do this request this is
actually best way to get even better
performance than implicit transactions
because whether you want it or not the
document layer starts the transaction
anyway so if it's going if it's if
that's going to happen anyway then we're
going to like amortize the cost by
running multiple requests under one
transaction so this is even though the
data model is document data model lots
of the design principles here really
remind worlds equal days will not work
but the sequel days for sequel times but
when you are running XP transactions the
same principles apply when you run a
when you write application on top of
foundation DB it is optimistic
concurrency control so you have to worry
about conflicts and you have to worry
about retries the transaction the excuse
the transaction the transactions we have
right now are not yet compatible with v4
MongoDB transactions this is something
we are actually working on this gonna
change very soon the implementation we
have right now is kind of tied to client
connection this is again to deal with
not being compatible with a MongoDB
transaction this is probably the only
feature which is not compatible with the
existing model MongoDB features then
storage model well foundation DB is
storing so we don't have to worry about
the we don't have to worry about
persistence or replications of like that
but we have to worry about how do we map
document on - they have to be keys that
is quite important and actually well
that is quite important let's say if you
take a sample JSON document in MongoDB
underscore ID if you underscore it is
the primary key we have a sample
employed document let's see how we store
this
we documented stores a single document
across multiple activities this allows
document layer to have support larger
documents because each FDB key can't
hold more than all the value can't hold
more than 100 K bytes of data by
spreading it across multiple keys you
can have we can support larger documents
and one number two you do if you want to
update just one field in the document
you don't have to read the entire
document and write again wait a second I
think I didn't cover everything here the
the wiki is four but it is quite
important so key is you can Kiki has a
prefix of the collection name well it
usually is the derivative it's but
that's not important it has the
collection name so that you can group
all of your collection data under one
key space and then key includes the
primary key so that you can group all of
your keys for the document together at
the same time
all the documents or the same time all
the documents are ordered by the primary
key so you can see here we have multiple
employee documents here all of them are
ordered by the primary key primary key
here is the primary key if I want to
treat you can think the decimal is a
MongoDB c'mon if I want to read all
employees in the collection that that
boils down to doing a get range on
employee prefix this is like well get
registration to become one right yeah so
the same way if I want to read if I want
to access a employee document based on
the ID because ID is the primary key ID
is the private key that is part of the
FTP key I can just prepare the prefix
using the primary key and prefix which
becomes employee to it taxes the
employee record of Bob
this is good as long as you only care
about predicates that include primary
key but we have predicates that include
something like I want to access all
employees with named Eric we have to
have secondary nurses and we really have
secondary nearest secondary nurses how
to maintain mapping from index key to
primary key index key here is named
primary key ID so this how it looks like
well it has the index prefix and after
that the index key which stores the name
and their primary key the primary key
can be stored in the value but if you
you don't want to because unlike primary
index secondary unlike primary key is
secondary keys are not unique you can
have multiple eight value here we have
multiple here X if you do if you keep if
you don't keep the primary key part of
the part of the key then many s or Eric
I guess yeah he's gonna overwrite the
developer which is not great then the
value we really have to we don't restore
anything if there is a query something
like give me all documents with numeric
it first goes to the index space asking
how does it get range on Eric it gets
all the primary documents goes back to
the primary space and race all the
documents we could avoid doing this to
phase or like two sets of gets if we
store the we can't be coached all the
document or the fields of the document
we care about as value well they are
called index s we don't support them yet
but that's something that we can do so
what is this guy what is this kind of so
as model giving us aspect of what we
call primary key second rock n roll when
it goes out the foundation DB they are
all just normal case they are all
treated the same way by primary index
and secondary nurses they are shorted
the same way this is a big difference
from lots of from other no sequel
databases where
secondary nurses
is very closely tied with the primary
index so if you have to do a query on
secondary index it usually has to go to
each and every short you will familiar
if you like see Cassandra MongoDB this
how they is gonna do the any Korean
second and it usually has to touch each
and every shard that's not the case here
because secondary starting is same as a
primary next roaring and also you we are
getting all these features without
setting up any short case then the
indices as explained before index
updates always happen together with the
actual document update so indices always
always stay constant with the primary
index or the document period there is no
there are no exceptions and in this is
all distributed as well that's good
index rebuild this is some place where
we are focusing on at the moment we
MongoDB customers know how painful index
tables can be I didn't believe until I I
didn't even think that's possible to do
a index rebuild from a if your
application when students rebuild they
actually has to go to the operations
team and ask them carefully bounce
replicas one by one so then I so that
they can actually label indexes on each
new repeatin separately well that's not
the case here there are lots other
documents we are doing but I guess I'm
running out of time
well building layers on top of
foundation DB can be quite easy because
of all the guarantees foundation DB is
giving but the st. and there are lots of
challenges
it is autistic as currency control so
you have to worry about avoiding
contentions Alec from our team is giving
a talk this afternoon I strongly suggest
going for that super interesting one and
caching because we want to run multiple
instances of document layer any data we
are caching is gonna work a ganaches
because he have to now worry about
concurrency
because it's not part of the foundation
to be translational guarantees and any
code you're writing on top of foundation
DB has to be higher burden because of
unknown commit failures the last one
this is very deceiving I put it in like
one line query pairing optimization
people spend decades making out making
these things better
well we have a basic model that works
that kind of works we are working on
making better and better future
improvements these are the things coming
very very soon we want to make our
transactions compatible so they're so
that they actually work in all kinds of
deployments and mutual TLS shin from our
team is working on it he's gonna
probably commit APR like this week index
rebuild improvements quite a few other
were coming our metal metal table design
could be improved quite a bit and
features aggregations change streams lot
of people ask me about chain streams I
understand that is a very desert feature
that is something we ought to work on
like beginning of next year and a
spatial index has stretched indexes
special intersects probably very soon
community now document layer is open
source I should have put some link here
but you here you have google you can
google it is open source Apache butyl
license it's not any there are no
restrictions it's not you can't run a
service if you want to I'm not pointing
fingers but you can't run a service if
you want to and give it a shot
please give feedback and forums if you
liked it let us know if you don't like
it definitely let us know because we can
improve on it and rise issues if you
have some pictures that you really want
to see soon and well compares we are
really likes about this project we think
we can we could really build community
around this this is a best project and
also this one is written in flow C++
flow is a very fun language to work on
brush me I did Java until two years
backs
and whereas a flow is good it's good
that's all for me
[Applause]
</CONTENT>
</DOC>
<DOC>
<VID> SKcF3HPnYqg </VID>
<CONTENT>
all right I think everyone's about
settled now so my name is Ryan Worrell
and I'm here to talk to you about
solving everyday data problems with
foundation DB so everyone so far this
morning is led off with a story and
there's have started from like before
the acquisition I'm the first person
speaking today who didn't really know
anything about foundation DB until after
the acquisition and I've been starting
to work with it in the open source
during the last eight months so a little
bit about me I am an independent
software engineer my primary client
right now is a company called
clickfunnels
they make web page builder and marketing
automation software that's integrated
together so entrepreneurs can sell their
products online without having to know a
ton about websites and technology and
thing like that things like that they
have over seventy thousand customers
they've processed almost two billion
dollars of payments directly through
their you know direct integrations in
the software and there are billions of
rows of ltp data in there in their
database which is Amazon or my sequel
and I'm very happy that they let me come
to this conference and and talk about
all this
entering stuff is very gracious to them
so for this talk I want to cover kind of
the the status quo today in companies
that are running at scale and the
proliferation of different data systems
that you know that comes about after you
know you add one thing then you add
another because you have to solve these
different problems over time I want to
describe what I mean by everyday data
problems from the title this talk and
why foundation DB can be a solution to
some of these data problems at your
company and to motivate that I'm going
to show you the recent data problem that
I came up with clickfunnels
that was you know enabling
if solving it would enable lots of great
new features for them and at the end I'm
gonna go cover a little bit about how
foundation TV you can be a solution to
your data problems at your company and
just like general things you should know
about using it if you're coming in cold
you know don't not knowing anything
about it so the the status quo today is
that most apps start out uncomplicated
you don't start out by building an
architecture that has you know ten
different data systems in it usually
just like a database and a hue and that
gets you pretty far but five years later
you end up with a dozen systems in
production and you got a run of all it's
not a good time so when I when I say
everyday data problems this is what I
really mean like there are specific
things that come up in your company and
you just rip tools off the shelf and you
know like how did you end up in this
with this architecture nobody thought
about it it just emerged over time this
is a pretty old picture right now some
of the technologies are a bit dated
maybe you wouldn't pick them anymore for
a specific thing but it's still
representative of how things were today
in in big companies so over the last you
know five years or so a lot of companies
are moving into microservices
architectures and this might have good
benefits for your team in terms of being
able to scale like the number of
programmers working on a product but you
can make the situation worse very easily
by by breaking gear your model if that
had you maybe had transactions with your
sequel database and now you just don't
and what you can do so you can end up
reimplemented that thing like this where
all you just have the same data systems
under the hood it's now just worse
because there's more of them so you know
that I know that's a funny picture but
like why is this actually a problem the
the biggest most direct one I think
that's applicable to big companies is
you have to run this thing you got to
pay people to run it and whether you use
a managed service or you run it yourself
you're still paying for it at some level
the the more direct financial costs for
people that you know maybe they they
have a bunch of people they hired to run
these things anyway so they don't care
about the salaries that's not how
they're thinking about it you still pay
for duplicated data if you have like
triple replicated systems for high
availability and then you have you know
ten of them that all have triple
replicated all of the data you're paying
for a lot of storage the the insidious
one is the development cost that comes
in the future of when you introduce
these tools in your architecture and it
just makes it more complicated to
develop features over time and you end
up going slower where this where this
you know people trade off things in
their you know consistency or or a de
Missa T by introducing all these new
systems and from my experience I worked
with a few different companies that end
up with this this problem is that a
diversity is just like ignored and
people just gloss over it and they they
forget that like oh if I push a job into
the job queue and then in the same
request handler I have to write into the
sequel database they just like don't do
anything about it and this can end up
with corrupt data and I've I've seen
this like in the real world in multiple
places and that's you know it's not it's
not good for your company to have a
reputation of like losing or corrupting
data for your customers so you should
try to avoid that the the cost of a lot
of people also ignore but is still there
and it's becoming more prevalent the
cost of securing these different systems
because if you or if you're running
multiple different data systems so you
do a really good job of securing your
front end sequel database but if all
that same data is in another system that
nobody thought about they gets hacked
you know you still lose so the more
systems you're running the more risk you
have the a way that this manifests not
the not security necessarily but a way
that these problems manifest himself in
the world is that error handling code is
not exercised very often so when when
areas do come up they can do really bad
things like you know an error in a
system that you don't really
think about that much just say you know
the safe like your Redis Goes Down and
it's maybe not core to your architecture
it's just a cache you may end up causing
some kind of cascading failure and you
know how often do you exercise all that
error handling code do you know it works
probably not so a lot of people will use
manage cloud services nowadays to try to
avoid some of the operational headaches
that come with running a bunch of
different data systems but they will not
pick up the pieces for you if something
breaks like they will reboot the VM and
maybe you know update the software to
the next inversion but if you lost data
they can't fix that so if you're running
a weak system that like doesn't have
durability it does async replication and
somebody's managing it for you it
doesn't matter you'll see you can still
lose data so why is foundation to be a
solution to this problem where I could
it be a solution to some of these
problems at your company you get the
ability to build anything that you want
or anything that you'd need at your
company and you can run multiple of
these systems together in one cluster
and one thing that people don't talk
about a lot with foundation TV is that
if you have solutions that are by their
nature eventually consistent those are
easier to build in foundation db2
because you can you know if you get
transactions inside the system you can
build the the fancier things on top that
are eventually consistent say like in
the example I'm going to talk about
we're replicating data from Aurora into
Foundation DB so that you know it's
eventually consistent but inside it's
still really easy a program so as an
example it's something that you you
could do if you do transactions on the
front end you take the changelog of the
data and write it into some downstream
the left database like snowflake for
example you can do some of this with
foundation BB if you take if you as you
mutate data you write it to a change log
and foundation DB and then you make like
say a compressed column structure in the
OLAP side you do a big tables
and it's all in the same cluster depends
on the size of the data if this is a
good idea or not but is something that
you can do so the the reason why I was
interested in foundation DB is a product
their problem I was working with
clickfunnels to to solve the one of the
most important features of the the
clickfunnels platform is I called Smart
lists and these are basically dynamic
email lists that are based on user
defined rules so the customer can come
in and say I want a smart list based on
people who bought this product who are
on this static email list and who live
in this state for example the the way
that that works on the back end is we
just we have these crazy sequel queries
that get generated and they run against
the the billions of rows in that OLTP
database and their user facing portions
and automated portions of this that do
hundreds of queries a second to
calculate these smart lists as things
change this is a it's not exactly a
query but it's like a representative
query of what it would look like this is
like for one rule and the where clause
can get weird looking so to break the
problem down the data volume is in the
hundreds of gigabytes for the system
that we're talking about and you were
doing complex joins on a row oriented
storage database so you can already tell
us is not going well we have a lot of
indexes but they can't satisfy every
query because the queries are
essentially user generated they can kind
of do whatever they want with these
rules and Aurora just recently released
Amazon recently released for a parallel
querying but you can't directly upgrade
your cluster to that you have to do some
downtime which is you know not something
we want to do but so right now we're
just stuck with single threaded queries
in Aurora the when you get down to the
core level in the product of of what
we're doing we're doing set operations
on you know sets of integers like anding
and o-ring sets of of integers together
to say like you are you match this rule
or this rule and then and this rule that
type of thing
so if you if you study databases you
might think you know the solution to
this in app indexes so what we do what
we're doing here is not directly like a
bitmap index you'd see in relational
database we're doing bitmaps for the for
the individual rules I'm not here to
cover what bitmap indexes are that's a
longer talk but we use the roaring
bitmap library which implements a
compressed bitmap format for our use
cases it ends up being two to three bits
per set bit in the in the bitmap but in
general its proportional to the number
of bits that you set and the library
implements vectorized operations for for
doing the hands indoors on the sets and
it's really fast if you get a big enough
machine you're doing billions of
operations a second
you can parallel as this to multiple
cores and distribute across multiple
machines relatively easily when you're
using foundation to be I should say if
you're just doing it all yourself then
it's obviously not is not as easy so the
you know it's like I described what what
we're gonna do with the bitmap indexes
but what did we get out of it like
what's the result here so are the
biggest customers it takes multiple
minutes to evaluate there the rules
against the the list of customers that
they have and it's under 100
milliseconds with with it Maps so it's a
it's a huge win the the new
possibilities that this enables on the
product side are things like evaluating
rules on every customer website page
view its now it's fast enough that we
can do that and you can you can imagine
a scenario where you want to dynamically
change things on the page based on the
valuation of those rules you can also
show people in the UI as they're setting
up rules how many people is just going
to match
like in real time as they're clicking
around it can change the rules however
they want and we can recalculate you can
also adapt your stats and analytics in
this format for example you can make
bitmaps for every hour if you want to do
stats hourly and you can still run all
the same rules against them that you
that I'm talking about before so for
example if you wanted to do you new
unique email opens per hour with a bunch
of rules applied to them to say filter
out people outside the United States
just as as an example something you can
do make a bitmap for every hour of the
unique email opens with the set bits
being the contacts that open the email
and you can create a graph out of it the
basically the to reduce it all down we
can do whatever we want with us now and
the pages will load instantly for even
our largest customers so how do we use
foundation to be to get there I should
say this is not in production today I'm
talking about a prototype system was
still working to get it into production
so the the first step is to replicate
the binary log from Aurora into
Foundation DB this is pretty
straightforward to do the the right
volume is not high enough for us to need
to worry about charting and by sharding
I mean writing data at different
portions of the key space to not hit one
storage server so what I'm gonna show is
an example of how you could do a log
structure if you needed to you know do
exactly what we're saying like replicate
data out of another database in a
foundation DB you you pick a prefix that
you want to represent your log if you
don't have more than one log different
prefix and you can use version stamp
operations which allow you to write data
in order into foundation DB without
needing to like coordinate incrementing
some kind of counter key because it uses
the commit version of the transaction to
and it sticks that into the key
dynamically for you and we just write
the data from the bin log as the value
so because these bitmaps can be big if
you have lots of bits set on them you
need to chunk it up into smaller
segments so say 2 to the 18th that's a
good size
you just want to know that it will
always fit within a single value under
100 kilobyte value limit so this gets a
little more complicated and I'm not
gonna go into it but basically we just
have to evaluate every write against the
rules because the rules it can be
complicated just like the code is not
that interesting but you can imagine
importantly we only use one writer at a
time so there's no contention among the
different writes going on we could scale
this a different way by saying you get
one writer per per user but as I saying
the the right volume isn't high enough
so you don't worry about that right now
because setting the bits is really fast
this is an example of how you'd store a
large object among many different keys
so the the bitmap is identified by a
rule which is just the idea of a rule in
the in the database and each chunk gets
an offset from 0 that is like the 2 to
the 18th chunk of what what the bitmap
is and the value you store in the key is
the compressed chunk of the bitmap so
this is the the fun part is how do you
read it how do you do the calculations
so you do a range read for for every
chunk for each rule that you want to
evaluate and you paralyze by reading
different ranges and this is just like a
classic fork/join pattern that you've
learned if you did she done parallel
programming before so the in this
example core one is gonna read chunks
one chunk one for rule one and two and
then a different core can go read chunk
and four one and two and then you know
they individually do the operations
required for that for the rules and then
they combine the data at the end into a
resulting bitmap so yeah the the results
of this this prototype real world
queries for like representative data for
our customers are under a hundred
milliseconds for the smaller customers
it's a lot less than that
that can run on a single large box today
and you know it's a it's got a lot of
cores and it's doing the calculations in
parallel but you could also distribute
this among multiple machines later with
very little extra work if you had a
really big bitmap thankfully we don't we
don't need to do that right now it's
really easy to get high availability out
of this because you just put a little
balancer in front use an auto scaling
group I heard all the the point that's
really important I think for people that
are coming new to foundation DB this is
under 3,000 lines of JavaScript using
the the node bindings and and the wrong
a bitmap library it's very easy to get a
solution that provides a lot of value
with little code so if you were going to
decide to use foundation you be at your
company one thing one thing I've heard a
lot about and that's been talked about
it today is the performance to
Foundation DB it's it's very easy to
create you know a simplistic transaction
in foundation to be that performs poorly
because you're saying doing all the the
reads sequentially you you need to
understand the concurrency potential of
your problem and do as many reads
concurrently as you as you can you also
need to make sure you don't
unintentionally coordinate and cause
conflicts some examples of that in a
second the the way that this works is
you need to break down the critical path
of your transaction and you know make
sure you can do as many things
concurrently as possible this is like
just because of Dell's law if you're
going to do things in parallel the more
you can do in parallel the greater speed
up you get so this is an example that
made the rounds a little while ago from
a company called active sphere they
created a high contention allocator
class it just allocates short numeric
prefixes to like that are unique just to
save space in the keys and the naive
implementation tops out at about 275
allocations the second
and the latency grows as you add more
and more concurrent clients because this
the naive implementation coordinates and
only essentially allows one operation to
happen at any given time but if you
relax the constraints a little bit and
you you model a concurrency a bit better
you can get you know more or less linear
scalability out of it and the latency is
consistent even at higher concurrency
and the the link that is down there in
the corner has the full explanation so
the the documentation covers how to do
stuff like tables logs queues and
secondary indexes very well and it's
also just not a lot of code to do so I I
think that you should like if you
haven't read the documentation yet in in
detail please do that because it's it's
pretty good at the at the basics that
you need to get started but the the more
important thing is you get the freedom
to build your exact solution regardless
of you know the simplified things that
are in the documentation if you are
creative you can do whatever you want
and you don't get the explosion of data
systems that I was talking about before
because you can run it all in one
cluster there's one cluster I manage one
cluster to secure and one API for all of
your developers to learn so that's my
talk if anybody has any questions feel
free to email me or tweet me if you have
any questions want to know anything
about foundation TV I'm by no means an
expert but I've done a little bit of
work with it thank you
[Applause]
</CONTENT>
</DOC>